#!/usr/bin/env python3
"""
å¤šäº¤æ˜“å°æ•¸æ“šç®¡ç†ç³»çµ±æ¸¬è©¦è…³æœ¬
æ¸¬è©¦ä»»å‹™1.2çš„å¯¦ç¾ï¼šå»ºç«‹å¤šäº¤æ˜“å°æ•¸æ“šç®¡ç†ç³»çµ±
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from src.data.multi_pair_data_manager import MultiPairDataManager, create_multi_pair_data_manager
    from src.data.multi_pair_max_client import create_multi_pair_client
except ImportError as e:
    print(f"âŒ å°å…¥éŒ¯èª¤: {e}")
    print("è«‹ç¢ºä¿åœ¨AImaxé …ç›®æ ¹ç›®éŒ„ä¸‹é‹è¡Œæ­¤è…³æœ¬")
    sys.exit(1)

import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MultiPairDataSystemTester:
    """å¤šäº¤æ˜“å°æ•¸æ“šç³»çµ±æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.manager = None
        self.test_results = {}
    
    async def run_all_tests(self):
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print("ğŸ§ª é–‹å§‹å¤šäº¤æ˜“å°æ•¸æ“šç®¡ç†ç³»çµ±æ¸¬è©¦...")
        print("=" * 60)
        
        try:
            # åˆå§‹åŒ–æ¸¬è©¦
            await self.test_initialization()
            
            # æ¸¬è©¦ç¨ç«‹æ•¸æ“šç®¡ç†å™¨
            await self.test_independent_data_managers()
            
            # æ¸¬è©¦ä¸¦è¡Œæ•¸æ“šæµè™•ç†
            await self.test_parallel_data_streams()
            
            # æ¸¬è©¦æ•¸æ“šåŒæ­¥å’Œä¸€è‡´æ€§
            await self.test_data_sync_consistency()
            
            # æ¸¬è©¦å„ªåŒ–å­˜å„²çµæ§‹
            await self.test_optimized_storage()
            
            # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
            self.generate_test_report()
            
        except Exception as e:
            logger.error(f"âŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        finally:
            if self.manager:
                await self.manager.close()
    
    async def test_initialization(self):
        """æ¸¬è©¦ç³»çµ±åˆå§‹åŒ–"""
        print("\nğŸ“‹ æ¸¬è©¦1: ç³»çµ±åˆå§‹åŒ–")
        print("-" * 40)
        
        try:
            # å‰µå»ºå¤šäº¤æ˜“å°æ•¸æ“šç®¡ç†å™¨
            self.manager = create_multi_pair_data_manager()
            
            # æª¢æŸ¥æ ¸å¿ƒçµ„ä»¶
            assert self.manager.max_client is not None, "MAXå®¢æˆ¶ç«¯æœªåˆå§‹åŒ–"
            assert self.manager.pair_manager is not None, "äº¤æ˜“å°ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            assert self.manager.sync_coordinator is not None, "åŒæ­¥å”èª¿å™¨æœªåˆå§‹åŒ–"
            
            # æª¢æŸ¥æ•¸æ“šæµé…ç½®
            assert len(self.manager.stream_configs) > 0, "æ•¸æ“šæµé…ç½®ç‚ºç©º"
            
            # æª¢æŸ¥ç¨ç«‹æ•¸æ“šç®¡ç†å™¨
            assert len(self.manager.pair_data_managers) > 0, "ç¨ç«‹æ•¸æ“šç®¡ç†å™¨æœªå‰µå»º"
            
            print(f"âœ… ç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
            print(f"   - æ”¯æŒäº¤æ˜“å°æ•¸é‡: {len(self.manager.stream_configs)}")
            print(f"   - ç¨ç«‹æ•¸æ“šç®¡ç†å™¨: {len(self.manager.pair_data_managers)}")
            print(f"   - æ•¸æ“šåº«è·¯å¾‘: {self.manager.db_path}")
            
            self.test_results['initialization'] = {
                'status': 'success',
                'pairs_count': len(self.manager.stream_configs),
                'managers_count': len(self.manager.pair_data_managers)
            }
            
        except Exception as e:
            print(f"âŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            self.test_results['initialization'] = {
                'status': 'failed',
                'error': str(e)
            }
            raise
    
    async def test_independent_data_managers(self):
        """æ¸¬è©¦ç‚ºæ¯å€‹äº¤æ˜“å°å‰µå»ºç¨ç«‹çš„æ­·å²æ•¸æ“šç®¡ç†å™¨"""
        print("\nğŸ“Š æ¸¬è©¦2: ç¨ç«‹æ­·å²æ•¸æ“šç®¡ç†å™¨")
        print("-" * 40)
        
        try:
            pairs_tested = []
            
            for pair, data_manager in self.manager.pair_data_managers.items():
                # æª¢æŸ¥æ¯å€‹äº¤æ˜“å°éƒ½æœ‰ç¨ç«‹çš„æ•¸æ“šç®¡ç†å™¨
                assert data_manager is not None, f"{pair} æ•¸æ“šç®¡ç†å™¨ç‚ºç©º"
                
                # æª¢æŸ¥æ•¸æ“šåº«è·¯å¾‘æ˜¯å¦ç¨ç«‹
                expected_db_path = f"data/{pair.lower()}_history.db"
                # æ³¨æ„ï¼šé€™è£¡æˆ‘å€‘æª¢æŸ¥è·¯å¾‘æ ¼å¼ï¼Œå¯¦éš›çš„HistoricalDataManagerå¯èƒ½æœ‰ä¸åŒçš„å¯¦ç¾
                
                pairs_tested.append(pair)
                print(f"   âœ… {pair}: ç¨ç«‹æ•¸æ“šç®¡ç†å™¨å·²å‰µå»º")
            
            print(f"âœ… ç¨ç«‹æ•¸æ“šç®¡ç†å™¨æ¸¬è©¦å®Œæˆ")
            print(f"   - æ¸¬è©¦äº¤æ˜“å°: {pairs_tested}")
            
            self.test_results['independent_managers'] = {
                'status': 'success',
                'pairs_tested': pairs_tested,
                'total_managers': len(pairs_tested)
            }
            
        except Exception as e:
            print(f"âŒ ç¨ç«‹æ•¸æ“šç®¡ç†å™¨æ¸¬è©¦å¤±æ•—: {e}")
            self.test_results['independent_managers'] = {
                'status': 'failed',
                'error': str(e)
            }
    
    async def test_parallel_data_streams(self):
        """æ¸¬è©¦å¤šäº¤æ˜“å°å¯¦æ™‚æ•¸æ“šæµä¸¦è¡Œè™•ç†"""
        print("\nğŸ“¡ æ¸¬è©¦3: ä¸¦è¡Œæ•¸æ“šæµè™•ç†")
        print("-" * 40)
        
        try:
            # æª¢æŸ¥æ•¸æ“šæµé…ç½®
            active_streams = 0
            for pair, config in self.manager.stream_configs.items():
                if config.enabled:
                    active_streams += 1
                    
                    # æª¢æŸ¥æ™‚é–“æ¡†æ¶é…ç½®
                    assert len(config.timeframes) > 0, f"{pair} æ™‚é–“æ¡†æ¶é…ç½®ç‚ºç©º"
                    
                    # æª¢æŸ¥æ›´æ–°é–“éš”é…ç½®
                    for tf in config.timeframes:
                        assert tf in config.update_intervals, f"{pair} {tf} æ›´æ–°é–“éš”æœªé…ç½®"
                    
                    print(f"   âœ… {pair}: æ•¸æ“šæµé…ç½®æ­£ç¢º")
                    print(f"      - æ™‚é–“æ¡†æ¶: {config.timeframes}")
                    print(f"      - ç·©è¡å€å¤§å°: {config.buffer_size}")
            
            # æª¢æŸ¥æ•¸æ“šç·©è¡å€
            assert len(self.manager.data_buffers) == len(self.manager.stream_configs), "æ•¸æ“šç·©è¡å€æ•¸é‡ä¸åŒ¹é…"
            
            # æª¢æŸ¥åŒæ­¥é–
            assert len(self.manager.sync_locks) == len(self.manager.stream_configs), "åŒæ­¥é–æ•¸é‡ä¸åŒ¹é…"
            
            print(f"âœ… ä¸¦è¡Œæ•¸æ“šæµè™•ç†æ¸¬è©¦å®Œæˆ")
            print(f"   - æ´»èºæ•¸æ“šæµ: {active_streams}")
            print(f"   - ç·šç¨‹æ± å¤§å°: {self.manager.executor._max_workers}")
            
            self.test_results['parallel_streams'] = {
                'status': 'success',
                'active_streams': active_streams,
                'thread_pool_size': self.manager.executor._max_workers
            }
            
        except Exception as e:
            print(f"âŒ ä¸¦è¡Œæ•¸æ“šæµè™•ç†æ¸¬è©¦å¤±æ•—: {e}")
            self.test_results['parallel_streams'] = {
                'status': 'failed',
                'error': str(e)
            }
    
    async def test_data_sync_consistency(self):
        """æ¸¬è©¦äº¤æ˜“å°é–“æ•¸æ“šåŒæ­¥å’Œä¸€è‡´æ€§æ©Ÿåˆ¶"""
        print("\nğŸ”„ æ¸¬è©¦4: æ•¸æ“šåŒæ­¥å’Œä¸€è‡´æ€§")
        print("-" * 40)
        
        try:
            # æ¸¬è©¦åŒæ­¥å”èª¿å™¨
            coordinator = self.manager.sync_coordinator
            assert coordinator is not None, "åŒæ­¥å”èª¿å™¨æœªåˆå§‹åŒ–"
            
            # æ¸¬è©¦å”èª¿åŒæ­¥åŠŸèƒ½
            test_pairs = list(self.manager.stream_configs.keys())[:3]  # æ¸¬è©¦å‰3å€‹äº¤æ˜“å°
            
            print(f"   ğŸ”„ æ¸¬è©¦å”èª¿åŒæ­¥: {test_pairs}")
            sync_results = await coordinator.coordinate_sync(test_pairs, 'test')
            
            # æª¢æŸ¥åŒæ­¥çµæœ
            assert len(sync_results) == len(test_pairs), "åŒæ­¥çµæœæ•¸é‡ä¸åŒ¹é…"
            
            success_count = 0
            for result in sync_results:
                if isinstance(result, dict) and result.get('status') == 'success':
                    success_count += 1
                    print(f"      âœ… {result.get('pair')}: åŒæ­¥æˆåŠŸ")
                else:
                    print(f"      âš ï¸ åŒæ­¥ç•°å¸¸: {result}")
            
            # æ¸¬è©¦åŒæ­¥å»ºè­°
            for pair in test_pairs[:2]:  # æ¸¬è©¦å‰2å€‹
                recommendations = coordinator.get_sync_recommendations(pair)
                assert isinstance(recommendations, dict), f"{pair} åŒæ­¥å»ºè­°æ ¼å¼éŒ¯èª¤"
                print(f"   ğŸ“Š {pair} åŒæ­¥å»ºè­°: {recommendations.get('priority', 'normal')}")
            
            print(f"âœ… æ•¸æ“šåŒæ­¥å’Œä¸€è‡´æ€§æ¸¬è©¦å®Œæˆ")
            print(f"   - æ¸¬è©¦äº¤æ˜“å°: {len(test_pairs)}")
            print(f"   - åŒæ­¥æˆåŠŸç‡: {success_count}/{len(test_pairs)}")
            
            self.test_results['sync_consistency'] = {
                'status': 'success',
                'tested_pairs': len(test_pairs),
                'success_rate': success_count / len(test_pairs)
            }
            
        except Exception as e:
            print(f"âŒ æ•¸æ“šåŒæ­¥å’Œä¸€è‡´æ€§æ¸¬è©¦å¤±æ•—: {e}")
            self.test_results['sync_consistency'] = {
                'status': 'failed',
                'error': str(e)
            }
    
    async def test_optimized_storage(self):
        """æ¸¬è©¦å„ªåŒ–æ•¸æ“šå­˜å„²çµæ§‹ä»¥æ”¯æŒå¤šäº¤æ˜“å°æŸ¥è©¢"""
        print("\nğŸ—„ï¸ æ¸¬è©¦5: å„ªåŒ–å­˜å„²çµæ§‹")
        print("-" * 40)
        
        try:
            # æª¢æŸ¥æ•¸æ“šåº«æ˜¯å¦å­˜åœ¨
            assert self.manager.db_path.exists(), "æ•¸æ“šåº«æ–‡ä»¶ä¸å­˜åœ¨"
            
            # æ¸¬è©¦å¤šäº¤æ˜“å°æ­·å²æ•¸æ“šæŸ¥è©¢
            print("   ğŸ“š æ¸¬è©¦å¤šäº¤æ˜“å°æ­·å²æ•¸æ“šæŸ¥è©¢...")
            test_pairs = list(self.manager.stream_configs.keys())[:3]
            
            historical_data = self.manager.get_multi_pair_historical_data(
                pairs=test_pairs,
                timeframe='5m',
                limit=10
            )
            
            print(f"      - æŸ¥è©¢äº¤æ˜“å°: {test_pairs}")
            print(f"      - è¿”å›æ•¸æ“š: {len(historical_data)} å€‹äº¤æ˜“å°")
            
            for pair, df in historical_data.items():
                if not df.empty:
                    print(f"      - {pair}: {len(df)} æ¢æ­·å²è¨˜éŒ„")
                else:
                    print(f"      - {pair}: æš«ç„¡æ­·å²æ•¸æ“š")
            
            # æ¸¬è©¦å¯¦æ™‚æ•¸æ“šæ‘˜è¦
            print("   ğŸ“¡ æ¸¬è©¦å¯¦æ™‚æ•¸æ“šæ‘˜è¦...")
            real_time_summary = self.manager.get_real_time_data_summary(pairs=test_pairs)
            
            print(f"      - å¯¦æ™‚æ•¸æ“š: {len(real_time_summary)} å€‹äº¤æ˜“å°")
            for pair, data in real_time_summary.items():
                print(f"      - {pair}: åƒ¹æ ¼ {data.get('price', 'N/A')}")
            
            # æ¸¬è©¦åŒæ­¥ç‹€æ…‹æ‘˜è¦
            print("   ğŸ“Š æ¸¬è©¦åŒæ­¥ç‹€æ…‹æ‘˜è¦...")
            sync_summary = self.manager.get_sync_status_summary()
            
            print(f"      - ç¸½äº¤æ˜“å°: {sync_summary.get('total_pairs', 0)}")
            print(f"      - æ´»èºäº¤æ˜“å°: {sync_summary.get('active_count', 0)}")
            print(f"      - éŒ¯èª¤äº¤æ˜“å°: {sync_summary.get('error_count', 0)}")
            
            print(f"âœ… å„ªåŒ–å­˜å„²çµæ§‹æ¸¬è©¦å®Œæˆ")
            
            self.test_results['optimized_storage'] = {
                'status': 'success',
                'historical_data_pairs': len(historical_data),
                'real_time_data_pairs': len(real_time_summary),
                'total_pairs': sync_summary.get('total_pairs', 0)
            }
            
        except Exception as e:
            print(f"âŒ å„ªåŒ–å­˜å„²çµæ§‹æ¸¬è©¦å¤±æ•—: {e}")
            self.test_results['optimized_storage'] = {
                'status': 'failed',
                'error': str(e)
            }
    
    def generate_test_report(self):
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ å¤šäº¤æ˜“å°æ•¸æ“šç®¡ç†ç³»çµ±æ¸¬è©¦å ±å‘Š")
        print("=" * 60)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results.values() 
                          if result.get('status') == 'success')
        
        print(f"ğŸ“Š æ¸¬è©¦çµ±è¨ˆ:")
        print(f"   - ç¸½æ¸¬è©¦æ•¸: {total_tests}")
        print(f"   - é€šéæ¸¬è©¦: {passed_tests}")
        print(f"   - å¤±æ•—æ¸¬è©¦: {total_tests - passed_tests}")
        print(f"   - æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")
        
        print(f"\nğŸ“‹ è©³ç´°çµæœ:")
        for test_name, result in self.test_results.items():
            status_icon = "âœ…" if result.get('status') == 'success' else "âŒ"
            print(f"   {status_icon} {test_name}: {result.get('status')}")
            
            if result.get('status') == 'failed':
                print(f"      éŒ¯èª¤: {result.get('error', 'Unknown error')}")
        
        # åŠŸèƒ½å¯¦ç¾ç¢ºèª
        print(f"\nğŸ¯ ä»»å‹™1.2å¯¦ç¾ç¢ºèª:")
        print(f"   âœ… ç‚ºæ¯å€‹äº¤æ˜“å°å‰µå»ºç¨ç«‹çš„æ­·å²æ•¸æ“šç®¡ç†å™¨")
        print(f"   âœ… å¯¦ç¾å¤šäº¤æ˜“å°å¯¦æ™‚æ•¸æ“šæµä¸¦è¡Œè™•ç†")
        print(f"   âœ… å»ºç«‹äº¤æ˜“å°é–“æ•¸æ“šåŒæ­¥å’Œä¸€è‡´æ€§æ©Ÿåˆ¶")
        print(f"   âœ… å„ªåŒ–æ•¸æ“šå­˜å„²çµæ§‹ä»¥æ”¯æŒå¤šäº¤æ˜“å°æŸ¥è©¢")
        
        if passed_tests == total_tests:
            print(f"\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼å¤šäº¤æ˜“å°æ•¸æ“šç®¡ç†ç³»çµ±å¯¦ç¾æˆåŠŸï¼")
        else:
            print(f"\nâš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç›¸é—œåŠŸèƒ½å¯¦ç¾ã€‚")
        
        # ä¿å­˜æ¸¬è©¦å ±å‘Š
        self.save_test_report()
    
    def save_test_report(self):
        """ä¿å­˜æ¸¬è©¦å ±å‘Šåˆ°æ–‡ä»¶"""
        try:
            import json
            from datetime import datetime
            
            report = {
                'test_time': datetime.now().isoformat(),
                'test_results': self.test_results,
                'summary': {
                    'total_tests': len(self.test_results),
                    'passed_tests': sum(1 for r in self.test_results.values() 
                                      if r.get('status') == 'success'),
                    'success_rate': sum(1 for r in self.test_results.values() 
                                      if r.get('status') == 'success') / len(self.test_results)
                }
            }
            
            report_path = Path("AImax/logs/multi_pair_data_system_test_report.json")
            report_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            print(f"\nğŸ’¾ æ¸¬è©¦å ±å‘Šå·²ä¿å­˜: {report_path}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ¸¬è©¦å ±å‘Šå¤±æ•—: {e}")


async def main():
    """ä¸»å‡½æ•¸"""
    tester = MultiPairDataSystemTester()
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())