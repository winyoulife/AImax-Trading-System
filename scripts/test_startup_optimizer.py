#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å•Ÿå‹•å„ªåŒ–å™¨æ¸¬è©¦è…³æœ¬
æ¸¬è©¦å•Ÿå‹•å„ªåŒ–ç³»çµ±çš„å„é …åŠŸèƒ½
"""

import sys
import os
import time
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from PyQt6.QtWidgets import QApplication
from PyQt6.QtCore import QTimer
from src.gui.startup_optimizer import (
    StartupOptimizer, 
    StartupTask, 
    ParallelTaskExecutor,
    LazyLoader,
    StartupTimeMonitor,
    ResourcePreloader
)


class StartupOptimizerTester:
    """å•Ÿå‹•å„ªåŒ–å™¨æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.app = QApplication(sys.argv)
        self.test_results = {}
        self.current_test = 0
        self.total_tests = 6
        
    def run_all_tests(self):
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print("ğŸ§ª å•Ÿå‹•å„ªåŒ–å™¨æ¸¬è©¦é–‹å§‹")
        print("=" * 50)
        
        tests = [
            ("æ™‚é–“ç›£æ§å™¨æ¸¬è©¦", self.test_time_monitor),
            ("ä¸¦è¡Œä»»å‹™åŸ·è¡Œå™¨æ¸¬è©¦", self.test_parallel_executor),
            ("å»¶é²è¼‰å…¥å™¨æ¸¬è©¦", self.test_lazy_loader),
            ("è³‡æºé è¼‰å…¥å™¨æ¸¬è©¦", self.test_resource_preloader),
            ("å®Œæ•´å•Ÿå‹•å„ªåŒ–æ¸¬è©¦", self.test_full_optimization),
            ("æ€§èƒ½åŸºæº–æ¸¬è©¦", self.test_performance_benchmark)
        ]
        
        for test_name, test_func in tests:
            self.current_test += 1
            print(f"\nğŸ“‹ æ¸¬è©¦ {self.current_test}/{self.total_tests}: {test_name}")
            print("-" * 30)
            
            try:
                result = test_func()
                self.test_results[test_name] = {
                    'success': True,
                    'result': result,
                    'error': None
                }
                print(f"âœ… {test_name} é€šé")
                
            except Exception as e:
                self.test_results[test_name] = {
                    'success': False,
                    'result': None,
                    'error': str(e)
                }
                print(f"âŒ {test_name} å¤±æ•—: {e}")
        
        self.print_summary()
        return self.test_results
    
    def test_time_monitor(self):
        """æ¸¬è©¦æ™‚é–“ç›£æ§å™¨"""
        monitor = StartupTimeMonitor()
        
        # é–‹å§‹ç›£æ§
        monitor.start_monitoring()
        time.sleep(0.1)
        
        # æ·»åŠ æª¢æŸ¥é»
        monitor.add_checkpoint("test_checkpoint_1")
        time.sleep(0.1)
        monitor.add_checkpoint("test_checkpoint_2")
        
        # æ¸¬è©¦éšæ®µè¨ˆæ™‚
        monitor.start_phase("test_phase")
        time.sleep(0.1)
        monitor.end_phase("test_phase")
        
        # é©—è­‰çµæœ
        total_time = monitor.get_total_time()
        checkpoints = monitor.get_checkpoint_times()
        phases = monitor.get_phase_times()
        
        assert total_time > 0.3, f"ç¸½æ™‚é–“æ‡‰è©²å¤§æ–¼0.3ç§’ï¼Œå¯¦éš›: {total_time}"
        assert "test_checkpoint_1" in checkpoints, "æª¢æŸ¥é»1æ‡‰è©²å­˜åœ¨"
        assert "test_checkpoint_2" in checkpoints, "æª¢æŸ¥é»2æ‡‰è©²å­˜åœ¨"
        assert "test_phase" in phases, "æ¸¬è©¦éšæ®µæ‡‰è©²å­˜åœ¨"
        assert phases["test_phase"] > 0.1, f"éšæ®µæ™‚é–“æ‡‰è©²å¤§æ–¼0.1ç§’ï¼Œå¯¦éš›: {phases['test_phase']}"
        
        print(f"   ç¸½æ™‚é–“: {total_time:.3f}s")
        print(f"   æª¢æŸ¥é»æ•¸é‡: {len(checkpoints)}")
        print(f"   éšæ®µæ•¸é‡: {len(phases)}")
        
        return {
            'total_time': total_time,
            'checkpoints': len(checkpoints),
            'phases': len(phases)
        }
    
    def test_parallel_executor(self):
        """æ¸¬è©¦ä¸¦è¡Œä»»å‹™åŸ·è¡Œå™¨"""
        executor = ParallelTaskExecutor(max_workers=2)
        
        # å‰µå»ºæ¸¬è©¦ä»»å‹™
        def quick_task():
            time.sleep(0.1)
            return "quick_done"
        
        def slow_task():
            time.sleep(0.2)
            return "slow_done"
        
        def error_task():
            raise Exception("æ¸¬è©¦éŒ¯èª¤")
        
        # æ·»åŠ ä»»å‹™
        executor.add_task(StartupTask("quick", quick_task, priority=1))
        executor.add_task(StartupTask("slow", slow_task, priority=2))
        executor.add_task(StartupTask("error", error_task, priority=3, is_critical=False))
        
        # åŸ·è¡Œä»»å‹™
        start_time = time.time()
        executor.execute_tasks()
        
        # ç­‰å¾…å®Œæˆï¼ˆç°¡å–®ç­‰å¾…ï¼‰
        while executor.running:
            time.sleep(0.01)
        
        execution_time = time.time() - start_time
        
        # é©—è­‰çµæœ
        assert len(executor.completed_tasks) == 3, f"æ‡‰è©²å®Œæˆ3å€‹ä»»å‹™ï¼Œå¯¦éš›: {len(executor.completed_tasks)}"
        assert executor.completed_tasks["quick"].success, "å¿«é€Ÿä»»å‹™æ‡‰è©²æˆåŠŸ"
        assert executor.completed_tasks["slow"].success, "æ…¢é€Ÿä»»å‹™æ‡‰è©²æˆåŠŸ"
        assert not executor.completed_tasks["error"].success, "éŒ¯èª¤ä»»å‹™æ‡‰è©²å¤±æ•—"
        
        # ä¸¦è¡ŒåŸ·è¡Œæ‡‰è©²æ¯”é †åºåŸ·è¡Œå¿«ï¼ˆèª¿æ•´é æœŸæ™‚é–“ï¼‰
        assert execution_time < 1.0, f"ä¸¦è¡ŒåŸ·è¡Œæ™‚é–“æ‡‰è©²å°æ–¼1.0ç§’ï¼Œå¯¦éš›: {execution_time:.3f}s"
        
        print(f"   åŸ·è¡Œæ™‚é–“: {execution_time:.3f}s")
        print(f"   æˆåŠŸä»»å‹™: {sum(1 for r in executor.completed_tasks.values() if r.success)}")
        print(f"   å¤±æ•—ä»»å‹™: {sum(1 for r in executor.completed_tasks.values() if not r.success)}")
        
        return {
            'execution_time': execution_time,
            'total_tasks': len(executor.completed_tasks),
            'successful_tasks': sum(1 for r in executor.completed_tasks.values() if r.success)
        }
    
    def test_lazy_loader(self):
        """æ¸¬è©¦å»¶é²è¼‰å…¥å™¨"""
        loader = LazyLoader()
        
        # è¨»å†Šæ¸¬è©¦æ¨¡çµ„
        def load_test_module():
            return {"name": "test_module", "loaded": True}
        
        def load_error_module():
            raise Exception("è¼‰å…¥å¤±æ•—")
        
        loader.register_module("test_module", load_test_module)
        loader.register_module("error_module", load_error_module)
        
        # æ¸¬è©¦æ­£å¸¸è¼‰å…¥
        assert not loader.is_loaded("test_module"), "æ¨¡çµ„æ‡‰è©²å°šæœªè¼‰å…¥"
        
        module = loader.load_module("test_module")
        assert module["name"] == "test_module", "æ¨¡çµ„å…§å®¹ä¸æ­£ç¢º"
        assert loader.is_loaded("test_module"), "æ¨¡çµ„æ‡‰è©²å·²è¼‰å…¥"
        
        # æ¸¬è©¦é‡è¤‡è¼‰å…¥
        module2 = loader.load_module("test_module")
        assert module is module2, "é‡è¤‡è¼‰å…¥æ‡‰è©²è¿”å›ç›¸åŒå°è±¡"
        
        # æ¸¬è©¦éŒ¯èª¤è™•ç†
        try:
            loader.load_module("error_module")
            assert False, "æ‡‰è©²æ‹‹å‡ºç•°å¸¸"
        except RuntimeError as e:
            assert "è¼‰å…¥æ¨¡çµ„ error_module å¤±æ•—" in str(e), "éŒ¯èª¤è¨Šæ¯ä¸æ­£ç¢º"
        
        # æ¸¬è©¦æœªè¨»å†Šæ¨¡çµ„
        try:
            loader.load_module("unknown_module")
            assert False, "æ‡‰è©²æ‹‹å‡ºç•°å¸¸"
        except ValueError as e:
            assert "æœªè¨»å†Šçš„æ¨¡çµ„" in str(e), "éŒ¯èª¤è¨Šæ¯ä¸æ­£ç¢º"
        
        loaded_modules = loader.get_loaded_modules()
        print(f"   å·²è¼‰å…¥æ¨¡çµ„: {loaded_modules}")
        
        return {
            'loaded_modules': len(loaded_modules),
            'test_passed': True
        }
    
    def test_resource_preloader(self):
        """æ¸¬è©¦è³‡æºé è¼‰å…¥å™¨"""
        preloader = ResourcePreloader()
        
        # æ·»åŠ é è¼‰å…¥ä»»å‹™
        def load_config():
            return {"config_key": "config_value"}
        
        def load_data():
            return {"data_key": "data_value"}
        
        def load_error():
            raise Exception("è¼‰å…¥éŒ¯èª¤")
        
        preloader.add_preload_task("config", load_config)
        preloader.add_preload_task("data", load_data)
        preloader.add_preload_task("error", load_error)
        
        # åŸ·è¡Œé è¼‰å…¥
        preloader.preload_resources()
        
        # é©—è­‰çµæœ
        assert preloader.is_preloaded("config"), "é…ç½®æ‡‰è©²å·²é è¼‰å…¥"
        assert preloader.is_preloaded("data"), "æ•¸æ“šæ‡‰è©²å·²é è¼‰å…¥"
        assert not preloader.is_preloaded("error"), "éŒ¯èª¤è³‡æºä¸æ‡‰è©²é è¼‰å…¥"
        
        config = preloader.get_resource("config")
        assert config["config_key"] == "config_value", "é…ç½®å…§å®¹ä¸æ­£ç¢º"
        
        data = preloader.get_resource("data")
        assert data["data_key"] == "data_value", "æ•¸æ“šå…§å®¹ä¸æ­£ç¢º"
        
        error_resource = preloader.get_resource("error")
        assert error_resource is None, "éŒ¯èª¤è³‡æºæ‡‰è©²ç‚ºNone"
        
        print(f"   é è¼‰å…¥è³‡æºæ•¸é‡: {len(preloader.preloaded_resources)}")
        
        return {
            'preloaded_count': len(preloader.preloaded_resources),
            'test_passed': True
        }
    
    def test_full_optimization(self):
        """æ¸¬è©¦å®Œæ•´å•Ÿå‹•å„ªåŒ–"""
        optimizer = StartupOptimizer()
        
        # é…ç½®å„ªåŒ–é¸é …
        optimizer.configure_optimization(
            parallel_loading=True,
            lazy_loading=True,
            resource_preloading=True,
            target_time=3.0
        )
        
        # è¨­ç½®å®Œæˆå›èª¿
        optimization_result = {}
        
        def on_completed(report):
            optimization_result.update(report)
        
        optimizer.optimization_completed.connect(on_completed)
        
        # åŸ·è¡Œå„ªåŒ–
        start_time = time.time()
        optimizer.optimize_startup()
        
        # ç­‰å¾…å®Œæˆ
        timeout = 10.0
        elapsed = 0.0
        while not optimization_result and elapsed < timeout:
            self.app.processEvents()
            time.sleep(0.01)
            elapsed = time.time() - start_time
        
        assert optimization_result, "å„ªåŒ–æ‡‰è©²å®Œæˆä¸¦è¿”å›çµæœ"
        
        # é©—è­‰å ±å‘Šå…§å®¹
        assert 'timing' in optimization_result, "å ±å‘Šæ‡‰è©²åŒ…å«æ™‚é–“ä¿¡æ¯"
        assert 'performance' in optimization_result, "å ±å‘Šæ‡‰è©²åŒ…å«æ€§èƒ½ä¿¡æ¯"
        assert 'task_stats' in optimization_result, "å ±å‘Šæ‡‰è©²åŒ…å«ä»»å‹™çµ±è¨ˆ"
        
        timing = optimization_result['timing']
        performance = optimization_result['performance']
        task_stats = optimization_result['task_stats']
        
        print(f"   ç¸½æ™‚é–“: {timing['total_time']:.3f}s")
        print(f"   ç›®æ¨™é”æˆ: {performance['target_met']}")
        print(f"   æ•ˆç‡åˆ†æ•¸: {performance['efficiency_score']:.1f}%")
        print(f"   æˆåŠŸä»»å‹™: {task_stats['successful_tasks']}/{task_stats['total_tasks']}")
        
        return {
            'total_time': timing['total_time'],
            'target_met': performance['target_met'],
            'efficiency_score': performance['efficiency_score'],
            'successful_tasks': task_stats['successful_tasks']
        }
    
    def test_performance_benchmark(self):
        """æ¸¬è©¦æ€§èƒ½åŸºæº–"""
        print("   åŸ·è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦...")
        
        # æ¸¬è©¦ä¸åŒé…ç½®çš„æ€§èƒ½
        configs = [
            ("é †åºè¼‰å…¥", False, False, False),
            ("ä¸¦è¡Œè¼‰å…¥", True, False, False),
            ("å®Œæ•´å„ªåŒ–", True, True, True)
        ]
        
        benchmark_results = {}
        
        for config_name, parallel, lazy, preload in configs:
            optimizer = StartupOptimizer()
            optimizer.configure_optimization(
                parallel_loading=parallel,
                lazy_loading=lazy,
                resource_preloading=preload,
                target_time=5.0
            )
            
            result = {}
            
            def on_completed(report):
                result.update(report)
            
            optimizer.optimization_completed.connect(on_completed)
            
            start_time = time.time()
            optimizer.optimize_startup()
            
            # ç­‰å¾…å®Œæˆ
            timeout = 10.0
            elapsed = 0.0
            while not result and elapsed < timeout:
                self.app.processEvents()
                time.sleep(0.01)
                elapsed = time.time() - start_time
            
            if result:
                benchmark_results[config_name] = {
                    'time': result['timing']['total_time'],
                    'efficiency': result['performance']['efficiency_score']
                }
                print(f"     {config_name}: {result['timing']['total_time']:.3f}s")
        
        return benchmark_results
    
    def print_summary(self):
        """æ‰“å°æ¸¬è©¦æ‘˜è¦"""
        print("\n" + "=" * 50)
        print("ğŸ“Š æ¸¬è©¦æ‘˜è¦")
        print("=" * 50)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results.values() if r['success'])
        failed_tests = total_tests - passed_tests
        
        print(f"ç¸½æ¸¬è©¦æ•¸: {total_tests}")
        print(f"é€šéæ¸¬è©¦: {passed_tests}")
        print(f"å¤±æ•—æ¸¬è©¦: {failed_tests}")
        print(f"æˆåŠŸç‡: {(passed_tests/total_tests)*100:.1f}%")
        
        if failed_tests > 0:
            print("\nâŒ å¤±æ•—çš„æ¸¬è©¦:")
            for test_name, result in self.test_results.items():
                if not result['success']:
                    print(f"   - {test_name}: {result['error']}")
        
        print("\nâœ… å•Ÿå‹•å„ªåŒ–å™¨æ¸¬è©¦å®Œæˆï¼")


def main():
    """ä¸»å‡½æ•¸"""
    try:
        tester = StartupOptimizerTester()
        results = tester.run_all_tests()
        
        # è¿”å›é©ç•¶çš„é€€å‡ºç¢¼
        success_count = sum(1 for r in results.values() if r['success'])
        return 0 if success_count == len(results) else 1
        
    except Exception as e:
        print(f"ğŸ’¥ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)