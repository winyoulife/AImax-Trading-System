#!/usr/bin/env python3
"""
AImax æ–‡æª”é©—è­‰è…³æœ¬
é©—è­‰æŠ€è¡“æ–‡æª”çš„å®Œæ•´æ€§å’Œæ­£ç¢ºæ€§
"""

import os
import sys
import json
from pathlib import Path

def validate_documentation():
    """é©—è­‰æ–‡æª”å®Œæ•´æ€§"""
    print("ğŸ” é–‹å§‹é©—è­‰AImaxæŠ€è¡“æ–‡æª”...")
    
    # æ–‡æª”ç›®éŒ„
    docs_dir = Path("AImax/docs")
    
    # å¿…éœ€çš„æ–‡æª”æ–‡ä»¶
    required_docs = [
        "README.md",
        "SYSTEM_ARCHITECTURE.md", 
        "API_DOCUMENTATION.md",
        "CONFIGURATION_GUIDE.md",
        "DEPLOYMENT_GUIDE.md",
        "TROUBLESHOOTING_GUIDE.md"
    ]
    
    # æª¢æŸ¥æ–‡æª”æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    missing_docs = []
    existing_docs = []
    
    for doc in required_docs:
        doc_path = docs_dir / doc
        if doc_path.exists():
            existing_docs.append(doc)
            print(f"âœ… {doc} - å­˜åœ¨")
        else:
            missing_docs.append(doc)
            print(f"âŒ {doc} - ç¼ºå¤±")
    
    # æª¢æŸ¥æ–‡æª”å…§å®¹
    content_issues = []
    
    for doc in existing_docs:
        doc_path = docs_dir / doc
        try:
            with open(doc_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # åŸºæœ¬å…§å®¹æª¢æŸ¥
            if len(content) < 1000:
                content_issues.append(f"{doc} - å…§å®¹éçŸ­")
            
            # æª¢æŸ¥å¿…è¦çš„æ¨™é¡Œ
            if doc == "README.md":
                required_sections = ["æ–‡æª”æ¦‚è¿°", "æ–‡æª”ç›®éŒ„", "å¿«é€Ÿå°èˆª"]
            elif doc == "SYSTEM_ARCHITECTURE.md":
                required_sections = ["ç³»çµ±æ¦‚è¿°", "ç³»çµ±æ¶æ§‹", "æ•¸æ“šæµæ¶æ§‹"]
            elif doc == "API_DOCUMENTATION.md":
                required_sections = ["APIæ¦‚è¿°", "èªè­‰æ©Ÿåˆ¶", "ç³»çµ±ç‹€æ…‹API"]
            elif doc == "CONFIGURATION_GUIDE.md":
                required_sections = ["é…ç½®æ¦‚è¿°", "ä¸»ç³»çµ±é…ç½®", "AIæ¨¡å‹é…ç½®"]
            elif doc == "DEPLOYMENT_GUIDE.md":
                required_sections = ["éƒ¨ç½²æ¦‚è¿°", "ç³»çµ±è¦æ±‚", "ç’°å¢ƒæº–å‚™"]
            elif doc == "TROUBLESHOOTING_GUIDE.md":
                required_sections = ["æ•…éšœæ’é™¤æ¦‚è¿°", "ç·Šæ€¥æ•…éšœè™•ç†", "å¸¸è¦‹å•é¡Œè¨ºæ–·"]
            else:
                required_sections = []
            
            for section in required_sections:
                if section not in content:
                    content_issues.append(f"{doc} - ç¼ºå°‘ç« ç¯€: {section}")
                    
        except Exception as e:
            content_issues.append(f"{doc} - è®€å–éŒ¯èª¤: {str(e)}")
    
    # ç”Ÿæˆé©—è­‰å ±å‘Š
    print("\nğŸ“Š æ–‡æª”é©—è­‰å ±å‘Š")
    print("=" * 50)
    print(f"ç¸½æ–‡æª”æ•¸é‡: {len(required_docs)}")
    print(f"å­˜åœ¨æ–‡æª”: {len(existing_docs)}")
    print(f"ç¼ºå¤±æ–‡æª”: {len(missing_docs)}")
    print(f"å…§å®¹å•é¡Œ: {len(content_issues)}")
    
    if missing_docs:
        print("\nâŒ ç¼ºå¤±çš„æ–‡æª”:")
        for doc in missing_docs:
            print(f"  - {doc}")
    
    if content_issues:
        print("\nâš ï¸  å…§å®¹å•é¡Œ:")
        for issue in content_issues:
            print(f"  - {issue}")
    
    # æª¢æŸ¥æ–‡æª”å¤§å°
    print("\nğŸ“ æ–‡æª”å¤§å°çµ±è¨ˆ:")
    total_size = 0
    for doc in existing_docs:
        doc_path = docs_dir / doc
        size = doc_path.stat().st_size
        total_size += size
        print(f"  {doc}: {size:,} bytes")
    
    print(f"\nç¸½å¤§å°: {total_size:,} bytes ({total_size/1024:.1f} KB)")
    
    # é©—è­‰çµæœ
    if not missing_docs and not content_issues:
        print("\nâœ… æ–‡æª”é©—è­‰é€šéï¼æ‰€æœ‰å¿…éœ€æ–‡æª”éƒ½å­˜åœ¨ä¸”å…§å®¹å®Œæ•´ã€‚")
        return True
    else:
        print("\nâŒ æ–‡æª”é©—è­‰å¤±æ•—ï¼è«‹ä¿®å¾©ä¸Šè¿°å•é¡Œã€‚")
        return False

def generate_doc_summary():
    """ç”Ÿæˆæ–‡æª”æ‘˜è¦"""
    print("\nğŸ“‹ ç”Ÿæˆæ–‡æª”æ‘˜è¦...")
    
    docs_dir = Path("AImax/docs")
    summary = {
        "documentation_summary": {
            "generated_at": "2025-01-27T10:00:00Z",
            "total_documents": 0,
            "total_size_bytes": 0,
            "documents": []
        }
    }
    
    if docs_dir.exists():
        for doc_file in docs_dir.glob("*.md"):
            size = doc_file.stat().st_size
            summary["documentation_summary"]["documents"].append({
                "name": doc_file.name,
                "size_bytes": size,
                "size_kb": round(size/1024, 1)
            })
            summary["documentation_summary"]["total_size_bytes"] += size
        
        summary["documentation_summary"]["total_documents"] = len(summary["documentation_summary"]["documents"])
        summary["documentation_summary"]["total_size_kb"] = round(summary["documentation_summary"]["total_size_bytes"]/1024, 1)
    
    # ä¿å­˜æ‘˜è¦
    summary_file = docs_dir / "documentation_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æ–‡æª”æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
    return summary

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ AImax æ–‡æª”é©—è­‰å·¥å…·")
    print("=" * 50)
    
    # é©—è­‰æ–‡æª”
    validation_passed = validate_documentation()
    
    # ç”Ÿæˆæ‘˜è¦
    summary = generate_doc_summary()
    
    # è¼¸å‡ºçµæœ
    if validation_passed:
        print("\nğŸ‰ æ–‡æª”é©—è­‰å®Œæˆï¼æŠ€è¡“æ–‡æª”å·²æº–å‚™å°±ç·’ã€‚")
        sys.exit(0)
    else:
        print("\nâš ï¸  æ–‡æª”é©—è­‰ç™¼ç¾å•é¡Œï¼Œè«‹æª¢æŸ¥ä¸¦ä¿®å¾©ã€‚")
        sys.exit(1)

if __name__ == "__main__":
    main()