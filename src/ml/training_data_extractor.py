#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¨“ç·´æ•¸æ“šæå–å™¨ - å¾æ­·å²è³‡æ–™åº«æå–é©åˆæ©Ÿå™¨å­¸ç¿’çš„è¨“ç·´æ•¸æ“š
"""

import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import sqlite3

from ..data.historical_data_manager import create_historical_manager
from ..data.technical_indicators import create_technical_calculator

logger = logging.getLogger(__name__)

class TrainingDataExtractor:
    """è¨“ç·´æ•¸æ“šæå–å™¨"""
    
    def __init__(self, db_path: str = "data/market_history.db"):
        """
        åˆå§‹åŒ–è¨“ç·´æ•¸æ“šæå–å™¨
        
        Args:
            db_path: æ­·å²æ•¸æ“šåº«è·¯å¾‘
        """
        self.db_path = Path(db_path)
        self.historical_manager = create_historical_manager(str(db_path))
        self.technical_calculator = create_technical_calculator()
        
        # ç‰¹å¾µé…ç½®
        self.feature_config = {
            'price_features': ['open', 'high', 'low', 'close', 'volume'],
            'technical_features': [
                'rsi_14', 'rsi_7', 'rsi_21',
                'sma_5', 'sma_10', 'sma_20', 'sma_50',
                'ema_12', 'ema_26',
                'macd', 'macd_signal', 'macd_histogram',
                'bb_upper', 'bb_middle', 'bb_lower', 'bb_width',
                'volume_sma_20', 'volume_ratio'
            ],
            'derived_features': [
                'price_change_1', 'price_change_5', 'price_change_15',
                'volume_change_1', 'volume_change_5',
                'volatility_5', 'volatility_20',
                'momentum_5', 'momentum_10'
            ]
        }
        
        logger.info("ğŸ”§ è¨“ç·´æ•¸æ“šæå–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def extract_training_dataset(self, 
                                     market: str = "btctwd",
                                     days: int = 30,
                                     timeframe: str = "5m") -> Optional[pd.DataFrame]:
        """
        æå–å®Œæ•´çš„è¨“ç·´æ•¸æ“šé›†
        
        Args:
            market: äº¤æ˜“å°
            days: æå–å¤©æ•¸
            timeframe: æ™‚é–“æ¡†æ¶
            
        Returns:
            åŒ…å«ç‰¹å¾µå’Œæ¨™ç±¤çš„å®Œæ•´æ•¸æ“šé›†
        """
        try:
            logger.info(f"ğŸš€ é–‹å§‹æå–è¨“ç·´æ•¸æ“šé›†: {market}, {days}å¤©, {timeframe}")
            
            # æ­¥é©Ÿ1: ç¢ºä¿æ­·å²æ•¸æ“šå®Œæ•´æ€§
            await self.historical_manager.ensure_historical_data(market, [timeframe])
            
            # æ­¥é©Ÿ2: ç²å–åŸå§‹æ­·å²æ•¸æ“š
            raw_data = self._get_raw_historical_data(market, timeframe, days)
            if raw_data is None or raw_data.empty:
                logger.error("âŒ ç„¡æ³•ç²å–åŸå§‹æ­·å²æ•¸æ“š")
                return None
            
            # æ­¥é©Ÿ3: è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
            enhanced_data = self._calculate_technical_features(raw_data)
            
            # æ­¥é©Ÿ4: ç”Ÿæˆè¡ç”Ÿç‰¹å¾µ
            feature_data = self._generate_derived_features(enhanced_data)
            
            # æ­¥é©Ÿ5: å‰µå»ºè¨“ç·´æ¨™ç±¤
            labeled_data = self._create_training_labels(feature_data)
            
            # æ­¥é©Ÿ6: æ•¸æ“šæ¸…æ´—å’Œé©—è­‰
            clean_data = self._clean_and_validate_data(labeled_data)
            
            logger.info(f"âœ… è¨“ç·´æ•¸æ“šé›†æå–å®Œæˆ: {len(clean_data)} æ¢è¨˜éŒ„")
            return clean_data
            
        except Exception as e:
            logger.error(f"âŒ æå–è¨“ç·´æ•¸æ“šé›†å¤±æ•—: {e}")
            return None
    
    def _get_raw_historical_data(self, market: str, timeframe: str, days: int) -> Optional[pd.DataFrame]:
        """ç²å–åŸå§‹æ­·å²æ•¸æ“š"""
        try:
            # è¨ˆç®—éœ€è¦çš„æ•¸æ“šé‡
            periods_per_day = {
                '1m': 1440,
                '5m': 288,
                '1h': 24,
                '1d': 1
            }
            
            limit = periods_per_day.get(timeframe, 288) * days
            
            # å¾æ•¸æ“šåº«ç²å–æ•¸æ“š
            df = self.historical_manager.get_historical_data(market, timeframe, limit)
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ ç„¡æ³•å¾æ•¸æ“šåº«ç²å– {market} {timeframe} æ•¸æ“š")
                return None
            
            logger.info(f"ğŸ“Š ç²å–åŸå§‹æ•¸æ“š: {len(df)} æ¢è¨˜éŒ„")
            return df
            
        except Exception as e:
            logger.error(f"âŒ ç²å–åŸå§‹æ­·å²æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    def _calculate_technical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ç‰¹å¾µ"""
        try:
            logger.info("ğŸ”¢ è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ç‰¹å¾µ...")
            
            enhanced_df = df.copy()
            
            # RSIæŒ‡æ¨™
            for period in [7, 14, 21]:
                enhanced_df[f'rsi_{period}'] = self._calculate_rsi(df['close'], period)
            
            # ç§»å‹•å¹³å‡ç·š
            for period in [5, 10, 20, 50]:
                enhanced_df[f'sma_{period}'] = df['close'].rolling(period).mean()
            
            # æŒ‡æ•¸ç§»å‹•å¹³å‡ç·š
            enhanced_df['ema_12'] = df['close'].ewm(span=12).mean()
            enhanced_df['ema_26'] = df['close'].ewm(span=26).mean()
            
            # MACD
            macd_line = enhanced_df['ema_12'] - enhanced_df['ema_26']
            macd_signal = macd_line.ewm(span=9).mean()
            enhanced_df['macd'] = macd_line
            enhanced_df['macd_signal'] = macd_signal
            enhanced_df['macd_histogram'] = macd_line - macd_signal
            
            # å¸ƒæ—å¸¶
            sma_20 = enhanced_df['sma_20']
            std_20 = df['close'].rolling(20).std()
            enhanced_df['bb_upper'] = sma_20 + (std_20 * 2)
            enhanced_df['bb_middle'] = sma_20
            enhanced_df['bb_lower'] = sma_20 - (std_20 * 2)
            enhanced_df['bb_width'] = enhanced_df['bb_upper'] - enhanced_df['bb_lower']
            
            # æˆäº¤é‡æŒ‡æ¨™
            enhanced_df['volume_sma_20'] = df['volume'].rolling(20).mean()
            enhanced_df['volume_ratio'] = df['volume'] / enhanced_df['volume_sma_20']
            
            logger.info(f"âœ… æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å®Œæˆï¼Œæ–°å¢ {len(enhanced_df.columns) - len(df.columns)} å€‹ç‰¹å¾µ")
            return enhanced_df
            
        except Exception as e:
            logger.error(f"âŒ è¨ˆç®—æŠ€è¡“æŒ‡æ¨™å¤±æ•—: {e}")
            return df
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è¨ˆç®—RSIæŒ‡æ¨™"""
        try:
            delta = prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            return rsi
        except Exception as e:
            logger.error(f"âŒ è¨ˆç®—RSIå¤±æ•—: {e}")
            return pd.Series(index=prices.index, dtype=float)
    
    def _generate_derived_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç”Ÿæˆè¡ç”Ÿç‰¹å¾µ"""
        try:
            logger.info("ğŸ”„ ç”Ÿæˆè¡ç”Ÿç‰¹å¾µ...")
            
            enhanced_df = df.copy()
            
            # åƒ¹æ ¼è®ŠåŒ–ç‰¹å¾µ
            for period in [1, 5, 15]:
                enhanced_df[f'price_change_{period}'] = df['close'].pct_change(period)
            
            # æˆäº¤é‡è®ŠåŒ–ç‰¹å¾µ
            for period in [1, 5]:
                enhanced_df[f'volume_change_{period}'] = df['volume'].pct_change(period)
            
            # æ³¢å‹•ç‡ç‰¹å¾µ
            for period in [5, 20]:
                returns = df['close'].pct_change()
                enhanced_df[f'volatility_{period}'] = returns.rolling(period).std()
            
            # å‹•é‡ç‰¹å¾µ
            for period in [5, 10]:
                enhanced_df[f'momentum_{period}'] = df['close'] / df['close'].shift(period) - 1
            
            # åƒ¹æ ¼ä½ç½®ç‰¹å¾µ
            enhanced_df['price_position_bb'] = (df['close'] - enhanced_df['bb_lower']) / (enhanced_df['bb_upper'] - enhanced_df['bb_lower'])
            enhanced_df['price_vs_sma20'] = df['close'] / enhanced_df['sma_20'] - 1
            
            # æ™‚é–“ç‰¹å¾µ
            enhanced_df['hour'] = df['timestamp'].dt.hour
            enhanced_df['day_of_week'] = df['timestamp'].dt.dayofweek
            enhanced_df['is_weekend'] = (df['timestamp'].dt.dayofweek >= 5).astype(int)
            
            logger.info(f"âœ… è¡ç”Ÿç‰¹å¾µç”Ÿæˆå®Œæˆï¼Œæ–°å¢ {len(enhanced_df.columns) - len(df.columns)} å€‹ç‰¹å¾µ")
            return enhanced_df
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆè¡ç”Ÿç‰¹å¾µå¤±æ•—: {e}")
            return df
    
    def _create_training_labels(self, df: pd.DataFrame) -> pd.DataFrame:
        """å‰µå»ºè¨“ç·´æ¨™ç±¤"""
        try:
            logger.info("ğŸ·ï¸ å‰µå»ºè¨“ç·´æ¨™ç±¤...")
            
            labeled_df = df.copy()
            
            # æœªä¾†æ”¶ç›Šç‡ï¼ˆç”¨æ–¼å›æ­¸ï¼‰
            for horizon in [1, 3, 5, 10]:
                labeled_df[f'future_return_{horizon}'] = df['close'].shift(-horizon) / df['close'] - 1
            
            # äº¤æ˜“ä¿¡è™Ÿï¼ˆç”¨æ–¼åˆ†é¡ï¼‰
            future_return_5 = labeled_df['future_return_5']
            
            # ä¸‰åˆ†é¡ï¼šè²·å…¥(1)ã€æŒæœ‰(0)ã€è³£å‡º(-1)
            buy_threshold = 0.002   # 0.2%
            sell_threshold = -0.002 # -0.2%
            
            labeled_df['signal_3class'] = np.where(
                future_return_5 > buy_threshold, 1,
                np.where(future_return_5 < sell_threshold, -1, 0)
            )
            
            # äºŒåˆ†é¡ï¼šè²·å…¥(1)ã€ä¸è²·å…¥(0)
            labeled_df['signal_binary'] = (future_return_5 > buy_threshold).astype(int)
            
            # é¢¨éšªæ¨™ç±¤
            volatility_5 = labeled_df['volatility_5']
            high_vol_threshold = volatility_5.quantile(0.8)
            labeled_df['high_risk'] = (volatility_5 > high_vol_threshold).astype(int)
            
            logger.info("âœ… è¨“ç·´æ¨™ç±¤å‰µå»ºå®Œæˆ")
            return labeled_df
            
        except Exception as e:
            logger.error(f"âŒ å‰µå»ºè¨“ç·´æ¨™ç±¤å¤±æ•—: {e}")
            return df
    
    def _clean_and_validate_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ•¸æ“šæ¸…æ´—å’Œé©—è­‰"""
        try:
            logger.info("ğŸ§¹ æ•¸æ“šæ¸…æ´—å’Œé©—è­‰...")
            
            # ç§»é™¤ç„¡æ•ˆæ•¸æ“š
            clean_df = df.copy()
            
            # ç§»é™¤åŒ…å«æœªä¾†æ•¸æ“šçš„æœ€å¾Œå¹¾è¡Œ
            clean_df = clean_df[:-10]
            
            # ç§»é™¤ç„¡é™å€¼å’ŒNaN
            clean_df = clean_df.replace([np.inf, -np.inf], np.nan)
            
            # è¨˜éŒ„æ¸…æ´—å‰çš„æ•¸æ“šé‡
            original_count = len(clean_df)
            
            # ç§»é™¤åŒ…å«NaNçš„è¡Œ
            clean_df = clean_df.dropna()
            
            # ç§»é™¤ç•°å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰
            numeric_columns = clean_df.select_dtypes(include=[np.number]).columns
            for col in numeric_columns:
                if col not in ['signal_3class', 'signal_binary', 'high_risk', 'hour', 'day_of_week', 'is_weekend']:
                    Q1 = clean_df[col].quantile(0.01)
                    Q3 = clean_df[col].quantile(0.99)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    clean_df = clean_df[(clean_df[col] >= lower_bound) & (clean_df[col] <= upper_bound)]
            
            cleaned_count = len(clean_df)
            removed_count = original_count - cleaned_count
            
            logger.info(f"âœ… æ•¸æ“šæ¸…æ´—å®Œæˆ: ç§»é™¤ {removed_count} æ¢ç•°å¸¸æ•¸æ“šï¼Œä¿ç•™ {cleaned_count} æ¢")
            
            # æ•¸æ“šè³ªé‡å ±å‘Š
            self._generate_data_quality_report(clean_df)
            
            return clean_df
            
        except Exception as e:
            logger.error(f"âŒ æ•¸æ“šæ¸…æ´—å¤±æ•—: {e}")
            return df
    
    def _generate_data_quality_report(self, df: pd.DataFrame):
        """ç”Ÿæˆæ•¸æ“šè³ªé‡å ±å‘Š"""
        try:
            logger.info("ğŸ“Š ç”Ÿæˆæ•¸æ“šè³ªé‡å ±å‘Š...")
            
            # åŸºæœ¬çµ±è¨ˆ
            total_records = len(df)
            feature_count = len([col for col in df.columns if col not in ['timestamp']])
            
            # æ¨™ç±¤åˆ†ä½ˆ
            if 'signal_3class' in df.columns:
                signal_dist = df['signal_3class'].value_counts()
                logger.info(f"ä¿¡è™Ÿåˆ†ä½ˆ - è²·å…¥: {signal_dist.get(1, 0)}, æŒæœ‰: {signal_dist.get(0, 0)}, è³£å‡º: {signal_dist.get(-1, 0)}")
            
            # æ™‚é–“ç¯„åœ
            if 'timestamp' in df.columns:
                start_time = df['timestamp'].min()
                end_time = df['timestamp'].max()
                logger.info(f"æ™‚é–“ç¯„åœ: {start_time} åˆ° {end_time}")
            
            logger.info(f"ğŸ“ˆ æ•¸æ“šè³ªé‡å ±å‘Š: {total_records} æ¢è¨˜éŒ„, {feature_count} å€‹ç‰¹å¾µ")
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ•¸æ“šè³ªé‡å ±å‘Šå¤±æ•—: {e}")
    
    def get_feature_names(self) -> List[str]:
        """ç²å–æ‰€æœ‰ç‰¹å¾µåç¨±"""
        all_features = []
        all_features.extend(self.feature_config['price_features'])
        all_features.extend(self.feature_config['technical_features'])
        all_features.extend(self.feature_config['derived_features'])
        
        # æ·»åŠ é¡å¤–çš„è¡ç”Ÿç‰¹å¾µ
        all_features.extend([
            'price_position_bb', 'price_vs_sma20',
            'hour', 'day_of_week', 'is_weekend'
        ])
        
        return all_features
    
    def save_training_data(self, df: pd.DataFrame, filename: str = None) -> str:
        """ä¿å­˜è¨“ç·´æ•¸æ“š"""
        try:
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"training_data_{timestamp}.csv"
            
            output_path = Path("AImax/data") / filename
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            df.to_csv(output_path, index=False)
            
            logger.info(f"ğŸ’¾ è¨“ç·´æ•¸æ“šå·²ä¿å­˜: {output_path}")
            return str(output_path)
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è¨“ç·´æ•¸æ“šå¤±æ•—: {e}")
            return ""


# å‰µå»ºå…¨å±€å¯¦ä¾‹
def create_training_data_extractor(db_path: str = "data/market_history.db") -> TrainingDataExtractor:
    """å‰µå»ºè¨“ç·´æ•¸æ“šæå–å™¨å¯¦ä¾‹"""
    return TrainingDataExtractor(db_path)


# æ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    import asyncio
    
    async def test_training_data_extractor():
        """æ¸¬è©¦è¨“ç·´æ•¸æ“šæå–å™¨"""
        print("ğŸ§ª æ¸¬è©¦è¨“ç·´æ•¸æ“šæå–å™¨...")
        
        extractor = create_training_data_extractor()
        
        try:
            # æå–è¨“ç·´æ•¸æ“š
            training_data = await extractor.extract_training_dataset(
                market="btctwd",
                days=7,  # æ¸¬è©¦ç”¨è¼ƒå°‘å¤©æ•¸
                timeframe="5m"
            )
            
            if training_data is not None:
                print(f"âœ… è¨“ç·´æ•¸æ“šæå–æˆåŠŸ: {len(training_data)} æ¢è¨˜éŒ„")
                print(f"ğŸ“Š ç‰¹å¾µæ•¸é‡: {len(training_data.columns)}")
                print(f"ğŸ·ï¸ æ¨™ç±¤åˆ—: {[col for col in training_data.columns if 'signal' in col or 'future' in col or 'risk' in col]}")
                
                # ä¿å­˜æ•¸æ“š
                saved_path = extractor.save_training_data(training_data, "test_training_data.csv")
                print(f"ğŸ’¾ æ•¸æ“šå·²ä¿å­˜åˆ°: {saved_path}")
                
            else:
                print("âŒ è¨“ç·´æ•¸æ“šæå–å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
    
    # é‹è¡Œæ¸¬è©¦
    asyncio.run(test_training_data_extractor())