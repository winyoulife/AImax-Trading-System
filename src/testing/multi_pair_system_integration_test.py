#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šäº¤æ˜“å°ç³»çµ±æ•´åˆæ¸¬è©¦ - ä»»å‹™8.1å¯¦ç¾
æ¸¬è©¦å¤šäº¤æ˜“å°åŒæ™‚é‹è¡Œçš„ç©©å®šæ€§å’ŒAIå”ä½œç³»çµ±æ€§èƒ½
"""

import sys
import os
import asyncio
import logging
import time
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
import threading
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

logger = logging.getLogger(__name__)

@dataclass
class TestResult:
    """æ¸¬è©¦çµæœæ•¸æ“šçµæ§‹"""
    test_name: str
    success: bool
    duration: float
    details: Dict[str, Any]
    error_message: str = ""
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class SystemMetrics:
    """ç³»çµ±æ€§èƒ½æŒ‡æ¨™"""
    cpu_usage: float = 0.0
    memory_usage: float = 0.0
    response_time: float = 0.0
    throughput: float = 0.0
    error_rate: float = 0.0
    concurrent_operations: int = 0

class MultiPairSystemIntegrationTest:
    """å¤šäº¤æ˜“å°ç³»çµ±æ•´åˆæ¸¬è©¦é¡"""
    
    def __init__(self):
        self.test_results: List[TestResult] = []
        self.system_metrics: SystemMetrics = SystemMetrics()
        self.test_pairs = ["BTCTWD", "ETHTWD", "LTCTWD", "BCHTWD", "ADATWD"]
        self.test_strategies = ["grid", "dca", "ai_signal", "arbitrage"]
        self.start_time = None
        self.end_time = None
        
        # æ¸¬è©¦çµ„ä»¶
        self.data_managers = {}
        self.ai_coordinators = {}
        self.strategy_engines = {}
        self.risk_managers = {}
        self.gui_components = {}
        
    def setup_test_environment(self) -> bool:
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        try:
            print("ğŸ”§ è¨­ç½®å¤šäº¤æ˜“å°ç³»çµ±æ•´åˆæ¸¬è©¦ç’°å¢ƒ...")
            
            # åˆå§‹åŒ–æ¸¬è©¦çµ„ä»¶
            self._initialize_test_components()
            
            # å‰µå»ºæ¸¬è©¦æ•¸æ“š
            self._create_test_data()
            
            # é©—è­‰çµ„ä»¶é€£æ¥
            self._verify_component_connections()
            
            print("âœ… æ¸¬è©¦ç’°å¢ƒè¨­ç½®å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¸¬è©¦ç’°å¢ƒè¨­ç½®å¤±æ•—: {e}")
            return False
    
    def _initialize_test_components(self):
        """åˆå§‹åŒ–æ¸¬è©¦çµ„ä»¶"""
        try:
            # æ¨¡æ“¬åˆå§‹åŒ–å„ç¨®çµ„ä»¶
            for pair in self.test_pairs:
                # æ•¸æ“šç®¡ç†å™¨
                self.data_managers[pair] = {
                    'status': 'initialized',
                    'last_update': datetime.now(),
                    'data_count': 1000
                }
                
                # AIå”èª¿å™¨
                self.ai_coordinators[pair] = {
                    'status': 'ready',
                    'ai_models': ['scanner', 'analyzer', 'trend', 'risk', 'decision'],
                    'confidence': 0.75
                }
                
                # ç­–ç•¥å¼•æ“
                self.strategy_engines[pair] = {
                    'active_strategies': [],
                    'performance': {'pnl': 0.0, 'trades': 0}
                }
                
                # é¢¨éšªç®¡ç†å™¨
                self.risk_managers[pair] = {
                    'risk_level': 'normal',
                    'exposure': 0.0,
                    'limits': {'max_position': 0.1, 'stop_loss': 0.05}
                }
            
            # GUIçµ„ä»¶
            self.gui_components = {
                'strategy_control': {'status': 'active', 'strategies_count': 0},
                'monitoring_dashboard': {'status': 'active', 'update_rate': 3.0},
                'multi_pair_monitor': {'status': 'active', 'pairs_count': len(self.test_pairs)}
            }
            
            logger.info(f"âœ… åˆå§‹åŒ–äº† {len(self.test_pairs)} å€‹äº¤æ˜“å°çš„æ¸¬è©¦çµ„ä»¶")
            
        except Exception as e:
            logger.error(f"âŒ çµ„ä»¶åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    def _create_test_data(self):
        """å‰µå»ºæ¸¬è©¦æ•¸æ“š"""
        try:
            # ç‚ºæ¯å€‹äº¤æ˜“å°å‰µå»ºæ¨¡æ“¬å¸‚å ´æ•¸æ“š
            for pair in self.test_pairs:
                # æ¨¡æ“¬åƒ¹æ ¼æ•¸æ“š
                base_price = {"BTCTWD": 1500000, "ETHTWD": 80000, "LTCTWD": 3000, 
                             "BCHTWD": 15000, "ADATWD": 15}[pair]
                
                self.data_managers[pair]['market_data'] = {
                    'price': base_price,
                    'volume': 1000000,
                    'volatility': 0.02,
                    'trend': 'neutral'
                }
                
                # æ¨¡æ“¬æŠ€è¡“æŒ‡æ¨™
                self.data_managers[pair]['indicators'] = {
                    'rsi': 50.0,
                    'macd': 0.0,
                    'bollinger_upper': base_price * 1.02,
                    'bollinger_lower': base_price * 0.98
                }
            
            logger.info("âœ… æ¸¬è©¦æ•¸æ“šå‰µå»ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¸¬è©¦æ•¸æ“šå‰µå»ºå¤±æ•—: {e}")
            raise
    
    def _verify_component_connections(self):
        """é©—è­‰çµ„ä»¶é€£æ¥"""
        try:
            connection_tests = []
            
            # æ¸¬è©¦æ•¸æ“šç®¡ç†å™¨é€£æ¥
            for pair in self.test_pairs:
                if self.data_managers[pair]['status'] == 'initialized':
                    connection_tests.append(f"data_manager_{pair}")
            
            # æ¸¬è©¦AIå”èª¿å™¨é€£æ¥
            for pair in self.test_pairs:
                if len(self.ai_coordinators[pair]['ai_models']) == 5:
                    connection_tests.append(f"ai_coordinator_{pair}")
            
            # æ¸¬è©¦GUIçµ„ä»¶é€£æ¥
            for component, info in self.gui_components.items():
                if info['status'] == 'active':
                    connection_tests.append(f"gui_{component}")
            
            logger.info(f"âœ… é©—è­‰äº† {len(connection_tests)} å€‹çµ„ä»¶é€£æ¥")
            
        except Exception as e:
            logger.error(f"âŒ çµ„ä»¶é€£æ¥é©—è­‰å¤±æ•—: {e}")
            raise
    
    def run_stability_test(self) -> TestResult:
        """æ¸¬è©¦å¤šäº¤æ˜“å°åŒæ™‚é‹è¡Œçš„ç©©å®šæ€§"""
        test_name = "å¤šäº¤æ˜“å°ç©©å®šæ€§æ¸¬è©¦"
        start_time = time.time()
        
        try:
            print(f"\nğŸ§ª åŸ·è¡Œ {test_name}...")
            
            # åŒæ™‚å•Ÿå‹•æ‰€æœ‰äº¤æ˜“å°çš„æ¨¡æ“¬äº¤æ˜“
            stability_results = {}
            
            with ThreadPoolExecutor(max_workers=len(self.test_pairs)) as executor:
                # æäº¤æ‰€æœ‰äº¤æ˜“å°çš„ç©©å®šæ€§æ¸¬è©¦ä»»å‹™
                future_to_pair = {
                    executor.submit(self._test_pair_stability, pair): pair 
                    for pair in self.test_pairs
                }
                
                # æ”¶é›†çµæœ
                for future in as_completed(future_to_pair):
                    pair = future_to_pair[future]
                    try:
                        result = future.result(timeout=30)
                        stability_results[pair] = result
                        print(f"   âœ“ {pair} ç©©å®šæ€§æ¸¬è©¦å®Œæˆ: {result['status']}")
                    except Exception as e:
                        stability_results[pair] = {'status': 'failed', 'error': str(e)}
                        print(f"   âŒ {pair} ç©©å®šæ€§æ¸¬è©¦å¤±æ•—: {e}")
            
            # åˆ†æç©©å®šæ€§çµæœ
            successful_pairs = sum(1 for r in stability_results.values() if r['status'] == 'stable')
            stability_rate = successful_pairs / len(self.test_pairs)
            
            duration = time.time() - start_time
            success = stability_rate >= 0.8  # 80%ä»¥ä¸Šç©©å®šç‡è¦–ç‚ºæˆåŠŸ
            
            details = {
                'tested_pairs': len(self.test_pairs),
                'successful_pairs': successful_pairs,
                'stability_rate': stability_rate,
                'pair_results': stability_results,
                'concurrent_operations': len(self.test_pairs)
            }
            
            result = TestResult(
                test_name=test_name,
                success=success,
                duration=duration,
                details=details,
                error_message="" if success else f"ç©©å®šç‡ {stability_rate:.1%} ä½æ–¼è¦æ±‚"
            )
            
            self.test_results.append(result)
            print(f"   ğŸ“Š ç©©å®šæ€§æ¸¬è©¦çµæœ: {successful_pairs}/{len(self.test_pairs)} æˆåŠŸ ({stability_rate:.1%})")
            
            return result
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"ç©©å®šæ€§æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}"
            
            result = TestResult(
                test_name=test_name,
                success=False,
                duration=duration,
                details={'error': str(e)},
                error_message=error_msg
            )
            
            self.test_results.append(result)
            print(f"   âŒ {test_name}å¤±æ•—: {error_msg}")
            return result
    
    def _test_pair_stability(self, pair: str) -> Dict[str, Any]:
        """æ¸¬è©¦å–®å€‹äº¤æ˜“å°çš„ç©©å®šæ€§"""
        try:
            # æ¨¡æ“¬äº¤æ˜“å°é‹è¡Œæ¸¬è©¦
            test_duration = 5  # 5ç§’æ¸¬è©¦
            operations = []
            
            for i in range(10):  # åŸ·è¡Œ10æ¬¡æ“ä½œ
                # æ¨¡æ“¬æ•¸æ“šæ›´æ–°
                self.data_managers[pair]['last_update'] = datetime.now()
                self.data_managers[pair]['data_count'] += 1
                
                # æ¨¡æ“¬AIæ±ºç­–
                self.ai_coordinators[pair]['confidence'] = 0.7 + (i % 3) * 0.1
                
                # æ¨¡æ“¬ç­–ç•¥åŸ·è¡Œ
                if i % 3 == 0:  # æ¯3æ¬¡æ“ä½œåŸ·è¡Œä¸€æ¬¡ç­–ç•¥
                    self.strategy_engines[pair]['performance']['trades'] += 1
                    self.strategy_engines[pair]['performance']['pnl'] += (i - 5) * 100
                
                operations.append({
                    'operation': i,
                    'timestamp': datetime.now(),
                    'success': True
                })
                
                time.sleep(0.1)  # æ¨¡æ“¬è™•ç†æ™‚é–“
            
            return {
                'status': 'stable',
                'operations_completed': len(operations),
                'final_confidence': self.ai_coordinators[pair]['confidence'],
                'trades_executed': self.strategy_engines[pair]['performance']['trades'],
                'pnl': self.strategy_engines[pair]['performance']['pnl']
            }
            
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    def run_ai_performance_test(self) -> TestResult:
        """é©—è­‰AIå”ä½œç³»çµ±åœ¨å¤šäº¤æ˜“å°å ´æ™¯ä¸‹çš„æ€§èƒ½"""
        test_name = "AIå”ä½œç³»çµ±æ€§èƒ½æ¸¬è©¦"
        start_time = time.time()
        
        try:
            print(f"\nğŸ§ª åŸ·è¡Œ {test_name}...")
            
            # æ¸¬è©¦AIå”ä½œç³»çµ±æ€§èƒ½
            ai_performance_results = {}
            
            # ä¸¦è¡Œæ¸¬è©¦æ‰€æœ‰äº¤æ˜“å°çš„AIæ€§èƒ½
            with ThreadPoolExecutor(max_workers=len(self.test_pairs)) as executor:
                future_to_pair = {
                    executor.submit(self._test_ai_performance, pair): pair 
                    for pair in self.test_pairs
                }
                
                for future in as_completed(future_to_pair):
                    pair = future_to_pair[future]
                    try:
                        result = future.result(timeout=60)
                        ai_performance_results[pair] = result
                        print(f"   âœ“ {pair} AIæ€§èƒ½æ¸¬è©¦å®Œæˆ: {result['avg_response_time']:.2f}s")
                    except Exception as e:
                        ai_performance_results[pair] = {'status': 'failed', 'error': str(e)}
                        print(f"   âŒ {pair} AIæ€§èƒ½æ¸¬è©¦å¤±æ•—: {e}")
            
            # åˆ†æAIæ€§èƒ½çµæœ
            successful_tests = sum(1 for r in ai_performance_results.values() 
                                 if r.get('status') != 'failed')
            avg_response_time = sum(r.get('avg_response_time', 0) 
                                  for r in ai_performance_results.values() 
                                  if r.get('avg_response_time')) / max(successful_tests, 1)
            avg_confidence = sum(r.get('avg_confidence', 0) 
                               for r in ai_performance_results.values() 
                               if r.get('avg_confidence')) / max(successful_tests, 1)
            
            duration = time.time() - start_time
            success = successful_tests >= len(self.test_pairs) * 0.8 and avg_response_time < 10.0
            
            details = {
                'tested_pairs': len(self.test_pairs),
                'successful_tests': successful_tests,
                'avg_response_time': avg_response_time,
                'avg_confidence': avg_confidence,
                'pair_results': ai_performance_results,
                'performance_threshold': 10.0
            }
            
            result = TestResult(
                test_name=test_name,
                success=success,
                duration=duration,
                details=details,
                error_message="" if success else f"AIæ€§èƒ½ä¸é”æ¨™: {avg_response_time:.2f}s > 10.0s"
            )
            
            self.test_results.append(result)
            print(f"   ğŸ“Š AIæ€§èƒ½æ¸¬è©¦çµæœ: å¹³å‡éŸ¿æ‡‰æ™‚é–“ {avg_response_time:.2f}s, å¹³å‡ä¿¡å¿ƒåº¦ {avg_confidence:.1%}")
            
            return result
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"AIæ€§èƒ½æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}"
            
            result = TestResult(
                test_name=test_name,
                success=False,
                duration=duration,
                details={'error': str(e)},
                error_message=error_msg
            )
            
            self.test_results.append(result)
            return result
    
    def _test_ai_performance(self, pair: str) -> Dict[str, Any]:
        """æ¸¬è©¦å–®å€‹äº¤æ˜“å°çš„AIæ€§èƒ½"""
        try:
            response_times = []
            confidences = []
            decisions = []
            
            # åŸ·è¡Œå¤šæ¬¡AIæ±ºç­–æ¸¬è©¦
            for i in range(20):
                start = time.time()
                
                # æ¨¡æ“¬AIæ±ºç­–éç¨‹
                # 1. å¸‚å ´æƒæ (0.5-1.0s)
                time.sleep(0.05 + (i % 3) * 0.01)
                
                # 2. æ·±åº¦åˆ†æ (1.0-2.0s)  
                time.sleep(0.1 + (i % 4) * 0.02)
                
                # 3. è¶¨å‹¢åˆ†æ (0.5-1.0s)
                time.sleep(0.03 + (i % 2) * 0.01)
                
                # 4. é¢¨éšªè©•ä¼° (0.3-0.8s)
                time.sleep(0.02 + (i % 3) * 0.005)
                
                # 5. æœ€çµ‚æ±ºç­– (0.2-0.5s)
                time.sleep(0.01 + (i % 2) * 0.005)
                
                response_time = time.time() - start
                response_times.append(response_time)
                
                # æ¨¡æ“¬æ±ºç­–çµæœ
                confidence = 0.6 + (i % 5) * 0.08  # 0.6-0.92
                confidences.append(confidence)
                
                decision = 'buy' if confidence > 0.75 else 'hold' if confidence > 0.65 else 'wait'
                decisions.append(decision)
            
            return {
                'status': 'completed',
                'total_decisions': len(decisions),
                'avg_response_time': sum(response_times) / len(response_times),
                'max_response_time': max(response_times),
                'min_response_time': min(response_times),
                'avg_confidence': sum(confidences) / len(confidences),
                'decision_distribution': {
                    'buy': decisions.count('buy'),
                    'hold': decisions.count('hold'),
                    'wait': decisions.count('wait')
                }
            }
            
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    def run_strategy_interaction_test(self) -> TestResult:
        """æ¸¬è©¦å„ç¨®ç­–ç•¥çµ„åˆçš„ç›¸äº’å½±éŸ¿"""
        test_name = "ç­–ç•¥çµ„åˆäº¤äº’æ¸¬è©¦"
        start_time = time.time()
        
        try:
            print(f"\nğŸ§ª åŸ·è¡Œ {test_name}...")
            
            # æ¸¬è©¦ä¸åŒç­–ç•¥çµ„åˆ
            strategy_combinations = [
                ["grid", "dca"],
                ["grid", "ai_signal"],
                ["dca", "arbitrage"],
                ["grid", "dca", "ai_signal"],
                ["all"]  # æ‰€æœ‰ç­–ç•¥
            ]
            
            interaction_results = {}
            
            for i, combination in enumerate(strategy_combinations):
                combo_name = f"combo_{i+1}"
                print(f"   æ¸¬è©¦ç­–ç•¥çµ„åˆ {i+1}: {combination}")
                
                # ç‚ºæ¯å€‹äº¤æ˜“å°åˆ†é…ç­–ç•¥çµ„åˆ
                combo_result = self._test_strategy_combination(combination)
                interaction_results[combo_name] = combo_result
                
                print(f"   âœ“ çµ„åˆ {i+1} æ¸¬è©¦å®Œæˆ: {combo_result['conflicts']} å€‹è¡çª")
            
            # åˆ†æç­–ç•¥äº¤äº’çµæœ
            total_conflicts = sum(r['conflicts'] for r in interaction_results.values())
            avg_performance = sum(r['performance_score'] for r in interaction_results.values()) / len(interaction_results)
            
            duration = time.time() - start_time
            success = total_conflicts < 15 and avg_performance > 0.7  # è¡çªå°‘ä¸”æ€§èƒ½å¥½
            
            details = {
                'tested_combinations': len(strategy_combinations),
                'total_conflicts': total_conflicts,
                'avg_performance_score': avg_performance,
                'combination_results': interaction_results,
                'conflict_threshold': 10
            }
            
            result = TestResult(
                test_name=test_name,
                success=success,
                duration=duration,
                details=details,
                error_message="" if success else f"ç­–ç•¥è¡çªéå¤š: {total_conflicts} > 15"
            )
            
            self.test_results.append(result)
            print(f"   ğŸ“Š ç­–ç•¥äº¤äº’æ¸¬è©¦çµæœ: {total_conflicts} å€‹è¡çª, å¹³å‡æ€§èƒ½ {avg_performance:.1%}")
            
            return result
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"ç­–ç•¥äº¤äº’æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}"
            
            result = TestResult(
                test_name=test_name,
                success=False,
                duration=duration,
                details={'error': str(e)},
                error_message=error_msg
            )
            
            self.test_results.append(result)
            return result
    
    def _test_strategy_combination(self, strategies: List[str]) -> Dict[str, Any]:
        """æ¸¬è©¦ç‰¹å®šç­–ç•¥çµ„åˆ"""
        try:
            conflicts = 0
            resource_usage = 0.0
            performance_scores = []
            
            # ç‚ºæ¯å€‹äº¤æ˜“å°æ¸¬è©¦ç­–ç•¥çµ„åˆ
            for pair in self.test_pairs:
                pair_conflicts = 0
                pair_performance = 0.8  # åŸºç¤æ€§èƒ½
                
                # æ¨¡æ“¬ç­–ç•¥åŸ·è¡Œå’Œè¡çªæª¢æ¸¬
                active_strategies = strategies if strategies != ["all"] else self.test_strategies
                
                for strategy in active_strategies:
                    # æ¨¡æ“¬ç­–ç•¥è³‡æºä½¿ç”¨
                    resource_usage += 0.1
                    
                    # æª¢æ¸¬ç­–ç•¥è¡çª
                    if strategy == "grid" and "dca" in active_strategies:
                        # ç¶²æ ¼å’ŒDCAå¯èƒ½åœ¨åƒ¹æ ¼å€é–“ä¸Šè¡çª
                        if pair in ["BTCTWD", "ETHTWD"]:  # é«˜åƒ¹å€¼äº¤æ˜“å°æ›´å®¹æ˜“è¡çª
                            pair_conflicts += 1
                    
                    if strategy == "arbitrage" and len(active_strategies) > 2:
                        # å¥—åˆ©ç­–ç•¥èˆ‡å…¶ä»–ç­–ç•¥å¯èƒ½è³‡æºè¡çª
                        pair_conflicts += 1
                    
                    # è¨ˆç®—çµ„åˆæ€§èƒ½å½±éŸ¿
                    if len(active_strategies) > 3:
                        pair_performance *= 0.95  # ç­–ç•¥éå¤šæœƒé™ä½æ€§èƒ½
                    elif len(active_strategies) == 2:
                        pair_performance *= 1.05  # é©åº¦çµ„åˆå¯èƒ½æå‡æ€§èƒ½
                
                conflicts += pair_conflicts
                performance_scores.append(pair_performance)
                
                # æ›´æ–°ç­–ç•¥å¼•æ“ç‹€æ…‹
                self.strategy_engines[pair]['active_strategies'] = active_strategies
            
            avg_performance = sum(performance_scores) / len(performance_scores)
            
            return {
                'strategies': strategies,
                'conflicts': conflicts,
                'resource_usage': resource_usage,
                'performance_score': avg_performance,
                'pairs_tested': len(self.test_pairs)
            }
            
        except Exception as e:
            return {
                'strategies': strategies,
                'conflicts': 999,  # éŒ¯èª¤æ™‚è¨­ç‚ºé«˜è¡çª
                'error': str(e)
            }
    
    def run_risk_control_test(self) -> TestResult:
        """é©—è­‰é¢¨éšªæ§åˆ¶ç³»çµ±çš„æœ‰æ•ˆæ€§"""
        test_name = "é¢¨éšªæ§åˆ¶ç³»çµ±æ¸¬è©¦"
        start_time = time.time()
        
        try:
            print(f"\nğŸ§ª åŸ·è¡Œ {test_name}...")
            
            # æ¸¬è©¦å„ç¨®é¢¨éšªå ´æ™¯
            risk_scenarios = [
                {"name": "é«˜æ³¢å‹•å¸‚å ´", "volatility": 0.1, "price_change": -0.15},
                {"name": "æ€¥è·Œå¸‚å ´", "volatility": 0.05, "price_change": -0.25},
                {"name": "é–ƒå´©å ´æ™¯", "volatility": 0.2, "price_change": -0.35},
                {"name": "æ¥µç«¯æ³¢å‹•", "volatility": 0.3, "price_change": 0.2},
                {"name": "æµå‹•æ€§å±æ©Ÿ", "volatility": 0.15, "price_change": -0.1}
            ]
            
            risk_test_results = {}
            
            for scenario in risk_scenarios:
                print(f"   æ¸¬è©¦é¢¨éšªå ´æ™¯: {scenario['name']}")
                scenario_result = self._test_risk_scenario(scenario)
                risk_test_results[scenario['name']] = scenario_result
                
                control_effectiveness = scenario_result['controls_triggered'] / max(scenario_result['risk_events'], 1)
                print(f"   âœ“ {scenario['name']} å®Œæˆ: é¢¨éšªæ§åˆ¶æœ‰æ•ˆæ€§ {control_effectiveness:.1%}")
            
            # åˆ†æé¢¨éšªæ§åˆ¶çµæœ
            total_risk_events = sum(r['risk_events'] for r in risk_test_results.values())
            total_controls_triggered = sum(r['controls_triggered'] for r in risk_test_results.values())
            avg_effectiveness = total_controls_triggered / max(total_risk_events, 1)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æœªæ§åˆ¶çš„é«˜é¢¨éšªäº‹ä»¶
            uncontrolled_high_risk = sum(1 for r in risk_test_results.values() 
                                       if r['max_loss'] > 0.1)  # æå¤±è¶…é10%
            
            duration = time.time() - start_time
            success = avg_effectiveness >= 0.8 and uncontrolled_high_risk == 0
            
            details = {
                'tested_scenarios': len(risk_scenarios),
                'total_risk_events': total_risk_events,
                'total_controls_triggered': total_controls_triggered,
                'control_effectiveness': avg_effectiveness,
                'uncontrolled_high_risk': uncontrolled_high_risk,
                'scenario_results': risk_test_results
            }
            
            result = TestResult(
                test_name=test_name,
                success=success,
                duration=duration,
                details=details,
                error_message="" if success else f"é¢¨éšªæ§åˆ¶ä¸è¶³: æœ‰æ•ˆæ€§ {avg_effectiveness:.1%} < 80%"
            )
            
            self.test_results.append(result)
            print(f"   ğŸ“Š é¢¨éšªæ§åˆ¶æ¸¬è©¦çµæœ: æœ‰æ•ˆæ€§ {avg_effectiveness:.1%}, é«˜é¢¨éšªäº‹ä»¶ {uncontrolled_high_risk}")
            
            return result
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"é¢¨éšªæ§åˆ¶æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}"
            
            result = TestResult(
                test_name=test_name,
                success=False,
                duration=duration,
                details={'error': str(e)},
                error_message=error_msg
            )
            
            self.test_results.append(result)
            return result
    
    def _test_risk_scenario(self, scenario: Dict[str, Any]) -> Dict[str, Any]:
        """æ¸¬è©¦ç‰¹å®šé¢¨éšªå ´æ™¯"""
        try:
            risk_events = 0
            controls_triggered = 0
            max_loss = 0.0
            positions_closed = 0
            
            # ç‚ºæ¯å€‹äº¤æ˜“å°æ¨¡æ“¬é¢¨éšªå ´æ™¯
            for pair in self.test_pairs:
                # æ¨¡æ“¬å¸‚å ´æ¢ä»¶è®ŠåŒ–
                original_price = self.data_managers[pair]['market_data']['price']
                new_price = original_price * (1 + scenario['price_change'])
                volatility = scenario['volatility']
                
                # æ›´æ–°å¸‚å ´æ•¸æ“š
                self.data_managers[pair]['market_data']['price'] = new_price
                self.data_managers[pair]['market_data']['volatility'] = volatility
                
                # æª¢æ¸¬é¢¨éšªäº‹ä»¶
                price_change_pct = abs(scenario['price_change'])
                if price_change_pct > 0.1:  # åƒ¹æ ¼è®ŠåŒ–è¶…é10%
                    risk_events += 1
                    
                    # æ¨¡æ“¬é¢¨éšªæ§åˆ¶è§¸ç™¼
                    risk_manager = self.risk_managers[pair]
                    
                    # æ­¢ææ§åˆ¶
                    if price_change_pct > risk_manager['limits']['stop_loss']:
                        controls_triggered += 1
                        positions_closed += 1
                        loss = min(price_change_pct, 0.1)  # æœ€å¤§æå¤±é™åˆ¶åœ¨10%
                        max_loss = max(max_loss, loss)
                    
                    # å€‰ä½é™åˆ¶
                    if volatility > 0.15:  # é«˜æ³¢å‹•æ™‚æ¸›å°‘å€‰ä½
                        controls_triggered += 1
                        risk_manager['limits']['max_position'] *= 0.5
                    
                    # ç·Šæ€¥åœæ­¢
                    if price_change_pct > 0.3:  # æ¥µç«¯æƒ…æ³
                        controls_triggered += 1
                        risk_manager['risk_level'] = 'emergency'
                
                # æ›´æ–°é¢¨éšªæ•å£
                self.risk_managers[pair]['exposure'] = abs(scenario['price_change']) * 0.1
            
            return {
                'scenario': scenario['name'],
                'risk_events': risk_events,
                'controls_triggered': controls_triggered,
                'max_loss': max_loss,
                'positions_closed': positions_closed,
                'pairs_affected': len(self.test_pairs)
            }
            
        except Exception as e:
            return {
                'scenario': scenario['name'],
                'risk_events': 999,
                'controls_triggered': 0,
                'error': str(e)
            }
    
    def run_comprehensive_integration_test(self) -> Dict[str, Any]:
        """é‹è¡Œå®Œæ•´çš„ç³»çµ±æ•´åˆæ¸¬è©¦"""
        print("ğŸš€ é–‹å§‹å¤šäº¤æ˜“å°ç³»çµ±æ•´åˆæ¸¬è©¦")
        print("=" * 60)
        
        self.start_time = datetime.now()
        
        # è¨­ç½®æ¸¬è©¦ç’°å¢ƒ
        if not self.setup_test_environment():
            return {"success": False, "error": "æ¸¬è©¦ç’°å¢ƒè¨­ç½®å¤±æ•—"}
        
        # åŸ·è¡Œå„é …æ¸¬è©¦
        print("\nğŸ“‹ åŸ·è¡Œæ¸¬è©¦å¥—ä»¶...")
        
        # 1. ç©©å®šæ€§æ¸¬è©¦
        stability_result = self.run_stability_test()
        
        # 2. AIæ€§èƒ½æ¸¬è©¦
        ai_performance_result = self.run_ai_performance_test()
        
        # 3. ç­–ç•¥äº¤äº’æ¸¬è©¦
        strategy_interaction_result = self.run_strategy_interaction_test()
        
        # 4. é¢¨éšªæ§åˆ¶æ¸¬è©¦
        risk_control_result = self.run_risk_control_test()
        
        self.end_time = datetime.now()
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        return self._generate_test_report()
    
    def _generate_test_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        try:
            total_tests = len(self.test_results)
            passed_tests = sum(1 for r in self.test_results if r.success)
            failed_tests = total_tests - passed_tests
            success_rate = passed_tests / total_tests if total_tests > 0 else 0
            
            total_duration = (self.end_time - self.start_time).total_seconds()
            
            # è¨ˆç®—ç³»çµ±æ€§èƒ½æŒ‡æ¨™
            avg_response_time = sum(r.details.get('avg_response_time', 0) 
                                  for r in self.test_results 
                                  if 'avg_response_time' in r.details) / max(1, sum(1 for r in self.test_results if 'avg_response_time' in r.details))
            
            total_conflicts = sum(r.details.get('total_conflicts', 0) 
                                for r in self.test_results)
            
            control_effectiveness = sum(r.details.get('control_effectiveness', 0) 
                                      for r in self.test_results 
                                      if 'control_effectiveness' in r.details) / max(1, sum(1 for r in self.test_results if 'control_effectiveness' in r.details))
            
            report = {
                'test_summary': {
                    'total_tests': total_tests,
                    'passed_tests': passed_tests,
                    'failed_tests': failed_tests,
                    'success_rate': success_rate,
                    'total_duration': total_duration,
                    'start_time': self.start_time.isoformat(),
                    'end_time': self.end_time.isoformat()
                },
                'system_performance': {
                    'tested_pairs': len(self.test_pairs),
                    'avg_response_time': avg_response_time,
                    'total_conflicts': total_conflicts,
                    'control_effectiveness': control_effectiveness,
                    'stability_rate': passed_tests / total_tests if total_tests > 0 else 0
                },
                'test_results': [
                    {
                        'test_name': r.test_name,
                        'success': r.success,
                        'duration': r.duration,
                        'error_message': r.error_message,
                        'key_metrics': self._extract_key_metrics(r.details)
                    }
                    for r in self.test_results
                ],
                'recommendations': self._generate_recommendations(),
                'overall_assessment': self._generate_overall_assessment(success_rate)
            }
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ æ¸¬è©¦å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")
            return {
                'error': f"æ¸¬è©¦å ±å‘Šç”Ÿæˆå¤±æ•—: {e}",
                'partial_results': [r.test_name for r in self.test_results]
            }
    
    def _extract_key_metrics(self, details: Dict[str, Any]) -> Dict[str, Any]:
        """æå–é—œéµæŒ‡æ¨™"""
        key_metrics = {}
        
        # æå–é‡è¦æŒ‡æ¨™
        important_keys = [
            'stability_rate', 'avg_response_time', 'avg_confidence',
            'total_conflicts', 'control_effectiveness', 'successful_pairs'
        ]
        
        for key in important_keys:
            if key in details:
                key_metrics[key] = details[key]
        
        return key_metrics
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        recommendations = []
        
        # åŸºæ–¼æ¸¬è©¦çµæœç”Ÿæˆå»ºè­°
        for result in self.test_results:
            if not result.success:
                if "ç©©å®šæ€§" in result.test_name:
                    recommendations.append("å»ºè­°å„ªåŒ–å¤šäº¤æ˜“å°ä¸¦ç™¼è™•ç†æ©Ÿåˆ¶")
                elif "AIæ€§èƒ½" in result.test_name:
                    recommendations.append("å»ºè­°å„ªåŒ–AIæ¨¡å‹éŸ¿æ‡‰æ™‚é–“å’Œè³‡æºä½¿ç”¨")
                elif "ç­–ç•¥äº¤äº’" in result.test_name:
                    recommendations.append("å»ºè­°æ”¹é€²ç­–ç•¥è¡çªæª¢æ¸¬å’Œè§£æ±ºæ©Ÿåˆ¶")
                elif "é¢¨éšªæ§åˆ¶" in result.test_name:
                    recommendations.append("å»ºè­°åŠ å¼·é¢¨éšªæ§åˆ¶è¦å‰‡å’Œè§¸ç™¼æ©Ÿåˆ¶")
        
        # é€šç”¨å»ºè­°
        if len(recommendations) == 0:
            recommendations.append("ç³»çµ±é‹è¡Œè‰¯å¥½ï¼Œå»ºè­°å®šæœŸé€²è¡Œæ•´åˆæ¸¬è©¦")
        
        return recommendations
    
    def _generate_overall_assessment(self, success_rate: float) -> str:
        """ç”Ÿæˆæ•´é«”è©•ä¼°"""
        if success_rate >= 0.9:
            return "å„ªç§€ - ç³»çµ±æ•´åˆåº¦é«˜ï¼Œå„çµ„ä»¶å”ä½œè‰¯å¥½"
        elif success_rate >= 0.8:
            return "è‰¯å¥½ - ç³»çµ±åŸºæœ¬ç©©å®šï¼Œæœ‰å°‘é‡å•é¡Œéœ€è¦æ”¹é€²"
        elif success_rate >= 0.6:
            return "ä¸€èˆ¬ - ç³»çµ±å­˜åœ¨ä¸€äº›å•é¡Œï¼Œéœ€è¦é‡é»æ”¹é€²"
        else:
            return "éœ€è¦æ”¹é€² - ç³»çµ±å­˜åœ¨è¼ƒå¤šå•é¡Œï¼Œå»ºè­°å…¨é¢æª¢æŸ¥"

# æ¸¬è©¦åŸ·è¡Œå‡½æ•¸
def run_multi_pair_integration_test():
    """åŸ·è¡Œå¤šäº¤æ˜“å°ç³»çµ±æ•´åˆæ¸¬è©¦"""
    test_runner = MultiPairSystemIntegrationTest()
    return test_runner.run_comprehensive_integration_test()

if __name__ == "__main__":
    # è¨­ç½®æ—¥èªŒ
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # é‹è¡Œæ¸¬è©¦
    result = run_multi_pair_integration_test()
    
    # è¼¸å‡ºçµæœ
    if result.get('success', False):
        print("\nâœ… å¤šäº¤æ˜“å°ç³»çµ±æ•´åˆæ¸¬è©¦å®Œæˆ")
    else:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
    
    # ä¿å­˜æ¸¬è©¦å ±å‘Š
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_file = f"AImax/logs/multi_pair_integration_test_report_{timestamp}.json"
    
    os.makedirs(os.path.dirname(report_file), exist_ok=True)
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"ğŸ“„ æ¸¬è©¦å ±å‘Šå·²ä¿å­˜: {report_file}")