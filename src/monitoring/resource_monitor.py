#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AImax è³‡æºä½¿ç”¨ç›£æ§å’Œå„ªåŒ–ç³»çµ± - ä»»å‹™10å¯¦ç¾
ç›£æ§GitHub Actionsä½¿ç”¨é‡ã€å­˜å„²ç©ºé–“ã€æ€§èƒ½æŒ‡æ¨™ä¸¦æä¾›å„ªåŒ–å»ºè­°
"""

import sys
import os
import json
import time
import logging
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from dataclasses import dataclass, field
import threading
import psutil
import shutil

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent.parent))

logger = logging.getLogger(__name__)

@dataclass
class ResourceUsage:
    """è³‡æºä½¿ç”¨æ•¸æ“šçµæ§‹"""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    disk_usage_gb: float
    disk_free_gb: float
    network_io_mb: float
    process_count: int
    file_count: int
    details: Dict[str, Any] = field(default_factory=dict)

@dataclass
class GitHubActionsUsage:
    """GitHub Actionsä½¿ç”¨é‡æ•¸æ“šçµæ§‹"""
    total_minutes_used: int
    total_minutes_quota: int
    usage_percentage: float
    remaining_minutes: int
    billing_cycle_start: datetime
    billing_cycle_end: datetime
    workflow_runs_count: int
    storage_usage_mb: float

class ResourceMonitor:
    """è³‡æºç›£æ§å™¨"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.monitoring_data: List[ResourceUsage] = []
        self.github_usage_data: List[GitHubActionsUsage] = []
        
        # ç›£æ§é…ç½®
        self.config = {
            'monitoring_interval': 60,  # 60ç§’ç›£æ§é–“éš”
            'data_retention_days': 30,  # ä¿ç•™30å¤©æ•¸æ“š
            'alert_thresholds': {
                'cpu_warning': 80.0,
                'cpu_critical': 95.0,
                'memory_warning': 85.0,
                'memory_critical': 95.0,
                'disk_warning': 85.0,
                'disk_critical': 95.0,
                'github_actions_warning': 80.0,
                'github_actions_critical': 95.0
            },
            'cleanup_thresholds': {
                'log_files_days': 7,
                'temp_files_days': 1,
                'cache_files_days': 3,
                'report_files_days': 30
            }
        }
        
        # GitHub APIé…ç½®
        self.github_config = {
            'api_base': 'https://api.github.com',
            'owner': None,  # å°‡å¾ç’°å¢ƒè®Šé‡æˆ–é…ç½®ä¸­ç²å–
            'repo': None,
            'token': None
        }
        
        # ç›£æ§ç‹€æ…‹
        self.monitoring_active = False
        self.monitoring_thread = None
        
        self.setup_github_config()
    
    def setup_github_config(self):
        """è¨­ç½®GitHubé…ç½®"""
        # å˜—è©¦å¾ç’°å¢ƒè®Šé‡ç²å–é…ç½®
        self.github_config['token'] = os.environ.get('GITHUB_TOKEN')
        self.github_config['owner'] = os.environ.get('GITHUB_REPOSITORY_OWNER')
        
        # å˜—è©¦å¾gité…ç½®ç²å–å€‰åº«ä¿¡æ¯
        try:
            import subprocess
            result = subprocess.run(['git', 'remote', 'get-url', 'origin'], 
                                  capture_output=True, text=True, cwd=self.project_root)
            if result.returncode == 0:
                remote_url = result.stdout.strip()
                if 'github.com' in remote_url:
                    # è§£æGitHubå€‰åº«ä¿¡æ¯
                    if remote_url.endswith('.git'):
                        remote_url = remote_url[:-4]
                    
                    parts = remote_url.split('/')
                    if len(parts) >= 2:
                        self.github_config['owner'] = parts[-2]
                        self.github_config['repo'] = parts[-1]
        except Exception as e:
            logger.warning(f"ç„¡æ³•ç²å–Gitå€‰åº«ä¿¡æ¯: {e}")
    
    def start_monitoring(self):
        """é–‹å§‹è³‡æºç›£æ§"""
        if self.monitoring_active:
            logger.warning("âš ï¸ è³‡æºç›£æ§å·²åœ¨é‹è¡Œ")
            return
        
        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitoring_thread.start()
        
        logger.info(f"ğŸ“Š è³‡æºç›£æ§å·²å•Ÿå‹•ï¼Œç›£æ§é–“éš”: {self.config['monitoring_interval']}ç§’")
    
    def stop_monitoring(self):
        """åœæ­¢è³‡æºç›£æ§"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=10)
        
        logger.info("ğŸ›‘ è³‡æºç›£æ§å·²åœæ­¢")
    
    def _monitoring_loop(self):
        """ç›£æ§å¾ªç’°"""
        while self.monitoring_active:
            try:
                # æ”¶é›†ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
                resource_usage = self._collect_system_resources()
                self.monitoring_data.append(resource_usage)
                
                # æ”¶é›†GitHub Actionsä½¿ç”¨æƒ…æ³
                if self._can_access_github_api():
                    github_usage = self._collect_github_actions_usage()
                    if github_usage:
                        self.github_usage_data.append(github_usage)
                
                # æª¢æŸ¥è­¦å‘Šé–¾å€¼
                self._check_alert_thresholds(resource_usage)
                
                # æ¸…ç†èˆŠæ•¸æ“š
                self._cleanup_old_data()
                
                # è‡ªå‹•å„ªåŒ–
                self._auto_optimize_resources()
                
                time.sleep(self.config['monitoring_interval'])
                
            except Exception as e:
                logger.error(f"âŒ ç›£æ§å¾ªç’°éŒ¯èª¤: {e}")
                time.sleep(self.config['monitoring_interval'])
    
    def _collect_system_resources(self) -> ResourceUsage:
        """æ”¶é›†ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # è¨˜æ†¶é«”ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            # ç£ç¢Ÿä½¿ç”¨æƒ…æ³
            disk_usage = psutil.disk_usage(str(self.project_root))
            disk_usage_gb = (disk_usage.total - disk_usage.free) / (1024**3)
            disk_free_gb = disk_usage.free / (1024**3)
            
            # ç¶²è·¯IO
            network_io = psutil.net_io_counters()
            network_io_mb = (network_io.bytes_sent + network_io.bytes_recv) / (1024**2)
            
            # é€²ç¨‹æ•¸é‡
            process_count = len(psutil.pids())
            
            # æ–‡ä»¶æ•¸é‡ï¼ˆé …ç›®ç›®éŒ„ï¼‰
            file_count = sum(1 for _ in self.project_root.rglob('*') if _.is_file())
            
            # è©³ç´°ä¿¡æ¯
            details = {
                'memory_total_gb': memory.total / (1024**3),
                'memory_available_gb': memory.available / (1024**3),
                'disk_total_gb': disk_usage.total / (1024**3),
                'cpu_count': psutil.cpu_count(),
                'load_average': os.getloadavg() if hasattr(os, 'getloadavg') else None,
                'project_size_mb': self._get_directory_size(self.project_root) / (1024**2)
            }
            
            return ResourceUsage(
                timestamp=datetime.now(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                disk_usage_gb=disk_usage_gb,
                disk_free_gb=disk_free_gb,
                network_io_mb=network_io_mb,
                process_count=process_count,
                file_count=file_count,
                details=details
            )
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†ç³»çµ±è³‡æºå¤±æ•—: {e}")
            return ResourceUsage(
                timestamp=datetime.now(),
                cpu_percent=0, memory_percent=0, disk_usage_gb=0,
                disk_free_gb=0, network_io_mb=0, process_count=0, file_count=0
            )
    
    def _get_directory_size(self, directory: Path) -> int:
        """ç²å–ç›®éŒ„å¤§å°ï¼ˆå­—ç¯€ï¼‰"""
        try:
            total_size = 0
            for file_path in directory.rglob('*'):
                if file_path.is_file():
                    try:
                        total_size += file_path.stat().st_size
                    except (OSError, FileNotFoundError):
                        continue
            return total_size
        except Exception as e:
            logger.error(f"âŒ è¨ˆç®—ç›®éŒ„å¤§å°å¤±æ•—: {e}")
            return 0
    
    def _can_access_github_api(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦å¯ä»¥è¨ªå•GitHub API"""
        return (self.github_config['token'] and 
                self.github_config['owner'] and 
                self.github_config['repo'])
    
    def _collect_github_actions_usage(self) -> Optional[GitHubActionsUsage]:
        """æ”¶é›†GitHub Actionsä½¿ç”¨æƒ…æ³"""
        try:
            headers = {
                'Authorization': f"token {self.github_config['token']}",
                'Accept': 'application/vnd.github.v3+json'
            }
            
            # ç²å–Actionsä½¿ç”¨é‡
            billing_url = f"{self.github_config['api_base']}/repos/{self.github_config['owner']}/{self.github_config['repo']}/actions/billing"
            
            response = requests.get(billing_url, headers=headers, timeout=30)
            
            if response.status_code == 200:
                billing_data = response.json()
                
                # ç²å–å·¥ä½œæµé‹è¡Œçµ±è¨ˆ
                runs_url = f"{self.github_config['api_base']}/repos/{self.github_config['owner']}/{self.github_config['repo']}/actions/runs"
                runs_response = requests.get(runs_url, headers=headers, timeout=30)
                
                workflow_runs_count = 0
                if runs_response.status_code == 200:
                    runs_data = runs_response.json()
                    workflow_runs_count = runs_data.get('total_count', 0)
                
                # è¨ˆç®—ä½¿ç”¨ç™¾åˆ†æ¯”
                total_minutes = billing_data.get('total_minutes_used', 0)
                included_minutes = billing_data.get('included_minutes', 2000)  # GitHubå…è²»é¡åº¦
                
                usage_percentage = (total_minutes / included_minutes * 100) if included_minutes > 0 else 0
                remaining_minutes = max(0, included_minutes - total_minutes)
                
                return GitHubActionsUsage(
                    total_minutes_used=total_minutes,
                    total_minutes_quota=included_minutes,
                    usage_percentage=usage_percentage,
                    remaining_minutes=remaining_minutes,
                    billing_cycle_start=datetime.now().replace(day=1),
                    billing_cycle_end=datetime.now().replace(day=1) + timedelta(days=32),
                    workflow_runs_count=workflow_runs_count,
                    storage_usage_mb=billing_data.get('total_paid_minutes_used', 0)
                )
            
            else:
                logger.warning(f"âš ï¸ GitHub APIè«‹æ±‚å¤±æ•—: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†GitHub Actionsä½¿ç”¨é‡å¤±æ•—: {e}")
            return None
    
    def _check_alert_thresholds(self, resource_usage: ResourceUsage):
        """æª¢æŸ¥è­¦å‘Šé–¾å€¼"""
        alerts = []
        thresholds = self.config['alert_thresholds']
        
        # CPUè­¦å‘Š
        if resource_usage.cpu_percent >= thresholds['cpu_critical']:
            alerts.append(f"ğŸš¨ CPUä½¿ç”¨ç‡å±éšª: {resource_usage.cpu_percent:.1f}%")
        elif resource_usage.cpu_percent >= thresholds['cpu_warning']:
            alerts.append(f"âš ï¸ CPUä½¿ç”¨ç‡è­¦å‘Š: {resource_usage.cpu_percent:.1f}%")
        
        # è¨˜æ†¶é«”è­¦å‘Š
        if resource_usage.memory_percent >= thresholds['memory_critical']:
            alerts.append(f"ğŸš¨ è¨˜æ†¶é«”ä½¿ç”¨ç‡å±éšª: {resource_usage.memory_percent:.1f}%")
        elif resource_usage.memory_percent >= thresholds['memory_warning']:
            alerts.append(f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨ç‡è­¦å‘Š: {resource_usage.memory_percent:.1f}%")
        
        # ç£ç¢Ÿç©ºé–“è­¦å‘Š
        total_disk = resource_usage.disk_usage_gb + resource_usage.disk_free_gb
        disk_usage_percent = (resource_usage.disk_usage_gb / total_disk * 100) if total_disk > 0 else 0
        
        if disk_usage_percent >= thresholds['disk_critical']:
            alerts.append(f"ğŸš¨ ç£ç¢Ÿä½¿ç”¨ç‡å±éšª: {disk_usage_percent:.1f}%")
        elif disk_usage_percent >= thresholds['disk_warning']:
            alerts.append(f"âš ï¸ ç£ç¢Ÿä½¿ç”¨ç‡è­¦å‘Š: {disk_usage_percent:.1f}%")
        
        # GitHub Actionsä½¿ç”¨é‡è­¦å‘Š
        if self.github_usage_data:
            latest_github_usage = self.github_usage_data[-1]
            if latest_github_usage.usage_percentage >= thresholds['github_actions_critical']:
                alerts.append(f"ğŸš¨ GitHub Actionsä½¿ç”¨é‡å±éšª: {latest_github_usage.usage_percentage:.1f}%")
            elif latest_github_usage.usage_percentage >= thresholds['github_actions_warning']:
                alerts.append(f"âš ï¸ GitHub Actionsä½¿ç”¨é‡è­¦å‘Š: {latest_github_usage.usage_percentage:.1f}%")
        
        # è¨˜éŒ„è­¦å‘Š
        for alert in alerts:
            logger.warning(alert)
    
    def _cleanup_old_data(self):
        """æ¸…ç†èˆŠæ•¸æ“š"""
        cutoff_date = datetime.now() - timedelta(days=self.config['data_retention_days'])
        
        # æ¸…ç†ç›£æ§æ•¸æ“š
        self.monitoring_data = [
            data for data in self.monitoring_data 
            if data.timestamp > cutoff_date
        ]
        
        # æ¸…ç†GitHubä½¿ç”¨æ•¸æ“š
        self.github_usage_data = [
            data for data in self.github_usage_data 
            if data.billing_cycle_start > cutoff_date
        ]
    
    def _auto_optimize_resources(self):
        """è‡ªå‹•è³‡æºå„ªåŒ–"""
        try:
            if not self.monitoring_data:
                return
            
            latest_usage = self.monitoring_data[-1]
            
            # å¦‚æœè¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜ï¼Œè§¸ç™¼åƒåœ¾å›æ”¶
            if latest_usage.memory_percent > 90:
                import gc
                collected = gc.collect()
                logger.info(f"ğŸ§¹ è‡ªå‹•åƒåœ¾å›æ”¶: æ¸…ç†äº† {collected} å€‹å°è±¡")
            
            # å¦‚æœç£ç¢Ÿç©ºé–“ä¸è¶³ï¼Œæ¸…ç†è‡¨æ™‚æ–‡ä»¶
            if latest_usage.disk_free_gb < 1.0:  # å°‘æ–¼1GB
                self.cleanup_temporary_files()
                logger.info("ğŸ§¹ è‡ªå‹•æ¸…ç†è‡¨æ™‚æ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"âŒ è‡ªå‹•å„ªåŒ–å¤±æ•—: {e}")
    
    def cleanup_temporary_files(self) -> Dict[str, Any]:
        """æ¸…ç†è‡¨æ™‚æ–‡ä»¶"""
        cleanup_result = {
            'cleaned_files': 0,
            'freed_space_mb': 0,
            'cleaned_directories': []
        }
        
        try:
            # æ¸…ç†ç›®æ¨™ç›®éŒ„
            cleanup_dirs = [
                self.project_root / "temp",
                self.project_root / "logs",
                self.project_root / "__pycache__",
                self.project_root / ".pytest_cache"
            ]
            
            for cleanup_dir in cleanup_dirs:
                if cleanup_dir.exists():
                    initial_size = self._get_directory_size(cleanup_dir)
                    
                    if cleanup_dir.name == "logs":
                        # åªæ¸…ç†èˆŠæ—¥èªŒæ–‡ä»¶
                        self._cleanup_old_log_files(cleanup_dir)
                    elif cleanup_dir.name == "temp":
                        # æ¸…ç†æ‰€æœ‰è‡¨æ™‚æ–‡ä»¶
                        shutil.rmtree(cleanup_dir)
                        cleanup_dir.mkdir()
                    else:
                        # æ¸…ç†ç·©å­˜ç›®éŒ„
                        if cleanup_dir.exists():
                            shutil.rmtree(cleanup_dir)
                    
                    final_size = self._get_directory_size(cleanup_dir) if cleanup_dir.exists() else 0
                    freed_space = (initial_size - final_size) / (1024**2)
                    
                    if freed_space > 0:
                        cleanup_result['freed_space_mb'] += freed_space
                        cleanup_result['cleaned_directories'].append(str(cleanup_dir))
            
            logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆ: é‡‹æ”¾ {cleanup_result['freed_space_mb']:.2f} MB ç©ºé–“")
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†è‡¨æ™‚æ–‡ä»¶å¤±æ•—: {e}")
        
        return cleanup_result
    
    def _cleanup_old_log_files(self, log_dir: Path):
        """æ¸…ç†èˆŠæ—¥èªŒæ–‡ä»¶"""
        try:
            cutoff_date = datetime.now() - timedelta(days=self.config['cleanup_thresholds']['log_files_days'])
            
            for log_file in log_dir.rglob("*.log"):
                if log_file.is_file():
                    file_time = datetime.fromtimestamp(log_file.stat().st_mtime)
                    if file_time < cutoff_date:
                        log_file.unlink()
                        
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†æ—¥èªŒæ–‡ä»¶å¤±æ•—: {e}")
    
    def get_resource_statistics(self) -> Dict[str, Any]:
        """ç²å–è³‡æºçµ±è¨ˆ"""
        if not self.monitoring_data:
            return {'error': 'No monitoring data available'}
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        cpu_values = [data.cpu_percent for data in self.monitoring_data[-24:]]  # æœ€è¿‘24å€‹æ•¸æ“šé»
        memory_values = [data.memory_percent for data in self.monitoring_data[-24:]]
        
        stats = {
            'current_usage': {
                'cpu_percent': self.monitoring_data[-1].cpu_percent,
                'memory_percent': self.monitoring_data[-1].memory_percent,
                'disk_usage_gb': self.monitoring_data[-1].disk_usage_gb,
                'disk_free_gb': self.monitoring_data[-1].disk_free_gb,
                'file_count': self.monitoring_data[-1].file_count
            },
            'averages_24h': {
                'cpu_percent': sum(cpu_values) / len(cpu_values) if cpu_values else 0,
                'memory_percent': sum(memory_values) / len(memory_values) if memory_values else 0
            },
            'peaks_24h': {
                'cpu_percent': max(cpu_values) if cpu_values else 0,
                'memory_percent': max(memory_values) if memory_values else 0
            },
            'data_points': len(self.monitoring_data),
            'monitoring_duration_hours': (
                (self.monitoring_data[-1].timestamp - self.monitoring_data[0].timestamp).total_seconds() / 3600
                if len(self.monitoring_data) > 1 else 0
            )
        }
        
        # æ·»åŠ GitHub Actionsçµ±è¨ˆ
        if self.github_usage_data:
            latest_github = self.github_usage_data[-1]
            stats['github_actions'] = {
                'usage_percentage': latest_github.usage_percentage,
                'minutes_used': latest_github.total_minutes_used,
                'minutes_remaining': latest_github.remaining_minutes,
                'workflow_runs': latest_github.workflow_runs_count
            }
        
        return stats
    
    def generate_optimization_recommendations(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        recommendations = []
        
        if not self.monitoring_data:
            return recommendations
        
        latest_usage = self.monitoring_data[-1]
        stats = self.get_resource_statistics()
        
        # CPUå„ªåŒ–å»ºè­°
        if stats['averages_24h']['cpu_percent'] > 70:
            recommendations.append({
                'category': 'CPU',
                'priority': 'high',
                'issue': f"CPUå¹³å‡ä½¿ç”¨ç‡éé«˜ ({stats['averages_24h']['cpu_percent']:.1f}%)",
                'recommendation': 'è€ƒæ…®å„ªåŒ–ç®—æ³•è¤‡é›œåº¦æˆ–æ¸›å°‘ä¸¦ç™¼è™•ç†',
                'actions': [
                    'æª¢æŸ¥æ˜¯å¦æœ‰æ­»å¾ªç’°æˆ–ä½æ•ˆç®—æ³•',
                    'æ¸›å°‘åŒæ™‚é‹è¡Œçš„GitHub Actionså·¥ä½œæµ',
                    'ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•¸æ“šçµæ§‹'
                ]
            })
        
        # è¨˜æ†¶é«”å„ªåŒ–å»ºè­°
        if stats['averages_24h']['memory_percent'] > 80:
            recommendations.append({
                'category': 'Memory',
                'priority': 'high',
                'issue': f"è¨˜æ†¶é«”å¹³å‡ä½¿ç”¨ç‡éé«˜ ({stats['averages_24h']['memory_percent']:.1f}%)",
                'recommendation': 'å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨ï¼Œé¿å…è¨˜æ†¶é«”æ´©æ¼',
                'actions': [
                    'æª¢æŸ¥æ˜¯å¦æœ‰è¨˜æ†¶é«”æ´©æ¼',
                    'å„ªåŒ–æ•¸æ“šç·©å­˜ç­–ç•¥',
                    'åŠæ™‚é‡‹æ”¾ä¸éœ€è¦çš„å°è±¡'
                ]
            })
        
        # ç£ç¢Ÿç©ºé–“å„ªåŒ–å»ºè­°
        if latest_usage.disk_free_gb < 2.0:
            recommendations.append({
                'category': 'Disk',
                'priority': 'critical',
                'issue': f"ç£ç¢Ÿç©ºé–“ä¸è¶³ (å‰©é¤˜ {latest_usage.disk_free_gb:.1f} GB)",
                'recommendation': 'ç«‹å³æ¸…ç†ä¸å¿…è¦çš„æ–‡ä»¶',
                'actions': [
                    'æ¸…ç†æ—¥èªŒæ–‡ä»¶',
                    'åˆªé™¤è‡¨æ™‚æ–‡ä»¶',
                    'å£“ç¸®æˆ–åˆªé™¤èˆŠçš„å‚™ä»½æ–‡ä»¶'
                ]
            })
        
        # GitHub Actionså„ªåŒ–å»ºè­°
        if self.github_usage_data:
            latest_github = self.github_usage_data[-1]
            if latest_github.usage_percentage > 80:
                recommendations.append({
                    'category': 'GitHub Actions',
                    'priority': 'high',
                    'issue': f"GitHub Actionsä½¿ç”¨é‡éé«˜ ({latest_github.usage_percentage:.1f}%)",
                    'recommendation': 'å„ªåŒ–å·¥ä½œæµåŸ·è¡Œé »ç‡å’Œæ•ˆç‡',
                    'actions': [
                        'æ¸›å°‘å·¥ä½œæµè§¸ç™¼é »ç‡',
                        'å„ªåŒ–å·¥ä½œæµåŸ·è¡Œæ™‚é–“',
                        'ä½¿ç”¨æ¢ä»¶åŸ·è¡Œé¿å…ä¸å¿…è¦çš„é‹è¡Œ',
                        'è€ƒæ…®ä½¿ç”¨self-hosted runners'
                    ]
                })
        
        # æ–‡ä»¶æ•¸é‡å„ªåŒ–å»ºè­°
        if latest_usage.file_count > 10000:
            recommendations.append({
                'category': 'Files',
                'priority': 'medium',
                'issue': f"é …ç›®æ–‡ä»¶æ•¸é‡éå¤š ({latest_usage.file_count} å€‹æ–‡ä»¶)",
                'recommendation': 'æ¸…ç†ä¸å¿…è¦çš„æ–‡ä»¶ï¼Œå„ªåŒ–é …ç›®çµæ§‹',
                'actions': [
                    'åˆªé™¤æœªä½¿ç”¨çš„æ–‡ä»¶',
                    'å£“ç¸®æ­·å²æ•¸æ“š',
                    'ä½¿ç”¨.gitignoreæ’é™¤ä¸å¿…è¦çš„æ–‡ä»¶'
                ]
            })
        
        return recommendations
    
    def generate_resource_report(self) -> str:
        """ç”Ÿæˆè³‡æºä½¿ç”¨å ±å‘Š"""
        stats = self.get_resource_statistics()
        recommendations = self.generate_optimization_recommendations()
        
        report = f"""
ğŸ“Š AImax è³‡æºä½¿ç”¨ç›£æ§å ±å‘Š
{'='*60}

ğŸ–¥ï¸ ç•¶å‰ç³»çµ±è³‡æºä½¿ç”¨:
   CPUä½¿ç”¨ç‡: {stats['current_usage']['cpu_percent']:.1f}%
   è¨˜æ†¶é«”ä½¿ç”¨ç‡: {stats['current_usage']['memory_percent']:.1f}%
   ç£ç¢Ÿä½¿ç”¨: {stats['current_usage']['disk_usage_gb']:.2f} GB
   ç£ç¢Ÿå‰©é¤˜: {stats['current_usage']['disk_free_gb']:.2f} GB
   æ–‡ä»¶æ•¸é‡: {stats['current_usage']['file_count']:,}

ğŸ“ˆ 24å°æ™‚å¹³å‡ä½¿ç”¨ç‡:
   CPUå¹³å‡: {stats['averages_24h']['cpu_percent']:.1f}%
   è¨˜æ†¶é«”å¹³å‡: {stats['averages_24h']['memory_percent']:.1f}%

ğŸ“Š 24å°æ™‚å³°å€¼ä½¿ç”¨ç‡:
   CPUå³°å€¼: {stats['peaks_24h']['cpu_percent']:.1f}%
   è¨˜æ†¶é«”å³°å€¼: {stats['peaks_24h']['memory_percent']:.1f}%

ğŸ“‹ ç›£æ§çµ±è¨ˆ:
   æ•¸æ“šé»æ•¸: {stats['data_points']}
   ç›£æ§æ™‚é•·: {stats['monitoring_duration_hours']:.1f} å°æ™‚
"""
        
        # æ·»åŠ GitHub Actionsçµ±è¨ˆ
        if 'github_actions' in stats:
            github_stats = stats['github_actions']
            report += f"""
ğŸš€ GitHub Actionsä½¿ç”¨æƒ…æ³:
   ä½¿ç”¨ç‡: {github_stats['usage_percentage']:.1f}%
   å·²ç”¨åˆ†é˜: {github_stats['minutes_used']}
   å‰©é¤˜åˆ†é˜: {github_stats['minutes_remaining']}
   å·¥ä½œæµé‹è¡Œæ¬¡æ•¸: {github_stats['workflow_runs']}
"""
        
        # æ·»åŠ å„ªåŒ–å»ºè­°
        if recommendations:
            report += f"\nğŸ’¡ å„ªåŒ–å»ºè­°:\n"
            for i, rec in enumerate(recommendations, 1):
                priority_emoji = {
                    'critical': 'ğŸš¨',
                    'high': 'âš ï¸',
                    'medium': 'ğŸ’¡',
                    'low': 'â„¹ï¸'
                }.get(rec['priority'], 'ğŸ’¡')
                
                report += f"\n{i}. {priority_emoji} {rec['category']} - {rec['priority'].upper()}\n"
                report += f"   å•é¡Œ: {rec['issue']}\n"
                report += f"   å»ºè­°: {rec['recommendation']}\n"
                report += f"   è¡Œå‹•:\n"
                for action in rec['actions']:
                    report += f"     â€¢ {action}\n"
        
        report += f"\n{'='*60}\n"
        report += f"å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        
        return report
    
    def save_monitoring_data(self) -> Path:
        """ä¿å­˜ç›£æ§æ•¸æ“šåˆ°æ–‡ä»¶"""
        reports_dir = self.project_root / "reports"
        reports_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜JSONæ ¼å¼çš„è©³ç´°æ•¸æ“š
        data_file = reports_dir / f"resource_monitoring_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        monitoring_data = {
            'timestamp': datetime.now().isoformat(),
            'system_resources': [
                {
                    'timestamp': data.timestamp.isoformat(),
                    'cpu_percent': data.cpu_percent,
                    'memory_percent': data.memory_percent,
                    'disk_usage_gb': data.disk_usage_gb,
                    'disk_free_gb': data.disk_free_gb,
                    'network_io_mb': data.network_io_mb,
                    'process_count': data.process_count,
                    'file_count': data.file_count,
                    'details': data.details
                }
                for data in self.monitoring_data
            ],
            'github_actions': [
                {
                    'total_minutes_used': data.total_minutes_used,
                    'usage_percentage': data.usage_percentage,
                    'remaining_minutes': data.remaining_minutes,
                    'workflow_runs_count': data.workflow_runs_count,
                    'billing_cycle_start': data.billing_cycle_start.isoformat(),
                    'billing_cycle_end': data.billing_cycle_end.isoformat()
                }
                for data in self.github_usage_data
            ],
            'statistics': self.get_resource_statistics(),
            'recommendations': self.generate_optimization_recommendations()
        }
        
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(monitoring_data, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ–‡æœ¬æ ¼å¼çš„å ±å‘Š
        report_file = reports_dir / f"resource_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(self.generate_resource_report())
        
        logger.info(f"ğŸ“„ ç›£æ§æ•¸æ“šå·²ä¿å­˜: {data_file}")
        logger.info(f"ğŸ“„ ç›£æ§å ±å‘Šå·²ä¿å­˜: {report_file}")
        
        return data_file

# å…¨å±€è³‡æºç›£æ§å™¨å¯¦ä¾‹
resource_monitor = ResourceMonitor()

# ä¾¿æ·å‡½æ•¸
def start_resource_monitoring():
    """å•Ÿå‹•è³‡æºç›£æ§"""
    resource_monitor.start_monitoring()

def stop_resource_monitoring():
    """åœæ­¢è³‡æºç›£æ§"""
    resource_monitor.stop_monitoring()

def get_resource_stats() -> Dict[str, Any]:
    """ç²å–è³‡æºçµ±è¨ˆ"""
    return resource_monitor.get_resource_statistics()

def cleanup_resources() -> Dict[str, Any]:
    """æ¸…ç†è³‡æº"""
    return resource_monitor.cleanup_temporary_files()

def get_optimization_recommendations() -> List[Dict[str, Any]]:
    """ç²å–å„ªåŒ–å»ºè­°"""
    return resource_monitor.generate_optimization_recommendations()