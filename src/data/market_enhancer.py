#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸‚å ´æ•¸æ“šå¢å¼·å™¨ - ç‚ºAIæä¾›è±å¯Œã€é«˜è³ªé‡çš„å¯¦æ™‚å¸‚å ´æ•¸æ“š
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

from .max_client import create_max_client
from .technical_indicators import create_technical_calculator
from .data_validator import create_data_validator
from .historical_data_manager import create_historical_manager

logger = logging.getLogger(__name__)

@dataclass
class EnhancedMarketData:
    """å¢å¼·çš„å¸‚å ´æ•¸æ“šçµæ§‹"""
    timestamp: datetime
    basic_data: Dict[str, Any]
    technical_indicators: Dict[str, Any]
    validation_report: Dict[str, Any]
    quality_score: float
    ai_formatted_data: str
    processing_time: float

class MarketDataEnhancer:
    """å¸‚å ´æ•¸æ“šå¢å¼·å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¸‚å ´æ•¸æ“šå¢å¼·å™¨"""
        self.max_client = create_max_client()
        self.technical_calculator = create_technical_calculator()
        self.data_validator = create_data_validator()
        self.historical_manager = create_historical_manager()
        
        # æ€§èƒ½çµ±è¨ˆ
        self.performance_stats = {
            'total_enhancements': 0,
            'successful_enhancements': 0,
            'average_processing_time': 0.0,
            'average_quality_score': 0.0,
            'data_sources_status': {
                'max_api': True,
                'historical_database': True,
                'technical_indicators': True,
                'data_validation': True
            }
        }
        
        logger.info("ğŸš€ å¸‚å ´æ•¸æ“šå¢å¼·å™¨åˆå§‹åŒ–å®Œæˆï¼ˆå«æ­·å²æ•¸æ“šåº«ï¼‰")
    
    async def get_enhanced_market_data(self, market: str = "btctwd") -> Optional[EnhancedMarketData]:
        """
        ç²å–å¢å¼·çš„å¸‚å ´æ•¸æ“š
        
        Args:
            market: äº¤æ˜“å°ï¼Œé»˜èªç‚º btctwd
            
        Returns:
            EnhancedMarketData: å¢å¼·çš„å¸‚å ´æ•¸æ“šï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å›None
        """
        start_time = datetime.now()
        
        try:
            self.performance_stats['total_enhancements'] += 1
            logger.info(f"ğŸ”„ é–‹å§‹ç²å–å¢å¼·å¸‚å ´æ•¸æ“š: {market}")
            
            # æ­¥é©Ÿ1: ç²å–åŸºç¤å¸‚å ´æ•¸æ“š
            basic_data = await self._get_basic_market_data(market)
            if not basic_data:
                logger.error("âŒ ç²å–åŸºç¤å¸‚å ´æ•¸æ“šå¤±æ•—")
                return None
            
            # æ­¥é©Ÿ2: ç²å–Kç·šæ•¸æ“šç”¨æ–¼æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
            klines_data = await self._get_klines_data(market)
            if not klines_data:
                logger.warning("âš ï¸ ç²å–Kç·šæ•¸æ“šå¤±æ•—ï¼Œä½¿ç”¨åŸºç¤æ•¸æ“š")
                klines_data = {}
            
            # æ­¥é©Ÿ3: è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
            technical_indicators = self._calculate_technical_indicators(klines_data)
            
            # æ­¥é©Ÿ4: åˆä½µæ‰€æœ‰æ•¸æ“š
            combined_data = {**basic_data, **technical_indicators}
            
            # æ­¥é©Ÿ5: æ•¸æ“šé©—è­‰å’Œæ¸…æ´—
            is_valid, validation_report = self.data_validator.validate_market_data(combined_data)
            if not is_valid:
                logger.warning("âš ï¸ æ•¸æ“šé©—è­‰æœªé€šéï¼Œé€²è¡Œæ¸…æ´—")
                combined_data = self.data_validator.clean_market_data(combined_data)
            
            # æ­¥é©Ÿ6: æ ¼å¼åŒ–ç‚ºAIå‹å¥½çš„æ ¼å¼
            ai_formatted_data = self._format_for_ai(combined_data, technical_indicators)
            
            # è¨ˆç®—è™•ç†æ™‚é–“
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # å‰µå»ºå¢å¼·æ•¸æ“šå°è±¡
            enhanced_data = EnhancedMarketData(
                timestamp=datetime.now(),
                basic_data=basic_data,
                technical_indicators=technical_indicators,
                validation_report=validation_report,
                quality_score=validation_report.get('quality_score', 0.0),
                ai_formatted_data=ai_formatted_data,
                processing_time=processing_time
            )
            
            # æ›´æ–°æ€§èƒ½çµ±è¨ˆ
            self._update_performance_stats(enhanced_data)
            
            logger.info(f"âœ… å¸‚å ´æ•¸æ“šå¢å¼·å®Œæˆï¼Œè³ªé‡åˆ†æ•¸: {enhanced_data.quality_score:.2f}")
            return enhanced_data
            
        except Exception as e:
            logger.error(f"âŒ å¸‚å ´æ•¸æ“šå¢å¼·å¤±æ•—: {e}")
            return None
    
    async def _get_basic_market_data(self, market: str) -> Optional[Dict[str, Any]]:
        """ç²å–åŸºç¤å¸‚å ´æ•¸æ“š"""
        try:
            basic_data = await self.max_client.get_enhanced_market_data(market)
            if basic_data:
                self.performance_stats['data_sources_status']['max_api'] = True
                return basic_data
            else:
                self.performance_stats['data_sources_status']['max_api'] = False
                return None
                
        except Exception as e:
            logger.error(f"âŒ ç²å–åŸºç¤å¸‚å ´æ•¸æ“šå¤±æ•—: {e}")
            self.performance_stats['data_sources_status']['max_api'] = False
            return None
    
    async def _get_klines_data(self, market: str) -> Dict[str, Any]:
        """ç²å–Kç·šæ•¸æ“šï¼ˆå„ªå…ˆä½¿ç”¨æœ¬åœ°æ•¸æ“šåº«ï¼‰"""
        try:
            logger.info("ğŸ“Š å„ªå…ˆå¾æœ¬åœ°æ•¸æ“šåº«ç²å–Kç·šæ•¸æ“š...")
            
            # é¦–å…ˆç¢ºä¿æ­·å²æ•¸æ“šå®Œæ•´æ€§
            await self.historical_manager.ensure_historical_data(market, ['1m', '5m', '1h'])
            
            # å¾æœ¬åœ°æ•¸æ“šåº«ç²å–æ•¸æ“š
            klines_data = self.historical_manager.get_multiple_timeframes(
                market, {'1m': 100, '5m': 50, '1h': 24}
            )
            
            if klines_data:
                logger.info(f"âœ… å¾æœ¬åœ°æ•¸æ“šåº«ç²å–åˆ° {len(klines_data)} å€‹æ™‚é–“æ¡†æ¶çš„æ•¸æ“š")
                self.performance_stats['data_sources_status']['historical_database'] = True
                return klines_data
            else:
                logger.warning("âš ï¸ æœ¬åœ°æ•¸æ“šåº«ç„¡æ•¸æ“šï¼Œå˜—è©¦å¾APIç²å–...")
                self.performance_stats['data_sources_status']['historical_database'] = False
                
                # å›é€€åˆ°APIç²å–
                return await self._get_klines_from_api(market)
            
        except Exception as e:
            logger.error(f"âŒ å¾æ•¸æ“šåº«ç²å–Kç·šæ•¸æ“šå¤±æ•—: {e}")
            self.performance_stats['data_sources_status']['historical_database'] = False
            
            # å›é€€åˆ°APIç²å–
            return await self._get_klines_from_api(market)
    
    async def _get_klines_from_api(self, market: str) -> Dict[str, Any]:
        """å¾APIç²å–Kç·šæ•¸æ“šï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            logger.info("ğŸ“¡ å¾MAX APIç²å–Kç·šæ•¸æ“š...")
            
            # ä¸¦è¡Œç²å–ä¸åŒæ™‚é–“æ¡†æ¶çš„Kç·šæ•¸æ“š
            tasks = [
                self.max_client._get_recent_klines(market, period=1, limit=100),   # 1åˆ†é˜
                self.max_client._get_recent_klines(market, period=5, limit=50),    # 5åˆ†é˜
                self.max_client._get_recent_klines(market, period=60, limit=24),   # 1å°æ™‚
            ]
            
            klines_1m, klines_5m, klines_1h = await asyncio.gather(*tasks, return_exceptions=True)
            
            klines_data = {}
            
            if not isinstance(klines_1m, Exception) and klines_1m is not None:
                klines_data['1m'] = klines_1m
            
            if not isinstance(klines_5m, Exception) and klines_5m is not None:
                klines_data['5m'] = klines_5m
            
            if not isinstance(klines_1h, Exception) and klines_1h is not None:
                klines_data['1h'] = klines_1h
            
            logger.info(f"âœ… å¾APIç²å–åˆ° {len(klines_data)} å€‹æ™‚é–“æ¡†æ¶çš„æ•¸æ“š")
            return klines_data
            
        except Exception as e:
            logger.error(f"âŒ å¾APIç²å–Kç·šæ•¸æ“šå¤±æ•—: {e}")
            return {}
    
    def _calculate_technical_indicators(self, klines_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™"""
        try:
            if not klines_data:
                logger.warning("âš ï¸ ç„¡Kç·šæ•¸æ“šï¼Œè·³éæŠ€è¡“æŒ‡æ¨™è¨ˆç®—")
                self.performance_stats['data_sources_status']['technical_indicators'] = False
                return {}
            
            indicators = self.technical_calculator.calculate_comprehensive_indicators(klines_data)
            self.performance_stats['data_sources_status']['technical_indicators'] = True
            return indicators
            
        except Exception as e:
            logger.error(f"âŒ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—: {e}")
            self.performance_stats['data_sources_status']['technical_indicators'] = False
            return {}
    
    def _format_for_ai(self, combined_data: Dict[str, Any], technical_indicators: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æ•¸æ“šç‚ºAIå‹å¥½çš„æ ¼å¼"""
        try:
            # åŸºç¤å¸‚å ´ä¿¡æ¯
            basic_info = self.max_client.format_data_for_ai(combined_data)
            
            # æŠ€è¡“æŒ‡æ¨™ä¿¡æ¯
            technical_info = ""
            if technical_indicators:
                technical_info = self.technical_calculator.format_indicators_for_ai(technical_indicators)
            
            # åˆä½µæ ¼å¼åŒ–ä¿¡æ¯
            formatted_data = f"""
{basic_info}

{technical_info}

ğŸ¯ AIäº¤æ˜“å»ºè­°åƒè€ƒ:
- ç•¶å‰å¸‚å ´ç‹€æ…‹: {'æ´»èº' if combined_data.get('volume_ratio', 1.0) > 1.2 else 'å¹³éœ'}
- æŠ€è¡“é¢åå‘: {self._get_technical_bias(technical_indicators)}
- é¢¨éšªç­‰ç´š: {self._assess_risk_level(combined_data, technical_indicators)}
- å»ºè­°æ“ä½œæ™‚æ©Ÿ: {self._get_timing_suggestion(combined_data)}
"""
            
            return formatted_data.strip()
            
        except Exception as e:
            logger.error(f"âŒ AIæ ¼å¼åŒ–å¤±æ•—: {e}")
            return "æ•¸æ“šæ ¼å¼åŒ–å¤±æ•—"
    
    def _get_technical_bias(self, indicators: Dict[str, Any]) -> str:
        """ç²å–æŠ€è¡“é¢åå‘"""
        try:
            if not indicators:
                return "ä¸­æ€§"
            
            bullish_signals = 0
            bearish_signals = 0
            
            # RSIä¿¡è™Ÿ
            rsi = indicators.get('medium_rsi', 50)
            if rsi < 30:
                bullish_signals += 1
            elif rsi > 70:
                bearish_signals += 1
            
            # MACDä¿¡è™Ÿ
            macd_signal = indicators.get('medium_macd_signal_type', 'ä¸­æ€§')
            if 'é‡‘å‰' in macd_signal:
                bullish_signals += 1
            elif 'æ­»å‰' in macd_signal:
                bearish_signals += 1
            
            # è¶¨å‹¢ä¿¡è™Ÿ
            dominant_trend = indicators.get('dominant_trend', 'éœ‡ç›ª')
            if dominant_trend == 'ä¸Šå‡':
                bullish_signals += 1
            elif dominant_trend == 'ä¸‹é™':
                bearish_signals += 1
            
            if bullish_signals > bearish_signals:
                return "åå¤š"
            elif bearish_signals > bullish_signals:
                return "åç©º"
            else:
                return "ä¸­æ€§"
                
        except Exception:
            return "ä¸­æ€§"
    
    def _assess_risk_level(self, basic_data: Dict[str, Any], indicators: Dict[str, Any]) -> str:
        """è©•ä¼°é¢¨éšªç­‰ç´š"""
        try:
            risk_score = 0
            
            # æ³¢å‹•ç‡é¢¨éšª
            volatility = indicators.get('long_volatility_level', 'ä¸­ç­‰')
            if volatility == 'é«˜':
                risk_score += 2
            elif volatility == 'ä¸­':
                risk_score += 1
            
            # æˆäº¤é‡é¢¨éšª
            volume_ratio = basic_data.get('volume_ratio', 1.0)
            if volume_ratio > 2.0 or volume_ratio < 0.5:
                risk_score += 1
            
            # æŠ€è¡“æŒ‡æ¨™æ¥µç«¯å€¼é¢¨éšª
            rsi = indicators.get('medium_rsi', 50)
            if rsi > 80 or rsi < 20:
                risk_score += 1
            
            if risk_score >= 3:
                return "é«˜é¢¨éšª"
            elif risk_score >= 2:
                return "ä¸­é¢¨éšª"
            else:
                return "ä½é¢¨éšª"
                
        except Exception:
            return "ä¸­é¢¨éšª"
    
    def _get_timing_suggestion(self, data: Dict[str, Any]) -> str:
        """ç²å–æ™‚æ©Ÿå»ºè­°"""
        try:
            hour = data.get('hour_of_day', 12)
            
            # åŸºæ–¼æ™‚é–“çš„å»ºè­°
            if 9 <= hour <= 11:
                return "é–‹ç›¤æ´»èºæœŸï¼Œé©åˆçŸ­ç·šæ“ä½œ"
            elif 14 <= hour <= 16:
                return "åˆå¾Œäº¤æ˜“æœŸï¼Œæ³¨æ„æ­æ´²å¸‚å ´å½±éŸ¿"
            elif 21 <= hour <= 23:
                return "ç¾è‚¡é–‹ç›¤æœŸï¼Œæ³¢å‹•å¯èƒ½åŠ å¤§"
            else:
                return "ç›¸å°å¹³éœæœŸï¼Œé©åˆè§€æœ›"
                
        except Exception:
            return "æ­£å¸¸äº¤æ˜“æ™‚æ®µ"
    
    def _update_performance_stats(self, enhanced_data: EnhancedMarketData):
        """æ›´æ–°æ€§èƒ½çµ±è¨ˆ"""
        try:
            if enhanced_data.quality_score > 0.5:
                self.performance_stats['successful_enhancements'] += 1
            
            # æ›´æ–°å¹³å‡è™•ç†æ™‚é–“
            total_time = (
                self.performance_stats['average_processing_time'] * 
                (self.performance_stats['total_enhancements'] - 1) + 
                enhanced_data.processing_time
            )
            self.performance_stats['average_processing_time'] = total_time / self.performance_stats['total_enhancements']
            
            # æ›´æ–°å¹³å‡è³ªé‡åˆ†æ•¸
            total_quality = (
                self.performance_stats['average_quality_score'] * 
                (self.performance_stats['total_enhancements'] - 1) + 
                enhanced_data.quality_score
            )
            self.performance_stats['average_quality_score'] = total_quality / self.performance_stats['total_enhancements']
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ€§èƒ½çµ±è¨ˆå¤±æ•—: {e}")
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½çµ±è¨ˆ"""
        return self.performance_stats.copy()
    
    def get_system_status(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±ç‹€æ…‹"""
        return {
            'enhancer_status': 'active',
            'data_sources': self.performance_stats['data_sources_status'],
            'performance': {
                'success_rate': (
                    self.performance_stats['successful_enhancements'] / 
                    max(1, self.performance_stats['total_enhancements'])
                ),
                'average_processing_time': self.performance_stats['average_processing_time'],
                'average_quality_score': self.performance_stats['average_quality_score']
            },
            'last_update': datetime.now()
        }
    
    async def close(self):
        """é—œé–‰é€£æ¥"""
        try:
            await self.max_client.close()
            await self.historical_manager.close()
            logger.info("âœ… å¸‚å ´æ•¸æ“šå¢å¼·å™¨å·²é—œé–‰")
        except Exception as e:
            logger.error(f"âŒ é—œé–‰å¢å¼·å™¨å¤±æ•—: {e}")


# å‰µå»ºå…¨å±€å¸‚å ´æ•¸æ“šå¢å¼·å™¨å¯¦ä¾‹
def create_market_enhancer() -> MarketDataEnhancer:
    """å‰µå»ºå¸‚å ´æ•¸æ“šå¢å¼·å™¨å¯¦ä¾‹"""
    return MarketDataEnhancer()


# æ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    import asyncio
    
    async def test_market_enhancer():
        """æ¸¬è©¦å¸‚å ´æ•¸æ“šå¢å¼·å™¨"""
        print("ğŸ§ª æ¸¬è©¦å¸‚å ´æ•¸æ“šå¢å¼·å™¨...")
        
        enhancer = create_market_enhancer()
        
        try:
            # ç²å–å¢å¼·å¸‚å ´æ•¸æ“š
            enhanced_data = await enhancer.get_enhanced_market_data("btctwd")
            
            if enhanced_data:
                print("âœ… ç²å–å¢å¼·å¸‚å ´æ•¸æ“šæˆåŠŸ!")
                print(f"ğŸ“Š è³ªé‡åˆ†æ•¸: {enhanced_data.quality_score:.2f}")
                print(f"â±ï¸ è™•ç†æ™‚é–“: {enhanced_data.processing_time:.2f}ç§’")
                print(f"ğŸ“ˆ æŠ€è¡“æŒ‡æ¨™æ•¸é‡: {len(enhanced_data.technical_indicators)}")
                
                print("\nğŸ¤– AIæ ¼å¼åŒ–æ•¸æ“š:")
                print(enhanced_data.ai_formatted_data)
                
                # é¡¯ç¤ºæ€§èƒ½çµ±è¨ˆ
                stats = enhancer.get_performance_stats()
                print(f"\nğŸ“Š æ€§èƒ½çµ±è¨ˆ:")
                print(f"æˆåŠŸç‡: {stats['successful_enhancements']}/{stats['total_enhancements']}")
                print(f"å¹³å‡è™•ç†æ™‚é–“: {stats['average_processing_time']:.2f}ç§’")
                print(f"å¹³å‡è³ªé‡åˆ†æ•¸: {stats['average_quality_score']:.2f}")
                
            else:
                print("âŒ ç²å–å¢å¼·å¸‚å ´æ•¸æ“šå¤±æ•—")
                
        finally:
            await enhancer.close()
    
    # é‹è¡Œæ¸¬è©¦
    asyncio.run(test_market_enhancer())