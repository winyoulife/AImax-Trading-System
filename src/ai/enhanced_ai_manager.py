#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼·AIå”ä½œç®¡ç†å™¨ - äº”AIè¶…æ™ºèƒ½å”ä½œç³»çµ±
æ”¯æŒå¤šäº¤æ˜“å°çš„å°ˆæ¥­AIåˆ†å·¥å”ä½œ
"""

import asyncio
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from pathlib import Path

import ollama

try:
    from .multi_pair_prompt_optimizer import create_multi_pair_prompt_optimizer, MultiPairContext
except ImportError:
    from multi_pair_prompt_optimizer import create_multi_pair_prompt_optimizer, MultiPairContext

logger = logging.getLogger(__name__)

@dataclass
class EnhancedAIResponse:
    """å¢å¼·AIå›æ‡‰æ•¸æ“šçµæ§‹"""
    ai_role: str
    model_name: str
    response: str
    confidence: float
    processing_time: float
    timestamp: datetime
    success: bool
    pair: str  # æ–°å¢ï¼šäº¤æ˜“å°
    risk_score: float = 0.0  # æ–°å¢ï¼šé¢¨éšªè©•åˆ†
    error_message: Optional[str] = None

@dataclass
class MultiPairDecision:
    """å¤šäº¤æ˜“å°å”ä½œæ±ºç­–çµæœ"""
    pair: str
    final_decision: str  # BUY, SELL, HOLD
    confidence: float
    consensus_level: float
    ai_responses: List[EnhancedAIResponse]
    reasoning: str
    risk_level: str
    risk_score: float  # æ–°å¢ï¼šæ•¸å€¼åŒ–é¢¨éšªè©•åˆ†
    position_size: float  # æ–°å¢ï¼šå»ºè­°å€‰ä½å¤§å°
    timestamp: datetime

class EnhancedAIManager:
    """å¢å¼·AIå”ä½œç®¡ç†å™¨ - äº”AIç³»çµ±"""
    
    def __init__(self, config_path: str = "config/ai_models.json"):
        self.config_path = Path(config_path)
        self.ollama_client = ollama.Client()
        
        # äº”AIæ¨¡å‹é…ç½®
        self.ai_models = {
            "market_scanner": {
                "model_name": "llama2:7b",
                "role": "å¿«é€Ÿå¸‚å ´ä¿¡è™Ÿè­˜åˆ¥",
                "weight": 0.15,
                "max_tokens": 300,
                "temperature": 0.3
            },
            "deep_analyst": {
                "model_name": "falcon:7b", 
                "role": "è¤‡é›œæŠ€è¡“åˆ†æå°ˆå®¶",
                "weight": 0.25,
                "max_tokens": 500,
                "temperature": 0.2
            },
            "trend_analyst": {
                "model_name": "qwen:7b",
                "role": "å¸‚å ´è¶¨å‹¢åˆ¤æ–·å°ˆå®¶", 
                "weight": 0.20,
                "max_tokens": 400,
                "temperature": 0.25
            },
            "risk_assessor": {
                "model_name": "mistral:7b",
                "role": "å¯¦æ™‚é¢¨éšªæ§åˆ¶å°ˆå®¶",
                "weight": 0.25,
                "max_tokens": 400,
                "temperature": 0.1
            },
            "decision_maker": {
                "model_name": "qwen:7b",
                "role": "ç¶œåˆæ±ºç­–åˆ¶å®šè€…",
                "weight": 0.15,
                "max_tokens": 300,
                "temperature": 0.15
            }
        }
        
        # å¤šäº¤æ˜“å°è¨­ç½®
        self.supported_pairs = ['BTCTWD', 'ETHTWD', 'LTCTWD', 'BCHTWD']
        self.pair_specific_configs = {}
        
        # å¤šäº¤æ˜“å°æç¤ºè©å„ªåŒ–å™¨ â­ æ–°å¢
        self.prompt_optimizer = create_multi_pair_prompt_optimizer()
        
        # æ€§èƒ½çµ±è¨ˆ
        self.performance_stats = {
            "total_decisions": 0,
            "successful_decisions": 0,
            "average_processing_time": 0.0,
            "ai_availability": {ai: True for ai in self.ai_models.keys()},
            "pair_stats": {pair: {"decisions": 0, "success_rate": 0.0} 
                          for pair in self.supported_pairs}
        }
        
        logger.info("ğŸ§  å¢å¼·AIå”ä½œç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ (äº”AIç³»çµ±)")
    
    async def analyze_multi_pair_market(self, 
                                      multi_pair_data: Dict[str, Dict[str, Any]]) -> Dict[str, MultiPairDecision]:
        """
        å¤šäº¤æ˜“å°å”ä½œåˆ†æ - ä½¿ç”¨å„ªåŒ–çš„å¤šäº¤æ˜“å°æç¤ºè©
        
        Args:
            multi_pair_data: {pair: market_data} æ ¼å¼çš„å¤šäº¤æ˜“å°æ•¸æ“š
            
        Returns:
            Dict[str, MultiPairDecision]: æ¯å€‹äº¤æ˜“å°çš„æ±ºç­–çµæœ
        """
        logger.info(f"ğŸš€ é–‹å§‹äº”AIå¤šäº¤æ˜“å°å”ä½œåˆ†æ: {len(multi_pair_data)} å€‹äº¤æ˜“å°")
        
        # å‰µå»ºå¤šäº¤æ˜“å°ä¸Šä¸‹æ–‡ â­ æ–°å¢
        multi_pair_context = self._create_multi_pair_context(multi_pair_data)
        
        decisions = {}
        
        # ä¸¦è¡Œåˆ†ææ‰€æœ‰äº¤æ˜“å°
        tasks = []
        for pair, market_data in multi_pair_data.items():
            if pair in self.supported_pairs:
                task = self._analyze_single_pair_with_context(pair, market_data, multi_pair_context)
                tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è™•ç†çµæœ
        for i, result in enumerate(results):
            pair = list(multi_pair_data.keys())[i]
            if isinstance(result, Exception):
                logger.error(f"âŒ {pair} åˆ†æå¤±æ•—: {result}")
                decisions[pair] = self._create_fallback_decision(pair, str(result))
            else:
                decisions[pair] = result
        
        logger.info(f"âœ… å¤šäº¤æ˜“å°åˆ†æå®Œæˆ: {len(decisions)} å€‹æ±ºç­–")
        return decisions
    
    async def _analyze_single_pair(self, pair: str, market_data: Dict[str, Any]) -> MultiPairDecision:
        """åˆ†æå–®å€‹äº¤æ˜“å°"""
        start_time = datetime.now()
        
        try:
            logger.info(f"ğŸ“Š é–‹å§‹åˆ†æ {pair}")
            
            # éšæ®µ1: å¸‚å ´æƒæå“¡ (LLaMA 2:7B)
            scanner_response = await self._run_market_scanner(pair, market_data)
            
            # éšæ®µ2: æ·±åº¦åˆ†æå¸« (Falcon 7B) 
            analyst_response = await self._run_deep_analyst(pair, market_data, scanner_response)
            
            # éšæ®µ3: è¶‹åŠ¿åˆ†æå¸« (Qwen 7B)
            trend_response = await self._run_trend_analyst(pair, market_data, scanner_response)
            
            # éšæ®µ4: é¢¨éšªè©•ä¼°AI (Mistral 7B) â­ æ–°å¢
            risk_response = await self._run_risk_assessor(pair, market_data, 
                                                        scanner_response, analyst_response, trend_response)
            
            # éšæ®µ5: æœ€çµ‚æ±ºç­–è€… (Qwen 7B)
            decision_response = await self._run_decision_maker(pair, market_data,
                                                             scanner_response, analyst_response, 
                                                             trend_response, risk_response)
            
            # ç¶œåˆæ‰€æœ‰AIçš„å›æ‡‰
            ai_responses = [scanner_response, analyst_response, trend_response, 
                          risk_response, decision_response]
            
            # ç”Ÿæˆæœ€çµ‚å”ä½œæ±ºç­–
            collaborative_decision = self._synthesize_multi_pair_decision(pair, ai_responses)
            
            # æ›´æ–°æ€§èƒ½çµ±è¨ˆ
            processing_time = (datetime.now() - start_time).total_seconds()
            self._update_performance_stats(pair, collaborative_decision, processing_time)
            
            logger.info(f"âœ… {pair} åˆ†æå®Œæˆ: {collaborative_decision.final_decision} "
                       f"(ä¿¡å¿ƒåº¦: {collaborative_decision.confidence:.2f})")
            
            return collaborative_decision
            
        except Exception as e:
            logger.error(f"âŒ {pair} åˆ†æå¤±æ•—: {e}")
            return self._create_fallback_decision(pair, str(e))
    
    async def _run_market_scanner(self, pair: str, market_data: Dict[str, Any]) -> EnhancedAIResponse:
        """é‹è¡Œå¸‚å ´æƒæå“¡ (LLaMA 2:7B)"""
        start_time = datetime.now()
        
        try:
            model_config = self.ai_models["market_scanner"]
            
            prompt = self._build_scanner_prompt(pair, market_data)
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=self._get_scanner_system_prompt(),
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return EnhancedAIResponse(
                ai_role="market_scanner",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True,
                pair=pair
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} å¸‚å ´æƒæå“¡åŸ·è¡Œå¤±æ•—: {e}")
            return self._create_error_response("market_scanner", pair, str(e))
    
    async def _run_deep_analyst(self, pair: str, market_data: Dict[str, Any], 
                              scanner_response: EnhancedAIResponse) -> EnhancedAIResponse:
        """é‹è¡Œæ·±åº¦åˆ†æå¸« (Falcon 7B)"""
        start_time = datetime.now()
        
        try:
            model_config = self.ai_models["deep_analyst"]
            
            prompt = self._build_analyst_prompt(pair, market_data, scanner_response)
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=self._get_analyst_system_prompt(),
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return EnhancedAIResponse(
                ai_role="deep_analyst",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True,
                pair=pair
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} æ·±åº¦åˆ†æå¸«åŸ·è¡Œå¤±æ•—: {e}")
            return self._create_error_response("deep_analyst", pair, str(e))
    
    async def _run_trend_analyst(self, pair: str, market_data: Dict[str, Any],
                               scanner_response: EnhancedAIResponse) -> EnhancedAIResponse:
        """é‹è¡Œè¶¨å‹¢åˆ†æå¸« (Qwen 7B)"""
        start_time = datetime.now()
        
        try:
            model_config = self.ai_models["trend_analyst"]
            
            prompt = self._build_trend_prompt(pair, market_data, scanner_response)
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=self._get_trend_system_prompt(),
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return EnhancedAIResponse(
                ai_role="trend_analyst",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True,
                pair=pair
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} è¶¨å‹¢åˆ†æå¸«åŸ·è¡Œå¤±æ•—: {e}")
            return self._create_error_response("trend_analyst", pair, str(e))
    
    async def _run_risk_assessor(self, pair: str, market_data: Dict[str, Any],
                               scanner_response: EnhancedAIResponse,
                               analyst_response: EnhancedAIResponse,
                               trend_response: EnhancedAIResponse) -> EnhancedAIResponse:
        """é‹è¡Œé¢¨éšªè©•ä¼°AI (Mistral 7B) â­ æ–°å¢æ ¸å¿ƒåŠŸèƒ½"""
        start_time = datetime.now()
        
        try:
            model_config = self.ai_models["risk_assessor"]
            
            prompt = self._build_risk_assessment_prompt(pair, market_data, 
                                                      scanner_response, analyst_response, trend_response)
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=self._get_risk_assessor_system_prompt(),
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            risk_score = self._extract_risk_score(response)
            
            return EnhancedAIResponse(
                ai_role="risk_assessor",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True,
                pair=pair,
                risk_score=risk_score
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} é¢¨éšªè©•ä¼°AIåŸ·è¡Œå¤±æ•—: {e}")
            return self._create_error_response("risk_assessor", pair, str(e))
    
    async def _run_decision_maker(self, pair: str, market_data: Dict[str, Any],
                                scanner_response: EnhancedAIResponse,
                                analyst_response: EnhancedAIResponse,
                                trend_response: EnhancedAIResponse,
                                risk_response: EnhancedAIResponse) -> EnhancedAIResponse:
        """é‹è¡Œæœ€çµ‚æ±ºç­–è€… (Qwen 7B)"""
        start_time = datetime.now()
        
        try:
            model_config = self.ai_models["decision_maker"]
            
            prompt = self._build_final_decision_prompt(pair, market_data,
                                                     scanner_response, analyst_response,
                                                     trend_response, risk_response)
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=self._get_decision_maker_system_prompt(),
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return EnhancedAIResponse(
                ai_role="decision_maker",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True,
                pair=pair
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} æœ€çµ‚æ±ºç­–è€…åŸ·è¡Œå¤±æ•—: {e}")
            return self._create_error_response("decision_maker", pair, str(e)) 
   
    async def _call_ai_model(self, model_name: str, system_prompt: str, 
                           user_prompt: str, max_tokens: int, temperature: float) -> str:
        """èª¿ç”¨AIæ¨¡å‹"""
        try:
            response = self.ollama_client.chat(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                options={
                    "num_predict": max_tokens,
                    "temperature": temperature,
                    "top_p": 0.9
                }
            )
            
            return response['message']['content']
            
        except Exception as e:
            logger.error(f"âŒ AIæ¨¡å‹èª¿ç”¨å¤±æ•— ({model_name}): {e}")
            raise
    
    def _get_scanner_system_prompt(self) -> str:
        """å¸‚å ´æƒæå“¡ç³»çµ±æç¤ºè©"""
        return """ä½ æ˜¯å°ˆæ¥­çš„åŠ å¯†è²¨å¹£å¸‚å ´æƒæå“¡ï¼Œè² è²¬å¿«é€Ÿè­˜åˆ¥äº¤æ˜“æ©Ÿæœƒå’Œå¸‚å ´ä¿¡è™Ÿã€‚

ä½ çš„è·è²¬ï¼š
1. å¿«é€Ÿæƒæå¸‚å ´æ•¸æ“šï¼Œè­˜åˆ¥é—œéµä¿¡è™Ÿ
2. è©•ä¼°çŸ­æœŸäº¤æ˜“æ©Ÿæœƒ
3. æä¾›åˆæ­¥çš„å¸‚å ´æ–¹å‘åˆ¤æ–·
4. æ¨™è¨˜éœ€è¦æ·±åº¦åˆ†æçš„é‡è¦ä¿¡è™Ÿ

ç‰¹é»ï¼š
- åæ‡‰è¿…é€Ÿï¼Œå°ˆæ³¨æ–¼å³æ™‚ä¿¡è™Ÿ
- å„ªå…ˆè€ƒæ…®æŠ€è¡“æŒ‡æ¨™çµ„åˆ
- æ³¨æ„æˆäº¤é‡å’Œåƒ¹æ ¼çš„é…åˆ
- æä¾›æ˜ç¢ºçš„æ•¸å­—åŒ–è©•ä¼°"""
    
    def _get_analyst_system_prompt(self) -> str:
        """æ·±åº¦åˆ†æå¸«ç³»çµ±æç¤ºè©"""
        return """ä½ æ˜¯å°ˆæ¥­çš„åŠ å¯†è²¨å¹£æ·±åº¦æŠ€è¡“åˆ†æå¸«ï¼Œæ“…é•·è¤‡é›œçš„æŠ€è¡“åˆ†æå’Œå¸‚å ´çµæ§‹åˆ†æã€‚

ä½ çš„è·è²¬ï¼š
1. é€²è¡Œæ·±åº¦æŠ€è¡“æŒ‡æ¨™åˆ†æ
2. è­˜åˆ¥æ”¯æ’é˜»åŠ›ä½å’Œé—œéµåƒ¹ä½
3. åˆ†æå¸‚å ´çµæ§‹å’Œå½¢æ…‹
4. è©•ä¼°æŠ€è¡“é¢çš„å¼·å¼±ç¨‹åº¦

ç‰¹é»ï¼š
- åˆ†ææ·±å…¥ï¼Œé‚è¼¯åš´è¬¹
- æ“…é•·å¤šæ™‚é–“æ¡†æ¶åˆ†æ
- é‡è¦–æŠ€è¡“æŒ‡æ¨™çš„èƒŒé›¢å’Œç¢ºèª
- æä¾›è©³ç´°çš„æŠ€è¡“åˆ†æå ±å‘Š"""
    
    def _get_trend_system_prompt(self) -> str:
        """è¶¨å‹¢åˆ†æå¸«ç³»çµ±æç¤ºè©"""
        return """ä½ æ˜¯å°ˆæ¥­çš„å¸‚å ´è¶¨å‹¢åˆ†æå¸«ï¼Œå°ˆæ³¨æ–¼è­˜åˆ¥å’Œåˆ†æå¸‚å ´è¶¨å‹¢çš„æ–¹å‘å’Œå¼·åº¦ã€‚

ä½ çš„è·è²¬ï¼š
1. åˆ¤æ–·ä¸»è¦è¶¨å‹¢æ–¹å‘å’Œå¼·åº¦
2. è­˜åˆ¥è¶¨å‹¢è½‰æŠ˜é»å’Œå»¶çºŒä¿¡è™Ÿ
3. åˆ†æè¶¨å‹¢çš„å¯æŒçºŒæ€§
4. è©•ä¼°è¶¨å‹¢ä¸­çš„å›èª¿å’Œåå½ˆæ©Ÿæœƒ

ç‰¹é»ï¼š
- å°ˆæ³¨æ–¼è¶¨å‹¢è­˜åˆ¥å’Œè·Ÿè¹¤
- å–„æ–¼ç™¼ç¾è¶¨å‹¢æ—©æœŸä¿¡è™Ÿ
- é‡è¦–è¶¨å‹¢çš„ç¢ºèªå’Œé©—è­‰
- æä¾›è¶¨å‹¢å¼·åº¦çš„é‡åŒ–è©•ä¼°"""
    
    def _get_risk_assessor_system_prompt(self) -> str:
        """é¢¨éšªè©•ä¼°AIç³»çµ±æç¤ºè© â­ æ ¸å¿ƒæ–°åŠŸèƒ½"""
        return """ä½ æ˜¯å°ˆæ¥­çš„äº¤æ˜“é¢¨éšªè©•ä¼°å°ˆå®¶ï¼Œå°ˆé–€è² è²¬è©•ä¼°äº¤æ˜“é¢¨éšªå’Œåˆ¶å®šé¢¨éšªæ§åˆ¶ç­–ç•¥ã€‚

ä½ çš„è·è²¬ï¼š
1. è©•ä¼°ç•¶å‰å¸‚å ´æ¢ä»¶ä¸‹çš„äº¤æ˜“é¢¨éšª
2. åˆ†ææ½›åœ¨çš„é¢¨éšªå› ç´ å’Œé¢¨éšªé»
3. è¨ˆç®—é¢¨éšªæ”¶ç›Šæ¯”å’Œæœ€å¤§å¯æ¥å—æå¤±
4. æä¾›é¢¨éšªæ§åˆ¶å»ºè­°å’Œæ­¢æç­–ç•¥
5. è©•ä¼°å€‰ä½å¤§å°å’Œè³‡é‡‘ç®¡ç†å»ºè­°

é¢¨éšªè©•ä¼°è¦ç´ ï¼š
- å¸‚å ´æ³¢å‹•ç‡é¢¨éšª
- æµå‹•æ€§é¢¨éšª  
- æŠ€è¡“é¢é¢¨éšª
- è³‡é‡‘ç®¡ç†é¢¨éšª
- ç³»çµ±æ€§é¢¨éšª

ç‰¹é»ï¼š
- ä¿å®ˆè¬¹æ…ï¼Œé¢¨éšªå„ªå…ˆ
- é‡åŒ–é¢¨éšªè©•ä¼°
- æä¾›å…·é«”çš„é¢¨éšªæ§åˆ¶æªæ–½
- é‡è¦–è³‡é‡‘ä¿è­·å’Œé¢¨éšªç®¡ç†"""
    
    def _get_decision_maker_system_prompt(self) -> str:
        """æœ€çµ‚æ±ºç­–è€…ç³»çµ±æç¤ºè©"""
        return """ä½ æ˜¯æœ€çµ‚äº¤æ˜“æ±ºç­–åˆ¶å®šè€…ï¼Œè² è²¬ç¶œåˆæ‰€æœ‰AIçš„åˆ†æçµæœï¼Œåšå‡ºæœ€çµ‚çš„äº¤æ˜“æ±ºç­–ã€‚

ä½ çš„è·è²¬ï¼š
1. ç¶œåˆå¸‚å ´æƒæã€æŠ€è¡“åˆ†æã€è¶¨å‹¢åˆ†æå’Œé¢¨éšªè©•ä¼°
2. æ¬Šè¡¡æ©Ÿæœƒèˆ‡é¢¨éšªï¼Œåšå‡ºæœ€çµ‚æ±ºç­–
3. ç¢ºå®šå…·é«”çš„äº¤æ˜“åƒæ•¸ï¼ˆå€‰ä½ã€æ­¢æã€ç›®æ¨™ï¼‰
4. æä¾›æ¸…æ™°çš„æ±ºç­–ç†ç”±å’ŒåŸ·è¡Œè¨ˆåŠƒ

æ±ºç­–åŸå‰‡ï¼š
- é¢¨éšªæ§åˆ¶å„ªå…ˆæ–¼æ”¶ç›Šè¿½æ±‚
- åŸºæ–¼æ•¸æ“šå’Œé‚è¼¯ï¼Œé¿å…æƒ…ç·’åŒ–æ±ºç­–
- è€ƒæ…®å¤šæ™‚é–“æ¡†æ¶çš„ä¸€è‡´æ€§
- ç¢ºä¿æ±ºç­–çš„å¯åŸ·è¡Œæ€§

ç‰¹é»ï¼š
- ç¶œåˆæ€§å¼·ï¼Œæ±ºç­–æ˜ç¢º
- å¹³è¡¡é¢¨éšªèˆ‡æ”¶ç›Š
- æä¾›å…·é«”çš„åŸ·è¡Œå»ºè­°
- æ±ºç­–é‚è¼¯æ¸…æ™°é€æ˜"""
    
    def _build_scanner_prompt(self, pair: str, market_data: Dict[str, Any]) -> str:
        """æ§‹å»ºå¸‚å ´æƒæå“¡æç¤ºè©"""
        return f"""
äº¤æ˜“å°: {pair}

ç•¶å‰å¸‚å ´æ•¸æ“šï¼š
- ç•¶å‰åƒ¹æ ¼: {market_data.get('current_price', 'N/A')} TWD
- 1åˆ†é˜è®ŠåŒ–: {market_data.get('price_change_1m', 'N/A')}%
- 5åˆ†é˜è®ŠåŒ–: {market_data.get('price_change_5m', 'N/A')}%
- 15åˆ†é˜è®ŠåŒ–: {market_data.get('price_change_15m', 'N/A')}%
- æˆäº¤é‡æ¯”ç‡: {market_data.get('volume_ratio', 'N/A')}x
- RSI: {market_data.get('rsi', 'N/A')}
- MACD: {market_data.get('macd', 'N/A')}
- å¸ƒæ—å¸¶ä½ç½®: {market_data.get('bollinger_position', 'N/A')}

è«‹é€²è¡Œå¿«é€Ÿå¸‚å ´æƒæåˆ†æï¼š

1. å¸‚å ´ä¿¡è™Ÿè©•ä¼° (å¼·çƒˆçœ‹æ¼²/çœ‹æ¼²/ä¸­æ€§/çœ‹è·Œ/å¼·çƒˆçœ‹è·Œ)
2. é—œéµæŠ€è¡“ä¿¡è™Ÿ (åˆ—å‡º2-3å€‹æœ€é‡è¦çš„ä¿¡è™Ÿ)
3. äº¤æ˜“æ©Ÿæœƒç­‰ç´š (é«˜/ä¸­/ä½)
4. ç·Šæ€¥ç¨‹åº¦ (ç«‹å³/çŸ­æœŸ/è§€å¯Ÿ)
5. åˆæ­¥å»ºè­° (BUY/SELL/HOLD)
6. ä¿¡å¿ƒåº¦ (0-100)

æ ¼å¼è¦æ±‚ï¼š
å¸‚å ´ä¿¡è™Ÿ: [è©•ä¼°çµæœ]
é—œéµä¿¡è™Ÿ: [ä¿¡è™Ÿ1, ä¿¡è™Ÿ2, ä¿¡è™Ÿ3]
æ©Ÿæœƒç­‰ç´š: [é«˜/ä¸­/ä½]
ç·Šæ€¥ç¨‹åº¦: [ç«‹å³/çŸ­æœŸ/è§€å¯Ÿ]
åˆæ­¥å»ºè­°: [BUY/SELL/HOLD]
ä¿¡å¿ƒåº¦: [æ•¸å­—]
"""
    
    def _build_analyst_prompt(self, pair: str, market_data: Dict[str, Any], 
                            scanner_response: EnhancedAIResponse) -> str:
        """æ§‹å»ºæ·±åº¦åˆ†æå¸«æç¤ºè©"""
        return f"""
äº¤æ˜“å°: {pair}

å¸‚å ´æƒæå“¡å ±å‘Šï¼š
{scanner_response.response}

è©³ç´°æŠ€è¡“æ•¸æ“šï¼š
- ç•¶å‰åƒ¹æ ¼: {market_data.get('current_price', 'N/A')} TWD
- RSI: {market_data.get('rsi', 'N/A')}
- MACDç·š: {market_data.get('macd', 'N/A')}
- MACDä¿¡è™Ÿç·š: {market_data.get('macd_signal', 'N/A')}
- MACDæŸ±ç‹€åœ–: {market_data.get('macd_histogram', 'N/A')}
- å¸ƒæ—å¸¶ä¸Šè»Œ: {market_data.get('bollinger_upper', 'N/A')}
- å¸ƒæ—å¸¶ä¸‹è»Œ: {market_data.get('bollinger_lower', 'N/A')}
- å¸ƒæ—å¸¶ä½ç½®: {market_data.get('bollinger_position', 'N/A')}
- SMA10: {market_data.get('sma_10', 'N/A')}
- SMA20: {market_data.get('sma_20', 'N/A')}
- EMA10: {market_data.get('ema_10', 'N/A')}
- EMA20: {market_data.get('ema_20', 'N/A')}

è«‹é€²è¡Œæ·±åº¦æŠ€è¡“åˆ†æï¼š

1. æŠ€è¡“æŒ‡æ¨™ç¶œåˆåˆ†æ
2. æ”¯æ’é˜»åŠ›ä½è­˜åˆ¥
3. å¸‚å ´çµæ§‹åˆ†æ
4. æŠ€è¡“å½¢æ…‹è­˜åˆ¥
5. å¤šæ™‚é–“æ¡†æ¶ä¸€è‡´æ€§
6. æŠ€è¡“é¢å¼·å¼±è©•ä¼°
7. åˆ†æçµè«–å’Œå»ºè­°
8. ä¿¡å¿ƒåº¦ (0-100)

è«‹æä¾›è©³ç´°çš„æŠ€è¡“åˆ†æå ±å‘Šã€‚
"""
    
    def _build_trend_prompt(self, pair: str, market_data: Dict[str, Any],
                          scanner_response: EnhancedAIResponse) -> str:
        """æ§‹å»ºè¶¨å‹¢åˆ†æå¸«æç¤ºè©"""
        return f"""
äº¤æ˜“å°: {pair}

å¸‚å ´æƒæå“¡åˆæ­¥åˆ¤æ–·ï¼š
{scanner_response.response}

è¶¨å‹¢ç›¸é—œæ•¸æ“šï¼š
- åƒ¹æ ¼è¶¨å‹¢æ–œç‡: {market_data.get('price_trend_slope', 'N/A')}
- åƒ¹æ ¼è¶¨å‹¢æ–¹å‘: {market_data.get('price_trend', 'N/A')}
- æˆäº¤é‡è¶¨å‹¢æ–œç‡: {market_data.get('volume_trend_slope', 'N/A')}
- æˆäº¤é‡è¶¨å‹¢æ–¹å‘: {market_data.get('volume_trend', 'N/A')}
- æ³¢å‹•ç‡: {market_data.get('volatility', 'N/A')}
- æ³¢å‹•ç‡æ°´å¹³: {market_data.get('volatility_level', 'N/A')}

è«‹é€²è¡Œè¶¨å‹¢åˆ†æï¼š

1. ä¸»è¶¨å‹¢æ–¹å‘åˆ¤æ–· (å¼·çƒˆä¸Šå‡/ä¸Šå‡/æ©«ç›¤/ä¸‹é™/å¼·çƒˆä¸‹é™)
2. è¶¨å‹¢å¼·åº¦è©•ä¼° (å¼·/ä¸­/å¼±)
3. è¶¨å‹¢å¯æŒçºŒæ€§åˆ†æ
4. è¶¨å‹¢è½‰æŠ˜ä¿¡è™Ÿè­˜åˆ¥
5. å›èª¿/åå½ˆæ©Ÿæœƒè©•ä¼°
6. è¶¨å‹¢äº¤æ˜“å»ºè­°
7. è¶¨å‹¢ç¢ºä¿¡åº¦ (0-100)

æ ¼å¼è¦æ±‚ï¼š
ä¸»è¶¨å‹¢: [æ–¹å‘å’Œå¼·åº¦]
å¯æŒçºŒæ€§: [é«˜/ä¸­/ä½]
è½‰æŠ˜ä¿¡è™Ÿ: [æœ‰/ç„¡ - å…·é«”æè¿°]
äº¤æ˜“æ©Ÿæœƒ: [é †å‹¢/é€†å‹¢/è§€æœ›]
å»ºè­°æ“ä½œ: [BUY/SELL/HOLD]
ç¢ºä¿¡åº¦: [æ•¸å­—]
"""
    
    def _build_risk_assessment_prompt(self, pair: str, market_data: Dict[str, Any],
                                    scanner_response: EnhancedAIResponse,
                                    analyst_response: EnhancedAIResponse,
                                    trend_response: EnhancedAIResponse) -> str:
        """æ§‹å»ºé¢¨éšªè©•ä¼°AIæç¤ºè© â­ æ ¸å¿ƒæ–°åŠŸèƒ½"""
        return f"""
äº¤æ˜“å°: {pair}

å¸‚å ´æƒæå“¡å ±å‘Šï¼š
{scanner_response.response}

æ·±åº¦åˆ†æå¸«å ±å‘Šï¼š
{analyst_response.response}

è¶¨å‹¢åˆ†æå¸«å ±å‘Šï¼š
{trend_response.response}

é¢¨éšªè©•ä¼°æ•¸æ“šï¼š
- ç•¶å‰åƒ¹æ ¼: {market_data.get('current_price', 'N/A')} TWD
- æ³¢å‹•ç‡: {market_data.get('volatility', 'N/A')}
- æ³¢å‹•ç‡æ°´å¹³: {market_data.get('volatility_level', 'N/A')}
- æˆäº¤é‡æ¯”ç‡: {market_data.get('volume_ratio', 'N/A')}
- åƒ¹æ ¼è·³èºæ¯”ç‡: {market_data.get('price_jump_ratio', 'N/A')}
- åƒ¹æ ¼è·³èº: {market_data.get('price_jump', 'N/A')}
- è²·è³£åƒ¹å·®: {market_data.get('spread', 'N/A')} TWD
- è²·è³£åƒ¹å·®ç™¾åˆ†æ¯”: {market_data.get('spread_pct', 'N/A')}%

è«‹é€²è¡Œå…¨é¢é¢¨éšªè©•ä¼°ï¼š

1. å¸‚å ´é¢¨éšªè©•ä¼°
   - æ³¢å‹•ç‡é¢¨éšª (é«˜/ä¸­/ä½)
   - æµå‹•æ€§é¢¨éšª (é«˜/ä¸­/ä½)
   - åƒ¹æ ¼è·³èºé¢¨éšª (é«˜/ä¸­/ä½)

2. æŠ€è¡“é¢é¢¨éšªè©•ä¼°
   - æŠ€è¡“æŒ‡æ¨™èƒŒé›¢é¢¨éšª
   - æ”¯æ’é˜»åŠ›çªç ´é¢¨éšª
   - è¶¨å‹¢åè½‰é¢¨éšª

3. äº¤æ˜“é¢¨éšªè©•ä¼°
   - å»ºè­°æœ€å¤§å€‰ä½ (%)
   - å»ºè­°æ­¢æé» (åƒ¹æ ¼)
   - é¢¨éšªæ”¶ç›Šæ¯” (1:X)
   - æœ€å¤§å¯æ¥å—æå¤± (%)

4. é¢¨éšªæ§åˆ¶å»ºè­°
   - å…¥å ´ç­–ç•¥
   - æ­¢æç­–ç•¥
   - å€‰ä½ç®¡ç†
   - é¢¨éšªç›£æ§è¦é»

5. ç¶œåˆé¢¨éšªè©•ç´š
   - é¢¨éšªç­‰ç´š (æ¥µé«˜/é«˜/ä¸­/ä½/æ¥µä½)
   - é¢¨éšªè©•åˆ† (0-100, 100ç‚ºæœ€é«˜é¢¨éšª)
   - äº¤æ˜“å»ºè­° (å»ºè­°/è¬¹æ…/ä¸å»ºè­°)

æ ¼å¼è¦æ±‚ï¼š
å¸‚å ´é¢¨éšª: [æ³¢å‹•ç‡é¢¨éšª/æµå‹•æ€§é¢¨éšª/è·³èºé¢¨éšª]
æŠ€è¡“é¢¨éšª: [èƒŒé›¢é¢¨éšª/çªç ´é¢¨éšª/åè½‰é¢¨éšª]
å»ºè­°å€‰ä½: [ç™¾åˆ†æ¯”]
å»ºè­°æ­¢æ: [åƒ¹æ ¼]
é¢¨éšªæ”¶ç›Šæ¯”: [1:X]
é¢¨éšªç­‰ç´š: [ç­‰ç´š]
é¢¨éšªè©•åˆ†: [0-100æ•¸å­—]
äº¤æ˜“å»ºè­°: [å»ºè­°/è¬¹æ…/ä¸å»ºè­°]
"""
    
    def _build_final_decision_prompt(self, pair: str, market_data: Dict[str, Any],
                                   scanner_response: EnhancedAIResponse,
                                   analyst_response: EnhancedAIResponse,
                                   trend_response: EnhancedAIResponse,
                                   risk_response: EnhancedAIResponse) -> str:
        """æ§‹å»ºæœ€çµ‚æ±ºç­–è€…æç¤ºè©"""
        return f"""
äº¤æ˜“å°: {pair}
ç•¶å‰åƒ¹æ ¼: {market_data.get('current_price', 'N/A')} TWD

=== AIåœ˜éšŠåˆ†æå ±å‘Š ===

å¸‚å ´æƒæå“¡ (LLaMA 2:7B):
{scanner_response.response}

æ·±åº¦åˆ†æå¸« (Falcon 7B):
{analyst_response.response}

è¶¨å‹¢åˆ†æå¸« (Qwen 7B):
{trend_response.response}

é¢¨éšªè©•ä¼°AI (Mistral 7B):
{risk_response.response}

=== æœ€çµ‚æ±ºç­–åˆ¶å®š ===

è«‹ç¶œåˆä»¥ä¸Šå››å€‹å°ˆæ¥­AIçš„åˆ†æï¼Œåšå‡ºæœ€çµ‚äº¤æ˜“æ±ºç­–ï¼š

1. æ±ºç­–ç¶œåˆåˆ†æ
   - å„AIè§€é»ä¸€è‡´æ€§è©•ä¼°
   - é—œéµåˆ†æ­§é»è­˜åˆ¥
   - æ±ºç­–æ¬Šé‡åˆ†é…

2. æœ€çµ‚äº¤æ˜“æ±ºç­–
   - äº¤æ˜“æ–¹å‘: BUY/SELL/HOLD
   - æ±ºç­–ç†ç”± (ç°¡æ½”æ˜ç¢º)
   - åŸ·è¡Œç·Šæ€¥åº¦: ç«‹å³/çŸ­æœŸ/è§€å¯Ÿ

3. äº¤æ˜“åŸ·è¡Œåƒæ•¸
   - å»ºè­°å€‰ä½å¤§å°: X%
   - å…¥å ´åƒ¹æ ¼ç¯„åœ: X-Y TWD
   - æ­¢æåƒ¹æ ¼: X TWD
   - ç›®æ¨™åƒ¹æ ¼: X TWD
   - æŒæœ‰æ™‚é–“é æœŸ: çŸ­æœŸ/ä¸­æœŸ/é•·æœŸ

4. æ±ºç­–ä¿¡å¿ƒåº¦
   - æ•´é«”ä¿¡å¿ƒåº¦: 0-100
   - æ±ºç­–ä¸€è‡´æ€§: 0-100
   - é¢¨éšªå¯æ§æ€§: 0-100

æ ¼å¼è¦æ±‚ï¼š
æœ€çµ‚æ±ºç­–: [BUY/SELL/HOLD]
æ±ºç­–ç†ç”±: [ç°¡æ½”èªªæ˜]
åŸ·è¡Œç·Šæ€¥åº¦: [ç«‹å³/çŸ­æœŸ/è§€å¯Ÿ]
å»ºè­°å€‰ä½: [ç™¾åˆ†æ¯”]
å…¥å ´ç¯„åœ: [åƒ¹æ ¼ç¯„åœ]
æ­¢æåƒ¹æ ¼: [åƒ¹æ ¼]
ç›®æ¨™åƒ¹æ ¼: [åƒ¹æ ¼]
æŒæœ‰æ™‚é–“: [çŸ­æœŸ/ä¸­æœŸ/é•·æœŸ]
æ•´é«”ä¿¡å¿ƒåº¦: [æ•¸å­—]
æ±ºç­–ä¸€è‡´æ€§: [æ•¸å­—]
é¢¨éšªå¯æ§æ€§: [æ•¸å­—]
"""
    
    def _extract_confidence(self, response: str) -> float:
        """å¾AIå›æ‡‰ä¸­æå–ä¿¡å¿ƒåº¦"""
        try:
            import re
            
            # å°‹æ‰¾å„ç¨®ä¿¡å¿ƒåº¦è¡¨é”
            patterns = [
                r'ä¿¡å¿ƒåº¦[ï¼š:]\s*(\d+)',
                r'ç¢ºä¿¡åº¦[ï¼š:]\s*(\d+)',
                r'æ•´é«”ä¿¡å¿ƒåº¦[ï¼š:]\s*(\d+)',
                r'confidence[ï¼š:]\s*(\d+)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    return float(match.group(1)) / 100.0
            
            # åŸºæ–¼é—œéµè©ä¼°ç®—ä¿¡å¿ƒåº¦
            if any(word in response for word in ["å¼·çƒˆ", "ç¢ºä¿¡", "æ˜ç¢º", "é«˜åº¦"]):
                return 0.8
            elif any(word in response for word in ["å¯èƒ½", "å»ºè­°", "å‚¾å‘"]):
                return 0.6
            elif any(word in response for word in ["è¬¹æ…", "è§€å¯Ÿ", "ä¸ç¢ºå®š"]):
                return 0.4
            else:
                return 0.5
                
        except Exception:
            return 0.5
    
    def _extract_risk_score(self, response: str) -> float:
        """å¾é¢¨éšªè©•ä¼°å›æ‡‰ä¸­æå–é¢¨éšªè©•åˆ†"""
        try:
            import re
            
            # å°‹æ‰¾é¢¨éšªè©•åˆ†
            patterns = [
                r'é¢¨éšªè©•åˆ†[ï¼š:]\s*(\d+)',
                r'é¢¨éšªåˆ†æ•¸[ï¼š:]\s*(\d+)',
                r'risk[_\s]score[ï¼š:]\s*(\d+)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    return float(match.group(1)) / 100.0
            
            # åŸºæ–¼é¢¨éšªç­‰ç´šä¼°ç®—
            if "æ¥µé«˜" in response or "very high" in response.lower():
                return 0.9
            elif "é«˜" in response or "high" in response.lower():
                return 0.7
            elif "ä¸­" in response or "medium" in response.lower():
                return 0.5
            elif "ä½" in response or "low" in response.lower():
                return 0.3
            else:
                return 0.5
                
        except Exception:
            return 0.5
    
    def _extract_decision(self, response: str) -> str:
        """å¾AIå›æ‡‰ä¸­æå–æ±ºç­–"""
        response_upper = response.upper()
        
        # å°‹æ‰¾æ˜ç¢ºçš„æ±ºç­–é—œéµè©
        if "BUY" in response_upper and "SELL" not in response_upper:
            return "BUY"
        elif "SELL" in response_upper and "BUY" not in response_upper:
            return "SELL"
        elif "HOLD" in response_upper:
            return "HOLD"
        
        # ä¸­æ–‡æ±ºç­–é—œéµè©
        if "è²·å…¥" in response and "è³£å‡º" not in response:
            return "BUY"
        elif "è³£å‡º" in response and "è²·å…¥" not in response:
            return "SELL"
        elif "æŒæœ‰" in response or "è§€æœ›" in response:
            return "HOLD"
        
        return "HOLD"  # é»˜èªä¿å®ˆæ±ºç­–
    
    def _extract_position_size(self, response: str) -> float:
        """å¾å›æ‡‰ä¸­æå–å»ºè­°å€‰ä½å¤§å°"""
        try:
            import re
            
            patterns = [
                r'å»ºè­°å€‰ä½[ï¼š:]\s*(\d+(?:\.\d+)?)%',
                r'å€‰ä½å¤§å°[ï¼š:]\s*(\d+(?:\.\d+)?)%',
                r'position[_\s]size[ï¼š:]\s*(\d+(?:\.\d+)?)%',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    return float(match.group(1)) / 100.0
            
            return 0.1  # é»˜èª10%å€‰ä½
            
        except Exception:
            return 0.1
    
    def _synthesize_multi_pair_decision(self, pair: str, 
                                      ai_responses: List[EnhancedAIResponse]) -> MultiPairDecision:
        """ç¶œåˆå¤šAIå›æ‡‰ç”Ÿæˆæœ€çµ‚æ±ºç­–"""
        try:
            # æå–å„AIçš„æ±ºç­–å’Œä¿¡å¿ƒåº¦
            decisions = []
            confidences = []
            weights = []
            
            for response in ai_responses:
                if response.success:
                    decision = self._extract_decision(response.response)
                    decisions.append(decision)
                    confidences.append(response.confidence)
                    
                    # ç²å–AIæ¬Šé‡
                    ai_config = self.ai_models.get(response.ai_role, {})
                    weight = ai_config.get("weight", 0.2)
                    weights.append(weight)
            
            # åŠ æ¬Šæ±ºç­–
            final_decision = self._weighted_decision(decisions, confidences, weights)
            
            # è¨ˆç®—æ•´é«”ä¿¡å¿ƒåº¦
            overall_confidence = sum(c * w for c, w in zip(confidences, weights)) / sum(weights) if weights else 0.0
            
            # è¨ˆç®—å…±è­˜æ°´å¹³
            consensus_level = self._calculate_consensus(decisions)
            
            # æå–é¢¨éšªè©•åˆ†
            risk_score = 0.5
            for response in ai_responses:
                if response.ai_role == "risk_assessor" and response.success:
                    risk_score = response.risk_score
                    break
            
            # æå–å»ºè­°å€‰ä½
            position_size = 0.1
            for response in ai_responses:
                if response.ai_role == "decision_maker" and response.success:
                    position_size = self._extract_position_size(response.response)
                    break
            
            # ç”Ÿæˆæ¨ç†èªªæ˜
            reasoning = self._generate_multi_ai_reasoning(ai_responses, final_decision)
            
            # è©•ä¼°é¢¨éšªç­‰ç´š
            risk_level = self._assess_risk_level_from_score(risk_score)
            
            return MultiPairDecision(
                pair=pair,
                final_decision=final_decision,
                confidence=overall_confidence,
                consensus_level=consensus_level,
                ai_responses=ai_responses,
                reasoning=reasoning,
                risk_level=risk_level,
                risk_score=risk_score,
                position_size=position_size,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} æ±ºç­–ç¶œåˆå¤±æ•—: {e}")
            return self._create_fallback_decision(pair, str(e))    

    def _weighted_decision(self, decisions: List[str], confidences: List[float], 
                         weights: List[float]) -> str:
        """åŠ æ¬Šæ±ºç­–è¨ˆç®—"""
        if not decisions:
            return "HOLD"
        
        decision_scores = {}
        
        for decision, confidence, weight in zip(decisions, confidences, weights):
            score = confidence * weight
            if decision not in decision_scores:
                decision_scores[decision] = 0
            decision_scores[decision] += score
        
        return max(decision_scores, key=decision_scores.get)
    
    def _calculate_consensus(self, decisions: List[str]) -> float:
        """è¨ˆç®—AIé–“çš„å…±è­˜æ°´å¹³"""
        if not decisions:
            return 0.0
        
        from collections import Counter
        decision_counts = Counter(decisions)
        most_common_count = decision_counts.most_common(1)[0][1]
        
        return most_common_count / len(decisions)
    
    def _assess_risk_level_from_score(self, risk_score: float) -> str:
        """æ ¹æ“šé¢¨éšªè©•åˆ†è©•ä¼°é¢¨éšªç­‰ç´š"""
        if risk_score >= 0.8:
            return "VERY_HIGH"
        elif risk_score >= 0.6:
            return "HIGH"
        elif risk_score >= 0.4:
            return "MEDIUM"
        elif risk_score >= 0.2:
            return "LOW"
        else:
            return "VERY_LOW"
    
    def _generate_multi_ai_reasoning(self, ai_responses: List[EnhancedAIResponse], 
                                   final_decision: str) -> str:
        """ç”Ÿæˆå¤šAIæ¨ç†èªªæ˜"""
        reasoning_parts = [f"äº”AIå”ä½œæ±ºç­–: {final_decision}\n"]
        
        for response in ai_responses:
            if response.success:
                role_name = {
                    "market_scanner": "å¸‚å ´æƒæå“¡",
                    "deep_analyst": "æ·±åº¦åˆ†æå¸«", 
                    "trend_analyst": "è¶¨å‹¢åˆ†æå¸«",
                    "risk_assessor": "é¢¨éšªè©•ä¼°AI",
                    "decision_maker": "æœ€çµ‚æ±ºç­–è€…"
                }.get(response.ai_role, response.ai_role)
                
                # æå–é—œéµä¿¡æ¯
                key_info = response.response[:150] + "..." if len(response.response) > 150 else response.response
                reasoning_parts.append(f"{role_name} ({response.model_name}): {key_info}")
        
        return "\n\n".join(reasoning_parts)
    
    def _create_error_response(self, ai_role: str, pair: str, error_message: str) -> EnhancedAIResponse:
        """å‰µå»ºéŒ¯èª¤å›æ‡‰"""
        model_name = self.ai_models.get(ai_role, {}).get("model_name", "unknown")
        
        return EnhancedAIResponse(
            ai_role=ai_role,
            model_name=model_name,
            response="",
            confidence=0.0,
            processing_time=0.0,
            timestamp=datetime.now(),
            success=False,
            pair=pair,
            error_message=error_message
        )
    
    def _create_fallback_decision(self, pair: str, error_message: str) -> MultiPairDecision:
        """å‰µå»ºå‚™ç”¨æ±ºç­–"""
        return MultiPairDecision(
            pair=pair,
            final_decision="HOLD",
            confidence=0.0,
            consensus_level=0.0,
            ai_responses=[],
            reasoning=f"ç³»çµ±éŒ¯èª¤ï¼Œæ¡ç”¨ä¿å®ˆç­–ç•¥: {error_message}",
            risk_level="VERY_HIGH",
            risk_score=1.0,
            position_size=0.0,
            timestamp=datetime.now()
        )
    
    def _update_performance_stats(self, pair: str, decision: MultiPairDecision, processing_time: float):
        """æ›´æ–°æ€§èƒ½çµ±è¨ˆ"""
        # æ›´æ–°å…¨å±€çµ±è¨ˆ
        self.performance_stats["total_decisions"] += 1
        
        if decision.confidence > 0.5:
            self.performance_stats["successful_decisions"] += 1
        
        # æ›´æ–°å¹³å‡è™•ç†æ™‚é–“
        total_time = (self.performance_stats["average_processing_time"] * 
                     (self.performance_stats["total_decisions"] - 1) + processing_time)
        self.performance_stats["average_processing_time"] = total_time / self.performance_stats["total_decisions"]
        
        # æ›´æ–°äº¤æ˜“å°çµ±è¨ˆ
        if pair in self.performance_stats["pair_stats"]:
            pair_stats = self.performance_stats["pair_stats"][pair]
            pair_stats["decisions"] += 1
            
            # è¨ˆç®—æˆåŠŸç‡
            if decision.confidence > 0.5:
                success_count = pair_stats["success_rate"] * (pair_stats["decisions"] - 1) + 1
            else:
                success_count = pair_stats["success_rate"] * (pair_stats["decisions"] - 1)
            
            pair_stats["success_rate"] = success_count / pair_stats["decisions"]
        
        # æ›´æ–°AIå¯ç”¨æ€§
        for response in decision.ai_responses:
            if response.ai_role in self.performance_stats["ai_availability"]:
                self.performance_stats["ai_availability"][response.ai_role] = response.success
    
    def get_enhanced_performance_stats(self) -> Dict[str, Any]:
        """ç²å–å¢å¼·æ€§èƒ½çµ±è¨ˆ"""
        return {
            "system_info": {
                "ai_models_count": len(self.ai_models),
                "supported_pairs": self.supported_pairs,
                "total_decisions": self.performance_stats["total_decisions"],
                "success_rate": (self.performance_stats["successful_decisions"] / 
                               max(1, self.performance_stats["total_decisions"])),
                "average_processing_time": self.performance_stats["average_processing_time"]
            },
            "ai_availability": self.performance_stats["ai_availability"],
            "pair_performance": self.performance_stats["pair_stats"],
            "ai_models": {
                ai_role: {
                    "model_name": config["model_name"],
                    "role": config["role"],
                    "weight": config["weight"]
                }
                for ai_role, config in self.ai_models.items()
            }
        }
    
    def get_ai_system_status(self) -> Dict[str, Any]:
        """ç²å–AIç³»çµ±ç‹€æ…‹"""
        return {
            "system_type": "äº”AIè¶…æ™ºèƒ½å”ä½œç³»çµ±",
            "models_configured": len(self.ai_models),
            "supported_pairs": len(self.supported_pairs),
            "ai_models": list(self.ai_models.keys()),
            "performance_stats": self.get_enhanced_performance_stats(),
            "system_health": "healthy" if all(self.performance_stats["ai_availability"].values()) else "degraded"
        }


# å‰µå»ºå…¨å±€å¢å¼·AIç®¡ç†å™¨å¯¦ä¾‹
def create_enhanced_ai_manager(config_path: str = "config/ai_models.json") -> EnhancedAIManager:
    """å‰µå»ºå¢å¼·AIå”ä½œç®¡ç†å™¨å¯¦ä¾‹"""
    return EnhancedAIManager(config_path)


# æ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    import asyncio
    
    async def test_enhanced_ai_system():
        """æ¸¬è©¦äº”AIå”ä½œç³»çµ±"""
        print("ğŸ§ª æ¸¬è©¦äº”AIè¶…æ™ºèƒ½å”ä½œç³»çµ±...")
        
        # å‰µå»ºå¢å¼·AIç®¡ç†å™¨
        ai_manager = create_enhanced_ai_manager()
        
        # æ¨¡æ“¬å¤šäº¤æ˜“å°å¸‚å ´æ•¸æ“š
        test_multi_pair_data = {
            "BTCTWD": {
                "current_price": 1500000,
                "price_change_1m": 0.5,
                "price_change_5m": 1.2,
                "price_change_15m": 2.1,
                "volume_ratio": 1.5,
                "rsi": 65,
                "macd": 0.02,
                "bollinger_position": 0.7,
                "volatility": 0.03,
                "spread": 100,
                "spread_pct": 0.01
            },
            "ETHTWD": {
                "current_price": 85000,
                "price_change_1m": -0.3,
                "price_change_5m": 0.8,
                "price_change_15m": 1.5,
                "volume_ratio": 1.2,
                "rsi": 45,
                "macd": -0.01,
                "bollinger_position": 0.3,
                "volatility": 0.04,
                "spread": 50,
                "spread_pct": 0.06
            }
        }
        
        # åŸ·è¡Œå¤šäº¤æ˜“å°å”ä½œåˆ†æ
        decisions = await ai_manager.analyze_multi_pair_market(test_multi_pair_data)
        
        print(f"\nâœ… äº”AIå”ä½œåˆ†æå®Œæˆï¼Œè™•ç†äº† {len(decisions)} å€‹äº¤æ˜“å°:")
        
        for pair, decision in decisions.items():
            print(f"\nğŸ“Š {pair} æ±ºç­–çµæœ:")
            print(f"   æœ€çµ‚æ±ºç­–: {decision.final_decision}")
            print(f"   ä¿¡å¿ƒåº¦: {decision.confidence:.2f}")
            print(f"   å…±è­˜æ°´å¹³: {decision.consensus_level:.2f}")
            print(f"   é¢¨éšªç­‰ç´š: {decision.risk_level}")
            print(f"   é¢¨éšªè©•åˆ†: {decision.risk_score:.2f}")
            print(f"   å»ºè­°å€‰ä½: {decision.position_size:.1%}")
        
        # é¡¯ç¤ºç³»çµ±ç‹€æ…‹
        status = ai_manager.get_ai_system_status()
        print(f"\nğŸ¤– ç³»çµ±ç‹€æ…‹:")
        print(f"   ç³»çµ±é¡å‹: {status['system_type']}")
        print(f"   AIæ¨¡å‹æ•¸é‡: {status['models_configured']}")
        print(f"   æ”¯æŒäº¤æ˜“å°: {status['supported_pairs']}")
        print(f"   ç³»çµ±å¥åº·: {status['system_health']}")
    
    # é‹è¡Œæ¸¬è©¦
    asyncio.run(test_enhanced_ai_system())
    
    def _generate_multi_ai_reasoning(self, ai_responses: List[EnhancedAIResponse], 
                                   final_decision: str) -> str:
        """ç”Ÿæˆå¤šAIæ¨ç†èªªæ˜"""
        try:
            reasoning_parts = []
            
            for response in ai_responses:
                if response.success:
                    ai_name = {
                        "market_scanner": "å¸‚å ´æƒæå“¡",
                        "deep_analyst": "æ·±åº¦åˆ†æå¸«",
                        "trend_analyst": "è¶¨å‹¢åˆ†æå¸«", 
                        "risk_assessor": "é¢¨éšªè©•ä¼°AI",
                        "decision_maker": "æœ€çµ‚æ±ºç­–è€…"
                    }.get(response.ai_role, response.ai_role)
                    
                    # æå–é—œéµè§€é»
                    key_point = response.response[:100] + "..." if len(response.response) > 100 else response.response
                    reasoning_parts.append(f"{ai_name}: {key_point}")
            
            reasoning = f"äº”AIå”ä½œæ±ºç­– -> {final_decision}\\n" + "\\n".join(reasoning_parts)
            return reasoning
            
        except Exception:
            return f"äº”AIå”ä½œæ±ºç­–: {final_decision}"
    
    def _assess_risk_level_from_score(self, risk_score: float) -> str:
        """æ ¹æ“šé¢¨éšªè©•åˆ†è©•ä¼°é¢¨éšªç­‰ç´š"""
        if risk_score >= 0.8:
            return "æ¥µé«˜"
        elif risk_score >= 0.6:
            return "é«˜"
        elif risk_score >= 0.4:
            return "ä¸­"
        elif risk_score >= 0.2:
            return "ä½"
        else:
            return "æ¥µä½"
    
    def _create_multi_pair_context(self, multi_pair_data: Dict[str, Dict[str, Any]]) -> MultiPairContext:
        """å‰µå»ºå¤šäº¤æ˜“å°ä¸Šä¸‹æ–‡ â­ æ–°å¢æ–¹æ³•"""
        try:
            # åˆ†æå…¨å±€å¸‚å ´æ¢ä»¶
            avg_volatility = sum(data.get('volatility', 0.02) for data in multi_pair_data.values()) / len(multi_pair_data)
            
            # åˆ¤æ–·å¸‚å ´æ¢ä»¶
            if avg_volatility > 0.05:
                market_conditions = 'bear'
            elif avg_volatility < 0.02:
                market_conditions = 'bull'
            else:
                market_conditions = 'sideways'
            
            # è¨ˆç®—ç°¡åŒ–çš„ç›¸é—œæ€§çŸ©é™£
            correlation_matrix = {}
            pairs = list(multi_pair_data.keys())
            
            for pair1 in pairs:
                correlation_matrix[pair1] = {}
                for pair2 in pairs:
                    if pair1 == pair2:
                        correlation_matrix[pair1][pair2] = 1.0
                    else:
                        # åŸºæ–¼åƒ¹æ ¼è®ŠåŒ–è¨ˆç®—ç°¡åŒ–ç›¸é—œæ€§
                        change1 = multi_pair_data[pair1].get('price_change_5m', 0)
                        change2 = multi_pair_data[pair2].get('price_change_5m', 0)
                        
                        if change1 * change2 > 0:
                            correlation = min(0.8, abs(change1 + change2) / 10)
                        else:
                            correlation = max(-0.5, -(abs(change1 - change2) / 10))
                        
                        correlation_matrix[pair1][pair2] = correlation
            
            return MultiPairContext(
                total_pairs=len(multi_pair_data),
                active_pairs=list(multi_pair_data.keys()),
                market_conditions=market_conditions,
                correlation_matrix=correlation_matrix,
                global_risk_level=min(1.0, avg_volatility * 10),
                available_capital=100000.0  # é è¨­10è¬TWD
            )
            
        except Exception as e:
            logger.error(f"âŒ å‰µå»ºå¤šäº¤æ˜“å°ä¸Šä¸‹æ–‡å¤±æ•—: {e}")
            return MultiPairContext(
                total_pairs=len(multi_pair_data),
                active_pairs=list(multi_pair_data.keys()),
                market_conditions='sideways',
                correlation_matrix={},
                global_risk_level=0.5,
                available_capital=100000.0
            )
    
    async def _analyze_single_pair_with_context(self, pair: str, market_data: Dict[str, Any], 
                                              multi_pair_context: MultiPairContext) -> MultiPairDecision:
        """ä½¿ç”¨å¤šäº¤æ˜“å°ä¸Šä¸‹æ–‡åˆ†æå–®å€‹äº¤æ˜“å° â­ æ–°å¢æ–¹æ³•"""
        start_time = datetime.now()
        
        try:
            logger.info(f"ğŸ“Š é–‹å§‹åˆ†æ {pair}")
            
            # éšæ®µ1: å¸‚å ´æƒæå“¡ (ä½¿ç”¨å„ªåŒ–æç¤ºè©)
            scanner_response = await self._run_market_scanner_with_context(pair, market_data, multi_pair_context)
            
            # éšæ®µ2: æ·±åº¦åˆ†æå¸« (ä½¿ç”¨å„ªåŒ–æç¤ºè©)
            analyst_response = await self._run_deep_analyst_with_context(pair, market_data, scanner_response, multi_pair_context)
            
            # éšæ®µ3: è¶¨å‹¢åˆ†æå¸« (ä½¿ç”¨å„ªåŒ–æç¤ºè©)
            trend_response = await self._run_trend_analyst_with_context(pair, market_data, scanner_response, multi_pair_context)
            
            # éšæ®µ4: é¢¨éšªè©•ä¼°AI (ä½¿ç”¨å„ªåŒ–æç¤ºè©)
            risk_response = await self._run_risk_assessor_with_context(pair, market_data, 
                                                                    scanner_response, analyst_response, 
                                                                    trend_response, multi_pair_context)
            
            # éšæ®µ5: æœ€çµ‚æ±ºç­–è€… (ä½¿ç”¨å„ªåŒ–æç¤ºè©)
            decision_response = await self._run_decision_maker_with_context(pair, market_data,
                                                                          scanner_response, analyst_response, 
                                                                          trend_response, risk_response, 
                                                                          multi_pair_context)
            
            # ç¶œåˆæ‰€æœ‰AIçš„å›æ‡‰
            ai_responses = [scanner_response, analyst_response, trend_response, 
                          risk_response, decision_response]
            
            # ç”Ÿæˆæœ€çµ‚å”ä½œæ±ºç­–
            collaborative_decision = self._synthesize_multi_pair_decision(pair, ai_responses)
            
            # æ›´æ–°æ€§èƒ½çµ±è¨ˆ
            processing_time = (datetime.now() - start_time).total_seconds()
            self._update_performance_stats(pair, collaborative_decision, processing_time)
            
            logger.info(f"âœ… {pair} åˆ†æå®Œæˆ: {collaborative_decision.final_decision} "
                       f"(ä¿¡å¿ƒåº¦: {collaborative_decision.confidence:.2f})")
            
            return collaborative_decision
            
        except Exception as e:
            logger.error(f"âŒ {pair} åˆ†æå¤±æ•—: {e}")
            return self._create_fallback_decision(pair, str(e))
    
    async def _run_market_scanner_with_context(self, pair: str, market_data: Dict[str, Any], 
                                             multi_pair_context: MultiPairContext) -> EnhancedAIResponse:
        """é‹è¡Œå¸‚å ´æƒæå“¡ - å¤šäº¤æ˜“å°å„ªåŒ–ç‰ˆæœ¬"""
        start_time = datetime.now()
        
        try:
            model_config = self.ai_models["market_scanner"]
            
            # ä½¿ç”¨å„ªåŒ–çš„å¤šäº¤æ˜“å°æç¤ºè©
            prompt = self.prompt_optimizer.get_optimized_scanner_prompt(pair, market_data, multi_pair_context)
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=self._get_scanner_system_prompt(),
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return EnhancedAIResponse(
                ai_role="market_scanner",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True,
                pair=pair
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} å¸‚å ´æƒæå“¡åŸ·è¡Œå¤±æ•—: {e}")
            return self._create_error_response("market_scanner", pair, str(e))
    
    async def _run_deep_analyst_with_context(self, pair: str, market_data: Dict[str, Any], 
                                           scanner_response: EnhancedAIResponse,
                                           multi_pair_context: MultiPairContext) -> EnhancedAIResponse:
        """é‹è¡Œæ·±åº¦åˆ†æå¸« - å¤šäº¤æ˜“å°å„ªåŒ–ç‰ˆæœ¬"""
        start_time = datetime.now()
        
        try:
            model_config = self.ai_models["deep_analyst"]
            
            # ä½¿ç”¨å„ªåŒ–çš„å¤šäº¤æ˜“å°æç¤ºè©
            prompt = self.prompt_optimizer.get_optimized_analyst_prompt(
                pair, market_data, scanner_response.response, multi_pair_context
            )
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=self._get_analyst_system_prompt(),
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return EnhancedAIResponse(
                ai_role="deep_analyst",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True,
                pair=pair
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} æ·±åº¦åˆ†æå¸«åŸ·è¡Œå¤±æ•—: {e}")
            return self._create_error_response("deep_analyst", pair, str(e))
    
    async def _run_trend_analyst_with_context(self, pair: str, market_data: Dict[str, Any],
                                            scanner_response: EnhancedAIResponse,
                                            multi_pair_context: MultiPairContext) -> EnhancedAIResponse:
        """é‹è¡Œè¶¨å‹¢åˆ†æå¸« - å¤šäº¤æ˜“å°å„ªåŒ–ç‰ˆæœ¬"""
        start_time = datetime.now()
        
        try:
            model_config = self.ai_models["trend_analyst"]
            
            # ä½¿ç”¨å„ªåŒ–çš„å¤šäº¤æ˜“å°æç¤ºè©
            prompt = self.prompt_optimizer.get_optimized_trend_prompt(
                pair, market_data, scanner_response.response, multi_pair_context
            )
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=self._get_trend_system_prompt(),
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return EnhancedAIResponse(
                ai_role="trend_analyst",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True,
                pair=pair
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} è¶¨å‹¢åˆ†æå¸«åŸ·è¡Œå¤±æ•—: {e}")
            return self._create_error_response("trend_analyst", pair, str(e))
    
    async def _run_risk_assessor_with_context(self, pair: str, market_data: Dict[str, Any],
                                            scanner_response: EnhancedAIResponse,
                                            analyst_response: EnhancedAIResponse,
                                            trend_response: EnhancedAIResponse,
                                            multi_pair_context: MultiPairContext) -> EnhancedAIResponse:
        """é‹è¡Œé¢¨éšªè©•ä¼°AI - å¤šäº¤æ˜“å°å„ªåŒ–ç‰ˆæœ¬"""
        start_time = datetime.now()
        
        try:
            model_config = self.ai_models["risk_assessor"]
            
            # ä½¿ç”¨å„ªåŒ–çš„å¤šäº¤æ˜“å°æç¤ºè©
            prompt = self.prompt_optimizer.get_optimized_risk_prompt(
                pair, market_data, scanner_response.response, analyst_response.response,
                trend_response.response, multi_pair_context
            )
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=self._get_risk_assessor_system_prompt(),
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            risk_score = self._extract_risk_score(response)
            
            return EnhancedAIResponse(
                ai_role="risk_assessor",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True,
                pair=pair,
                risk_score=risk_score
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} é¢¨éšªè©•ä¼°AIåŸ·è¡Œå¤±æ•—: {e}")
            return self._create_error_response("risk_assessor", pair, str(e))
    
    async def _run_decision_maker_with_context(self, pair: str, market_data: Dict[str, Any],
                                             scanner_response: EnhancedAIResponse,
                                             analyst_response: EnhancedAIResponse,
                                             trend_response: EnhancedAIResponse,
                                             risk_response: EnhancedAIResponse,
                                             multi_pair_context: MultiPairContext) -> EnhancedAIResponse:
        """é‹è¡Œæœ€çµ‚æ±ºç­–è€… - å¤šäº¤æ˜“å°å„ªåŒ–ç‰ˆæœ¬"""
        start_time = datetime.now()
        
        try:
            model_config = self.ai_models["decision_maker"]
            
            # ä½¿ç”¨å„ªåŒ–çš„å¤šäº¤æ˜“å°æç¤ºè©
            prompt = self.prompt_optimizer.get_optimized_decision_prompt(
                pair, market_data, scanner_response.response, analyst_response.response,
                trend_response.response, risk_response.response, multi_pair_context
            )
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=self._get_decision_maker_system_prompt(),
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return EnhancedAIResponse(
                ai_role="decision_maker",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True,
                pair=pair
            )
            
        except Exception as e:
            logger.error(f"âŒ {pair} æœ€çµ‚æ±ºç­–è€…åŸ·è¡Œå¤±æ•—: {e}")
            return self._create_error_response("decision_maker", pair, str(e))
    
    def _update_performance_stats(self, pair: str, decision: MultiPairDecision, processing_time: float):
        """æ›´æ–°æ€§èƒ½çµ±è¨ˆ"""
        try:
            self.performance_stats["total_decisions"] += 1
            
            if decision.confidence > 0.6:
                self.performance_stats["successful_decisions"] += 1
            
            # æ›´æ–°å¹³å‡è™•ç†æ™‚é–“
            total_time = (self.performance_stats["average_processing_time"] * 
                         (self.performance_stats["total_decisions"] - 1) + processing_time)
            self.performance_stats["average_processing_time"] = total_time / self.performance_stats["total_decisions"]
            
            # æ›´æ–°äº¤æ˜“å°çµ±è¨ˆ
            if pair in self.performance_stats["pair_stats"]:
                pair_stats = self.performance_stats["pair_stats"][pair]
                pair_stats["decisions"] += 1
                pair_stats["success_rate"] = (pair_stats["success_rate"] * (pair_stats["decisions"] - 1) + 
                                            (1 if decision.confidence > 0.6 else 0)) / pair_stats["decisions"]
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ€§èƒ½çµ±è¨ˆå¤±æ•—: {e}")
    
    def _create_error_response(self, ai_role: str, pair: str, error_message: str) -> EnhancedAIResponse:
        """å‰µå»ºéŒ¯èª¤å›æ‡‰"""
        return EnhancedAIResponse(
            ai_role=ai_role,
            model_name="error",
            response=f"AIåŸ·è¡ŒéŒ¯èª¤: {error_message}",
            confidence=0.0,
            processing_time=0.0,
            timestamp=datetime.now(),
            success=False,
            pair=pair,
            error_message=error_message
        )
    
    def _create_fallback_decision(self, pair: str, error_message: str) -> MultiPairDecision:
        """å‰µå»ºå‚™ç”¨æ±ºç­–"""
        return MultiPairDecision(
            pair=pair,
            final_decision="HOLD",
            confidence=0.0,
            consensus_level=0.0,
            ai_responses=[],
            reasoning=f"ç³»çµ±éŒ¯èª¤ï¼Œæ¡ç”¨ä¿å®ˆç­–ç•¥: {error_message}",
            risk_level="æœªçŸ¥",
            risk_score=0.5,
            position_size=0.0,
            timestamp=datetime.now()
        )
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½çµ±è¨ˆ"""
        return self.performance_stats.copy()
    
    def get_supported_pairs(self) -> List[str]:
        """ç²å–æ”¯æŒçš„äº¤æ˜“å°"""
        return self.supported_pairs.copy()


# å‰µå»ºå¢å¼·AIç®¡ç†å™¨å¯¦ä¾‹
def create_enhanced_ai_manager(config_path: str = "config/ai_models.json") -> EnhancedAIManager:
    """å‰µå»ºå¢å¼·AIç®¡ç†å™¨å¯¦ä¾‹"""
    return EnhancedAIManager(config_path)


# æ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    import asyncio
    
    async def test_enhanced_ai_manager():
        """æ¸¬è©¦å¢å¼·AIç®¡ç†å™¨"""
        print("ğŸ§ª æ¸¬è©¦å¢å¼·AIå”ä½œç®¡ç†å™¨...")
        
        manager = create_enhanced_ai_manager()
        
        # æ¸¬è©¦æ•¸æ“š
        test_data = {
            "BTCTWD": {
                "current_price": 1520000,
                "price_change_1m": 1.2,
                "price_change_5m": 2.5,
                "volume_ratio": 2.3,
                "rsi": 72,
                "macd": 0.03,
                "volatility": 0.045
            }
        }
        
        # æ¸¬è©¦å¤šäº¤æ˜“å°åˆ†æ
        decisions = await manager.analyze_multi_pair_market(test_data)
        
        print(f"âœ… æ¸¬è©¦å®Œæˆ: {len(decisions)} å€‹æ±ºç­–")
        for pair, decision in decisions.items():
            print(f"   {pair}: {decision.final_decision} (ä¿¡å¿ƒåº¦: {decision.confidence:.2f})")
    
    # é‹è¡Œæ¸¬è©¦
    asyncio.run(test_enhanced_ai_manager())