#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå”ä½œç®¡ç†å™¨ - çµ±ä¸€ç®¡ç†ä¸‰å€‹AIæ¨¡å‹çš„å”ä½œ
"""

import asyncio
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from pathlib import Path

import ollama

logger = logging.getLogger(__name__)

@dataclass
class AIResponse:
    """AIå›æ‡‰æ•¸æ“šçµæ§‹"""
    ai_role: str
    model_name: str
    response: str
    confidence: float
    processing_time: float
    timestamp: datetime
    success: bool
    error_message: Optional[str] = None

@dataclass
class CollaborativeDecision:
    """å”ä½œæ±ºç­–çµæœ"""
    final_decision: str  # BUY, SELL, HOLD
    confidence: float
    consensus_level: float
    ai_responses: List[AIResponse]
    reasoning: str
    risk_level: str
    timestamp: datetime

class AICollaborationManager:
    """AIå”ä½œç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "config/ai_models.json"):
        """
        åˆå§‹åŒ–AIå”ä½œç®¡ç†å™¨
        
        Args:
            config_path: AIæ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾‘
        """
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.ollama_client = ollama.Client()
        
        # AIæ¨¡å‹é…ç½®
        self.models = self.config["ai_models"]
        self.collaboration_settings = self.config["collaboration_settings"]
        self.fallback_settings = self.config["fallback_settings"]
        
        # æ€§èƒ½çµ±è¨ˆ
        self.performance_stats = {
            "total_decisions": 0,
            "successful_decisions": 0,
            "average_processing_time": 0.0,
            "ai_availability": {
                "market_scanner": True,
                "deep_analyst": True,
                "decision_maker": True
            }
        }
        
        logger.info("ğŸ¤– AIå”ä½œç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self) -> Dict[str, Any]:
        """è¼‰å…¥AIæ¨¡å‹é…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"âœ… è¼‰å…¥AIé…ç½®: {self.config_path}")
            return config
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥AIé…ç½®å¤±æ•—: {e}")
            raise
    
    async def analyze_market_collaboratively(self, market_data: Dict[str, Any]) -> CollaborativeDecision:
        """
        å”ä½œåˆ†æå¸‚å ´æ•¸æ“š
        
        Args:
            market_data: å¸‚å ´æ•¸æ“š
            
        Returns:
            CollaborativeDecision: å”ä½œæ±ºç­–çµæœ
        """
        start_time = datetime.now()
        
        try:
            logger.info("ğŸš€ é–‹å§‹AIå”ä½œå¸‚å ´åˆ†æ")
            
            # éšæ®µ1: å¸‚å ´æƒæå“¡å¿«é€Ÿæƒæ
            scanner_response = await self._run_market_scanner(market_data)
            
            # éšæ®µ2: æ·±åº¦åˆ†æå¸«è©³ç´°åˆ†æ
            analyst_response = await self._run_deep_analyst(market_data, scanner_response)
            
            # éšæ®µ3: æœ€çµ‚æ±ºç­–è€…åšå‡ºæ±ºç­–
            decision_response = await self._run_decision_maker(
                market_data, scanner_response, analyst_response
            )
            
            # ç¶œåˆæ‰€æœ‰AIçš„å›æ‡‰
            ai_responses = [scanner_response, analyst_response, decision_response]
            
            # ç”Ÿæˆæœ€çµ‚å”ä½œæ±ºç­–
            collaborative_decision = self._synthesize_decision(ai_responses)
            
            # æ›´æ–°æ€§èƒ½çµ±è¨ˆ
            processing_time = (datetime.now() - start_time).total_seconds()
            self._update_performance_stats(collaborative_decision, processing_time)
            
            logger.info(f"âœ… AIå”ä½œåˆ†æå®Œæˆ: {collaborative_decision.final_decision}")
            return collaborative_decision
            
        except Exception as e:
            logger.error(f"âŒ AIå”ä½œåˆ†æå¤±æ•—: {e}")
            return self._create_fallback_decision(str(e))
    
    async def _run_market_scanner(self, market_data: Dict[str, Any]) -> AIResponse:
        """é‹è¡Œå¸‚å ´æƒæå“¡"""
        start_time = datetime.now()
        
        try:
            model_config = self.models["market_scanner"]
            
            prompt = self._build_scanner_prompt(market_data)
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=model_config["system_prompt"],
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return AIResponse(
                ai_role="market_scanner",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True
            )
            
        except Exception as e:
            logger.error(f"âŒ å¸‚å ´æƒæå“¡åŸ·è¡Œå¤±æ•—: {e}")
            return AIResponse(
                ai_role="market_scanner",
                model_name=model_config["model_name"],
                response="",
                confidence=0.0,
                processing_time=0.0,
                timestamp=datetime.now(),
                success=False,
                error_message=str(e)
            )
    
    async def _run_deep_analyst(self, market_data: Dict[str, Any], scanner_response: AIResponse) -> AIResponse:
        """é‹è¡Œæ·±åº¦åˆ†æå¸«"""
        start_time = datetime.now()
        
        try:
            model_config = self.models["deep_analyst"]
            
            prompt = self._build_analyst_prompt(market_data, scanner_response)
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=model_config["system_prompt"],
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return AIResponse(
                ai_role="deep_analyst",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True
            )
            
        except Exception as e:
            logger.error(f"âŒ æ·±åº¦åˆ†æå¸«åŸ·è¡Œå¤±æ•—: {e}")
            return AIResponse(
                ai_role="deep_analyst",
                model_name=model_config["model_name"],
                response="",
                confidence=0.0,
                processing_time=0.0,
                timestamp=datetime.now(),
                success=False,
                error_message=str(e)
            )
    
    async def _run_decision_maker(self, market_data: Dict[str, Any], 
                                scanner_response: AIResponse, 
                                analyst_response: AIResponse) -> AIResponse:
        """é‹è¡Œæœ€çµ‚æ±ºç­–è€…"""
        start_time = datetime.now()
        
        try:
            model_config = self.models["decision_maker"]
            
            prompt = self._build_decision_prompt(market_data, scanner_response, analyst_response)
            
            response = await self._call_ai_model(
                model_name=model_config["model_name"],
                system_prompt=model_config["system_prompt"],
                user_prompt=prompt,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return AIResponse(
                ai_role="decision_maker",
                model_name=model_config["model_name"],
                response=response,
                confidence=self._extract_confidence(response),
                processing_time=processing_time,
                timestamp=datetime.now(),
                success=True
            )
            
        except Exception as e:
            logger.error(f"âŒ æœ€çµ‚æ±ºç­–è€…åŸ·è¡Œå¤±æ•—: {e}")
            return AIResponse(
                ai_role="decision_maker",
                model_name=model_config["model_name"],
                response="",
                confidence=0.0,
                processing_time=0.0,
                timestamp=datetime.now(),
                success=False,
                error_message=str(e)
            )
    
    async def _call_ai_model(self, model_name: str, system_prompt: str, 
                           user_prompt: str, max_tokens: int, temperature: float) -> str:
        """èª¿ç”¨AIæ¨¡å‹"""
        try:
            response = self.ollama_client.chat(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                options={
                    "num_predict": max_tokens,
                    "temperature": temperature,
                    "top_p": 0.9
                }
            )
            
            return response['message']['content']
            
        except Exception as e:
            logger.error(f"âŒ AIæ¨¡å‹èª¿ç”¨å¤±æ•— ({model_name}): {e}")
            raise
    
    def _build_scanner_prompt(self, market_data: Dict[str, Any]) -> str:
        """æ§‹å»ºå¸‚å ´æƒæå“¡æç¤ºè©"""
        # å¦‚æœæœ‰AIæ ¼å¼åŒ–çš„æ•¸æ“šï¼Œç›´æ¥ä½¿ç”¨
        if 'ai_formatted_data' in market_data:
            formatted_data = market_data['ai_formatted_data']
        else:
            # å›é€€åˆ°åŸºæœ¬æ ¼å¼
            formatted_data = f"""
å¸‚å ´æ•¸æ“šï¼š
- ç•¶å‰åƒ¹æ ¼: {market_data.get('current_price', 'N/A')} TWD
- 1åˆ†é˜è®ŠåŒ–: {market_data.get('price_change_1m', 'N/A')}%
- 5åˆ†é˜è®ŠåŒ–: {market_data.get('price_change_5m', 'N/A')}%
- æˆäº¤é‡æ¯”ç‡: {market_data.get('volume_ratio', 'N/A')}x
- RSI: {market_data.get('rsi', 'N/A')}
- MACD: {market_data.get('macd_trend', 'N/A')}
"""
        
        return f"""
ä½ æ˜¯å°ˆæ¥­çš„åŠ å¯†è²¨å¹£å¸‚å ´æƒæå“¡ï¼Œè² è²¬å¿«é€Ÿè­˜åˆ¥äº¤æ˜“æ©Ÿæœƒã€‚

{formatted_data}

è«‹åŸºæ–¼ä»¥ä¸Šæ•¸æ“šé€²è¡Œå¿«é€Ÿåˆ†æï¼š

1. å¸‚å ´è©•ä¼° (çœ‹æ¼²/çœ‹è·Œ/ä¸­æ€§)
2. é—œéµä¿¡è™Ÿè­˜åˆ¥ (åˆ—å‡º2-3å€‹æœ€é‡è¦çš„ä¿¡è™Ÿ)
3. æ©Ÿæœƒç­‰ç´š (é«˜/ä¸­/ä½)
4. ä¿¡å¿ƒåº¦ (0-100)
5. å»ºè­°æ“ä½œ (BUY/SELL/HOLD)

è¦æ±‚ï¼š
- ä¿æŒç°¡æ½”ï¼Œå°ˆæ³¨æ–¼æœ€é—œéµçš„ä¿¡è™Ÿ
- å„ªå…ˆè€ƒæ…®æŠ€è¡“æŒ‡æ¨™çµ„åˆ
- æ³¨æ„æˆäº¤é‡å’Œåƒ¹æ ¼çš„é…åˆ
- çµ¦å‡ºæ˜ç¢ºçš„æ•¸å­—ä¿¡å¿ƒåº¦

æ ¼å¼ï¼š
å¸‚å ´è©•ä¼°: [çœ‹æ¼²/çœ‹è·Œ/ä¸­æ€§]
é—œéµä¿¡è™Ÿ: [ä¿¡è™Ÿ1, ä¿¡è™Ÿ2, ä¿¡è™Ÿ3]
æ©Ÿæœƒç­‰ç´š: [é«˜/ä¸­/ä½]
å»ºè­°æ“ä½œ: [BUY/SELL/HOLD]
ä¿¡å¿ƒåº¦: [0-100æ•¸å­—]
"""
    
    def _build_analyst_prompt(self, market_data: Dict[str, Any], scanner_response: AIResponse) -> str:
        """æ§‹å»ºæ·±åº¦åˆ†æå¸«æç¤ºè©"""
        return f"""
åŸºæ–¼å¸‚å ´æƒæå“¡çš„åˆæ­¥åˆ†æï¼Œè«‹é€²è¡Œæ·±åº¦æŠ€è¡“åˆ†æï¼š

å¸‚å ´æƒæå“¡å ±å‘Šï¼š
{scanner_response.response}

è©³ç´°å¸‚å ´æ•¸æ“šï¼š
- ç•¶å‰åƒ¹æ ¼: {market_data.get('current_price', 'N/A')} TWD
- åƒ¹æ ¼è®ŠåŒ–: {market_data.get('price_changes', {})}
- æŠ€è¡“æŒ‡æ¨™: {market_data.get('technical_indicators', {})}
- æˆäº¤é‡åˆ†æ: {market_data.get('volume_analysis', {})}

è«‹æä¾›ï¼š
1. æŠ€è¡“æŒ‡æ¨™åˆ†æ
2. æ”¯æ’é˜»åŠ›ä½åˆ†æ
3. é¢¨éšªè©•ä¼°
4. è©³ç´°äº¤æ˜“å»ºè­°
5. ä¿¡å¿ƒåº¦ (0-100)

è«‹æä¾›å°ˆæ¥­çš„æŠ€è¡“åˆ†æå ±å‘Šã€‚
"""
    
    def _build_decision_prompt(self, market_data: Dict[str, Any], 
                             scanner_response: AIResponse, 
                             analyst_response: AIResponse) -> str:
        """æ§‹å»ºæœ€çµ‚æ±ºç­–è€…æç¤ºè©"""
        return f"""
åŸºæ–¼å¸‚å ´æƒæå“¡å’Œæ·±åº¦åˆ†æå¸«çš„å ±å‘Šï¼Œè«‹åšå‡ºæœ€çµ‚äº¤æ˜“æ±ºç­–ï¼š

å¸‚å ´æƒæå“¡å ±å‘Šï¼š
{scanner_response.response}

æ·±åº¦åˆ†æå¸«å ±å‘Šï¼š
{analyst_response.response}

è«‹ç¶œåˆåˆ†æä¸¦æä¾›ï¼š
1. æœ€çµ‚æ±ºç­–: BUY/SELL/HOLD
2. æ±ºç­–ç†ç”±
3. å»ºè­°å€‰ä½å¤§å° (%)
4. æ­¢æé»
5. ç›®æ¨™åƒ¹ä½
6. ä¿¡å¿ƒåº¦ (0-100)

è«‹åšå‡ºæ˜ç¢ºçš„äº¤æ˜“æ±ºç­–ã€‚
"""
    
    def _extract_confidence(self, response: str) -> float:
        """å¾AIå›æ‡‰ä¸­æå–ä¿¡å¿ƒåº¦"""
        try:
            # ç°¡åŒ–ç‰ˆæœ¬ï¼šå°‹æ‰¾ä¿¡å¿ƒåº¦æ•¸å­—
            import re
            confidence_match = re.search(r'ä¿¡å¿ƒåº¦[ï¼š:]\s*(\d+)', response)
            if confidence_match:
                return float(confidence_match.group(1)) / 100.0
            
            # å¦‚æœæ‰¾ä¸åˆ°æ˜ç¢ºçš„ä¿¡å¿ƒåº¦ï¼Œæ ¹æ“šå›æ‡‰å…§å®¹ä¼°ç®—
            if "å¼·çƒˆ" in response or "ç¢ºä¿¡" in response:
                return 0.8
            elif "å¯èƒ½" in response or "å»ºè­°" in response:
                return 0.6
            else:
                return 0.5
                
        except Exception:
            return 0.5
    
    def _synthesize_decision(self, ai_responses: List[AIResponse]) -> CollaborativeDecision:
        """ç¶œåˆAIå›æ‡‰ç”Ÿæˆæœ€çµ‚æ±ºç­–"""
        try:
            # æå–æ±ºç­–
            decisions = []
            confidences = []
            
            for response in ai_responses:
                if response.success:
                    decision = self._extract_decision(response.response)
                    decisions.append(decision)
                    confidences.append(response.confidence)
            
            # è¨ˆç®—å…±è­˜æ°´å¹³
            consensus_level = self._calculate_consensus(decisions)
            
            # ç¢ºå®šæœ€çµ‚æ±ºç­–
            final_decision = self._determine_final_decision(decisions, confidences)
            
            # è¨ˆç®—æ•´é«”ä¿¡å¿ƒåº¦
            overall_confidence = sum(confidences) / len(confidences) if confidences else 0.0
            
            # ç”Ÿæˆæ¨ç†èªªæ˜
            reasoning = self._generate_reasoning(ai_responses, final_decision)
            
            # è©•ä¼°é¢¨éšªç­‰ç´š
            risk_level = self._assess_risk_level(ai_responses, overall_confidence)
            
            return CollaborativeDecision(
                final_decision=final_decision,
                confidence=overall_confidence,
                consensus_level=consensus_level,
                ai_responses=ai_responses,
                reasoning=reasoning,
                risk_level=risk_level,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"âŒ æ±ºç­–ç¶œåˆå¤±æ•—: {e}")
            return self._create_fallback_decision(str(e))
    
    def _extract_decision(self, response: str) -> str:
        """å¾AIå›æ‡‰ä¸­æå–æ±ºç­–"""
        response_upper = response.upper()
        
        if "BUY" in response_upper and "SELL" not in response_upper:
            return "BUY"
        elif "SELL" in response_upper and "BUY" not in response_upper:
            return "SELL"
        else:
            return "HOLD"
    
    def _calculate_consensus(self, decisions: List[str]) -> float:
        """è¨ˆç®—AIé–“çš„å…±è­˜æ°´å¹³"""
        if not decisions:
            return 0.0
        
        # è¨ˆç®—æœ€å¸¸è¦‹æ±ºç­–çš„æ¯”ä¾‹
        from collections import Counter
        decision_counts = Counter(decisions)
        most_common_count = decision_counts.most_common(1)[0][1]
        
        return most_common_count / len(decisions)
    
    def _determine_final_decision(self, decisions: List[str], confidences: List[float]) -> str:
        """ç¢ºå®šæœ€çµ‚æ±ºç­–"""
        if not decisions:
            return "HOLD"
        
        # åŠ æ¬ŠæŠ•ç¥¨
        decision_weights = {}
        for decision, confidence in zip(decisions, confidences):
            if decision not in decision_weights:
                decision_weights[decision] = 0
            decision_weights[decision] += confidence
        
        # è¿”å›æ¬Šé‡æœ€é«˜çš„æ±ºç­–
        return max(decision_weights, key=decision_weights.get)
    
    def _generate_reasoning(self, ai_responses: List[AIResponse], final_decision: str) -> str:
        """ç”Ÿæˆæ±ºç­–æ¨ç†èªªæ˜"""
        reasoning_parts = []
        
        for response in ai_responses:
            if response.success:
                reasoning_parts.append(f"{response.ai_role}: {response.response[:100]}...")
        
        reasoning = f"æœ€çµ‚æ±ºç­–: {final_decision}\n\n" + "\n\n".join(reasoning_parts)
        return reasoning
    
    def _assess_risk_level(self, ai_responses: List[AIResponse], confidence: float) -> str:
        """è©•ä¼°é¢¨éšªç­‰ç´š"""
        if confidence >= 0.8:
            return "LOW"
        elif confidence >= 0.6:
            return "MEDIUM"
        else:
            return "HIGH"
    
    def _create_fallback_decision(self, error_message: str) -> CollaborativeDecision:
        """å‰µå»ºå‚™ç”¨æ±ºç­–"""
        return CollaborativeDecision(
            final_decision="HOLD",
            confidence=0.0,
            consensus_level=0.0,
            ai_responses=[],
            reasoning=f"ç³»çµ±éŒ¯èª¤ï¼Œæ¡ç”¨ä¿å®ˆç­–ç•¥: {error_message}",
            risk_level="HIGH",
            timestamp=datetime.now()
        )
    
    def _update_performance_stats(self, decision: CollaborativeDecision, processing_time: float):
        """æ›´æ–°æ€§èƒ½çµ±è¨ˆ"""
        self.performance_stats["total_decisions"] += 1
        
        if decision.confidence > 0.5:
            self.performance_stats["successful_decisions"] += 1
        
        # æ›´æ–°å¹³å‡è™•ç†æ™‚é–“
        total_time = (self.performance_stats["average_processing_time"] * 
                     (self.performance_stats["total_decisions"] - 1) + processing_time)
        self.performance_stats["average_processing_time"] = total_time / self.performance_stats["total_decisions"]
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½çµ±è¨ˆ"""
        return self.performance_stats.copy()
    
    def get_ai_status(self) -> Dict[str, Any]:
        """ç²å–AIç‹€æ…‹"""
        return {
            "models_configured": len(self.models),
            "collaboration_enabled": self.collaboration_settings["enable_parallel_processing"],
            "fallback_enabled": self.fallback_settings["enable_fallback"],
            "performance_stats": self.get_performance_stats()
        }


# å‰µå»ºå…¨å±€AIç®¡ç†å™¨å¯¦ä¾‹
def create_ai_manager(config_path: str = "config/ai_models.json") -> AICollaborationManager:
    """å‰µå»ºAIå”ä½œç®¡ç†å™¨å¯¦ä¾‹"""
    return AICollaborationManager(config_path)


# æ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    import asyncio
    
    async def test_ai_collaboration():
        """æ¸¬è©¦AIå”ä½œåŠŸèƒ½"""
        print("ğŸ§ª æ¸¬è©¦AIå”ä½œç³»çµ±...")
        
        # å‰µå»ºAIç®¡ç†å™¨
        ai_manager = create_ai_manager()
        
        # æ¨¡æ“¬å¸‚å ´æ•¸æ“š
        test_market_data = {
            "current_price": 1500000,
            "price_change_1m": 0.5,
            "price_change_5m": 1.2,
            "volume": 1000000,
            "volume_change": 25,
            "technical_indicators": {
                "rsi": 65,
                "macd": "é‡‘å‰"
            }
        }
        
        # åŸ·è¡Œå”ä½œåˆ†æ
        decision = await ai_manager.analyze_market_collaboratively(test_market_data)
        
        print(f"âœ… å”ä½œæ±ºç­–å®Œæˆ:")
        print(f"æœ€çµ‚æ±ºç­–: {decision.final_decision}")
        print(f"ä¿¡å¿ƒåº¦: {decision.confidence:.2f}")
        print(f"å…±è­˜æ°´å¹³: {decision.consensus_level:.2f}")
        print(f"é¢¨éšªç­‰ç´š: {decision.risk_level}")
        
        # é¡¯ç¤ºæ€§èƒ½çµ±è¨ˆ
        stats = ai_manager.get_performance_stats()
        print(f"\nğŸ“Š æ€§èƒ½çµ±è¨ˆ:")
        print(f"ç¸½æ±ºç­–æ¬¡æ•¸: {stats['total_decisions']}")
        print(f"æˆåŠŸæ±ºç­–æ¬¡æ•¸: {stats['successful_decisions']}")
        print(f"å¹³å‡è™•ç†æ™‚é–“: {stats['average_processing_time']:.2f}ç§’")
    
    # é‹è¡Œæ¸¬è©¦
    asyncio.run(test_ai_collaboration())